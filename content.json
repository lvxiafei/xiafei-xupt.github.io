{"meta":{"title":"xiafei-xupt's blog","subtitle":"汝之意志所向,即吾剑之所指","description":null,"author":"xiafei-xupt","url":"http://yoursite.com"},"pages":[{"title":"About me","date":"2018-11-03T13:11:20.930Z","updated":"2018-08-03T03:01:32.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"热爱技术与远方 目前在学习内核"}],"posts":[{"title":"","slug":"华为多次承认有研发手机系统，为什么不推广？","date":"2019-03-15T02:35:20.032Z","updated":"2019-03-15T02:52:14.340Z","comments":true,"path":"华为多次承认有研发手机系统，为什么不推广？/","link":"","permalink":"http://yoursite.com/华为多次承认有研发手机系统，为什么不推广？/","excerpt":"","text":"转载：华为多次承认有研发手机系统，为什么不推广？有2大原因很无奈！ 华为多次承认有研发手机系统，为什么不推广？有2大原因很无奈！华为这个企业在近年来的发展是一直朝着更好的方向前进，虽然说遇到的困难也不小，但是我们还是能够感受到华为的自身的实力，作为一个在中国自主研发比较出色的一个企业，华为掌握了全球最多的5G专利技术，还自己研发了处理器芯片，当然我们在手机的体验中也是能够感受到华为很多的新科技，就手机行业上来说，现在华为的位置已经可以坐到全球出货量前三的位置，本来还可以占据第二的，只是稍微有些遗憾。种种的事迹都表明了现在的华为实力越来越强大，而且多次承认有自主研发的系统。 对于华为自主研发系统其实早在很久之前就有相关的传闻，只是一直没有得到确定，也就不知道传闻是真是假，而这一次余承东亲自承认确实华为现在有着自己的一个操作系统，不过也只是为了给自己留条后路，暂时不会去做一个推广。很多用户可能就比较奇怪了，按照华为的实力，想必系统的体验感还是很强，如果能够拿出来使用，华为就系统这一方面可以省下不少的钱，而且说不定也会成为流行的第三大系统，到时候这个收益不久更多了吗？可是华为多次承认有研发手机系统，为什么不推广？有2大原因很无奈！ 第一个原因：生态不够完善要知道创立一个系统来说并不什么难事，难得是后期的生态完善，这样说可能大家都不是很懂，我们换个简单的说法，就比如说现在的苹果系统和安卓系统的生态都相当的完善了，不需要各大app重新再研发适配的软件。而且对于这些软件开发者来说，华为的新系统暂时还看不到什么收益，目前使用华为手机的人比较多，不过总体来讲使用其他的手机品牌的人也不少，到时候华为的系统肯定是用在华为的手机上，这样一来也就没有多少的收益，软件开发者是不会因为这一点用户量而去费心研究匹配新系统的软件。既然软件开发者不去设计，那么消费者可以用到的软件就很少，对于消费者来说这是不能够满足需求的。说白了就是现在华为的系统跟其他两个系统比起来没有那么大的市场。 第二个原因：华为本意不是拿来现在使用我们都知道华为这个企业危机意识一直是很强的，他们研发这个系统并不是现在要拿出来给安卓的系统或者是苹果的系统抗衡，本意就是为了有一天，假如我们不能够在使用谷歌系统的时候，自己不会处于一个尴尬的地位。大家都知道美国政府入侵华为5G系统的事情，如果说到时候因为这个官司的问题，谷歌受到压力不再给华为提供系统，至少华为也不会因此感到焦急，还有退路可言。说白了这个系统存在的意义也就是以防万一。 总结以上这两个原因就是为什么现在华为不推广自己的新系统，当然华为这一种自主研发的精神以及有强烈的危机意识是我们中国人的福气，华为在全球上的地位很大一部分都是代表着中国的。那么对于我们今天讨论的话题小伙伴们有什么不一样的看法呢？","categories":[],"tags":[]},{"title":"羽毛球攻略","slug":"羽毛球攻略","date":"2019-03-14T03:12:01.000Z","updated":"2019-03-14T03:29:41.828Z","comments":true,"path":"羽毛球攻略/","link":"","permalink":"http://yoursite.com/羽毛球攻略/","excerpt":"","text":"路线各种招式学会，超能量消耗最低方向灵活运用 招式 http://www.ctsports.com.cn/article-95415.html http://www.sohu.com/a/253794399_99921299 技巧充分利用空间位置（上下左右前后）和场地、器械等环境 和 对手状况与其打优势差，记住，你的对手是人！ 羽毛球的步法和手法傻子口诀参考：https://wenku.baidu.com/view/1a7f7e7e0722192e4536f6c7.html","categories":[],"tags":[{"name":"运动","slug":"运动","permalink":"http://yoursite.com/tags/运动/"}]},{"title":"文件系统理论学习","slug":"文件系统理论学习","date":"2019-03-07T10:56:49.000Z","updated":"2019-03-07T14:06:44.423Z","comments":true,"path":"文件系统理论学习/","link":"","permalink":"http://yoursite.com/文件系统理论学习/","excerpt":"","text":"定义wiki计算机的文件系统是一种存储和组织计算机数据的方法，它使得对其访问和查找变得容易，文件系统使用文件和树形目录的抽象逻辑概念代替了硬盘和光盘等物理设备使用数据块的概念，用户使用文件系统来保存数据不必关心数据实际保存在硬盘（或者光盘）的地址为多少的数据块上，只需要记住这个文件的所属目录和文件名。在写入新数据之前，用户不必关心硬盘上的那个块地址没有被使用，硬盘上的存储空间管理（分配和释放）功能由文件系统自动完成，用户只需要记住数据被写入到了哪个文件中。 文件系统通常使用硬盘和光盘这样的存储设备，并维护文件在设备中的物理位置。但是，实际上文件系统也可能仅仅是一种访问数据的界面而已，实际的数据是通过网络协议（如NFS、SMB、9P等）提供的或者内存上，甚至可能根本没有对应的文件（如proc文件系统）。 严格地说，文件系统是一套实现了数据的存储、分级组织、访问和获取等操作的抽象数据类型（Abstract data type） LKPA从系统角度看，文件系统是对文件存储器空间进行组织和分配，负责文件的存储并对存入的文件进行保护和检索的系统。具体地说，它负责为用户建立文件，存入、读出、修改、转储文件，控制文件的存取，当用户不再使用时撤销文件等 文件系统指文件存在的物理空间，Linux系统中每个分区都是一个文件系统，都有自己的目录层次结构。Linux会将这些分属不同分区的、单独的文件系统按一定的方式形成一个系统的总的目录层次结构。 总结文件系统是一种用于向用户提供底层数据访问的机制！ 特点 庞大的数据结构 一切皆文件 文件系统的目录组织是一个树形结构 文件本身是无结构的字符流 文件系统把外部设备做成特殊文件,与普通文件一并进行管理 文件结构Windows每个分区是一棵树/根目录 Linux /bin 二进制可执行命令 /dev 设备特殊文件 /etc 系统管理和配置文件 /home 用户主目录的基点，比如用户user的主目录就是/home/user。 /lib 标准程序设计库，又叫动态链接共享库。 /sbin 系统管理命令，这里存放的是系统管理员使用的管理程序 /tmp 公用的临时文件存储点 /root 系统管理员的主目录 /mnt 用户临时安装其他文件系统的目录。 /proc 虚拟的目录，不占用磁盘空间，是系统内存的映射。可直接访问这个目录来获取系统信息。 /var 某些大文件的溢出区，例如各种服务的日志文件 /usr 最庞大的目录，要用到的应用程序和文件几乎都在这个目录下。 总结：整个文件系统只有一棵树，根目录是公共地方，家目录你随便折腾（体现了多用户的特点） 文件系统分区每个分区都是一个文件系统 索引节点号标识一个文件eg: ls -li cat /proc/filesystems 安装mount：一般挂载到/mnt目录下 文件类型 常规文件存放数据、程序等信息的文件，一般分为文本文件和二进制文件 目录文件将文件的名称和它的索引节点号结合在一起的一张表 设备文件每种I/O设备对应一个设备文件，存放在/dev目录中 管道文件主要用于在进程间传递数据的媒介，Linux对管道的操作与文件操作相同，将管道作为文件进行处理，又称为先进先出文件 链接文件又称为符号链接文件，提供了共享文件的一种方法。使用链接文件可以访问常规文件，目录文件和其它文件 注意：通过ls /dev -l命令可以看到fifo为管道文件，d为目录文件，c为字符文件，l为链接文件 虚拟文件系统虚拟文件系统（简称VFS）为用户程序提供了具体文件系统的接口，它对每个具体文件系统的细节进行抽象，使所有文件系统依赖于VFS且可以通过VFS协同工作。要注意VFS与具体文件系统的区别，VFS只存在于内存中，在系统启动时创建，在系统关闭时消亡。 虚拟含义 在同一个目录结构中, 可以挂载着若干种不同的文件系统. VFS隐藏了它们的实现细节, 为使用者提供统一的接口; 目录结构本身并不是绝对的, 每个进程可能会看到不一样的目录结构. 目录结构是由”地址空间(namespace)”来描述的, 不同的进程可能拥有不同的namespace, 不同的namespace可能有着不同的目录结构(因为它们可能挂载了不同的文件系统). VFS中四个主要对象超级块对象：描述已安装文件系统。 索引节点对象：描述一个文件。 目录项对象：描述一个目录项，是路径的组成部分。 文件对象：描述由进程打开的文件。","categories":[],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"http://yoursite.com/tags/Kernel/"}]},{"title":"空循环引起的问题","slug":"空循环引起的问题","date":"2019-03-07T03:48:53.000Z","updated":"2019-03-07T03:48:54.260Z","comments":true,"path":"空循环引起的问题/","link":"","permalink":"http://yoursite.com/空循环引起的问题/","excerpt":"","text":"输出为-1下列程序的输出结果是（ ） int main(void) { int Y=1; while(Y--); printf(&quot;Y=%d&quot;,Y); } A.Y=0 B.Y=1 C.Y=-1 D.Y=随机数 输出为0那么 int main(void) { int Y=1; while(Y--) printf(&quot;Y=%d&quot;,Y); } 呢？ 解析： 第一个程序由于是空循环，当Y为0时还要判断一下，故结果为-1 第二个程序直接输出，结果为0","categories":[],"tags":[{"name":"C","slug":"C","permalink":"http://yoursite.com/tags/C/"}]},{"title":"中断发展史","slug":"中断发展史","date":"2019-03-06T03:40:16.000Z","updated":"2019-03-06T03:44:01.750Z","comments":true,"path":"中断发展史/","link":"","permalink":"http://yoursite.com/中断发展史/","excerpt":"","text":"发展过程首先，中断上下部分是为了避免中断嵌套时关中断太长有些中断得不到响应引出的一种机制，中断既能让程序运行的快，又能让程序完成的多个工作，即有效利用时间和空间，中断上半部分是特点是快速可以及时快速响应所有中断（避免了有些中断得不到响应这种情况的发生），中断下半部分执行的比较慢，它才是中断主要执行的有用部分，相对于上半部分而言，下半部分执行时可以被中断，也就是允许并发，考虑到中断下半部分的执行，引出了小任务机制，不可睡眠，工作队列，可睡眠， 引出软中断实现中断下半部分，随着中断数的不停增加，软中断不够用了，于是下半部又做了进化，为了提高中断处理数量，顺道改进处理效率，于是产生了tasklet机制（小任务机制） 由于之前机制中的中断不可挂起，串行执行，也就是说只要有一个处理时间较长，则会导致其他中断响应的延迟，为了完成这些不可能完成的任务，引出了工作队列，工作队列的本质是一组内核线程，作为中断守护线程来使用。 操作系统显然不能任由每个中断各自为政，为了对所有中断进行统一管理，引入软中断我们不可中断部分的共同部分放在函数do_IRQ中，需要添加中断处理函数时，通过request_irq实现。下半部放在do_softirq中，也就是软中断，通过open_softirq添加对应的处理函数。 旧事物跟不上历史的发展时，总会有新事物出现。随着中断数的不停增加，软中断不够用了，于是下半部又做了进化。软中断用轮询的方式处理。假如正好是最后一种中断，则必须循环完所有的中断类型，才能最终执行对应的处理函数。显然当年开发人员为了保证轮询的效率，于是限制中断个数为32个。 为了提高中断处理数量，顺道改进处理效率，于是产生了tasklet机制。 工作队列：由于之前机制中的中断不可挂起，串行执行，也就是说只要有一个处理时间较长，则会导致其他中断响应的延迟，为了完成这些不可能完成的任务，引出了工作队列，工作队列的本质是一组内核线程，作为中断守护线程来使用。 中断的栈和进程的栈是一个么？不是，因为每个进程都有属于自己的栈（每个进程都有自己的虚拟空间，虚拟空间中有栈，在执行时通过页机制转换），假设中断栈和进程栈是同一个栈，那么每个进程的栈地址都不一样，这样恢复中断时将变得非常麻烦。中断栈应该公有，因为中断最后是要中断CPU的，而内核是管理硬件的，所以猜测中断栈应该在内核态，内核空间也有自己的栈，那么内核栈是否和中断栈是同一个栈？查阅资料得知在2.4版本中，中断栈和内核栈共享，优点是代码简单，缺点是共享有时可能会导致内核栈空间不够用（内核栈和中断栈数据共享），为了改善这个缺点，要么扩大内核栈大小，要么在内核空间重新开辟一个栈，称为中断栈，考虑到中断栈如果发生嵌套，可能会破坏内核栈数据（可能会造成栈溢出），所以现在Linux内核采用内核栈和中断栈分离的设计 参考资料 Linux中的中断处理机制","categories":[],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"http://yoursite.com/tags/Kernel/"}]},{"title":"Level DB和Couch DB的区别？","slug":"Level DB和Couch DB的区别？","date":"2019-03-06T02:47:10.000Z","updated":"2019-03-06T02:59:28.639Z","comments":true,"path":"Level DB和Couch DB的区别？/","link":"","permalink":"http://yoursite.com/Level DB和Couch DB的区别？/","excerpt":"","text":"相关定义Level DB：(是fabric默认的db），Level DB 是嵌入在 Peer 中的默认键值对（key-value）状态数据库。 Counch DB：支持副查询（更加丰富），Couch DB 是一种可选的替代 level DB 的状态数据库。 与 Level DB 键值存储一样，Couch DB 不仅可以根据 key 进行相应的查询，还可以根据不同的应用场景需求实现复杂查询。 区别对比 参考资料 CouchDB vs. LevelDB Comparison - DB-Engines","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"}]},{"title":"文件描述符","slug":"文件描述符","date":"2019-03-05T13:41:51.000Z","updated":"2019-03-06T02:44:22.818Z","comments":true,"path":"文件描述符/","link":"","permalink":"http://yoursite.com/文件描述符/","excerpt":"","text":"相关说明1.对于内核而言，所有打开文件都由文件描述符引用2.文件描述符是一个非负整数3.当打开一个现存文件或创建一个新文件时，内核向进程返回一个文件描述符4.当读、写一个文件时，用open或create返回的文件描述符标书该文件，将其作为参数传送给read或write 代码体现fs_test.c： #include &lt;stdio.h&gt; #include &lt;fcntl.h&gt; int main(int argc,char *argv[]) { int fd = open(&quot;/etc/passwd&quot;,O_RDONLY); printf(&quot;fd : %d\\n&quot;,fd); return 0; } 执行上面代码，返回值是3 注：fcntl.h，是unix标准中通用的头文件，其中包含的相关函数有 open，fcntl，shutdown，unlink，fclose等！ 为什么是3？当一个进程启动时，它会自动打开三个文件，这三个文件分别是：标准输入、标准输出、标准出错，它们对应的文件描述符分别是0、1、2，所以当打开/etc/passwd这个文件时，它就接着以3开始计数了。 POSIX.1应用程序中，整数0、1、2营被代换成符号常数STDIN_FILENO、STDOUT_FILENO、STDERR_FILENO，这些常数都定义在头文件&lt;unistd.h&gt;（可在/usr/include目录下找到，或使用cat unistd.h | grep STDIN_FILENO查看）中。 文件描述符范围0-OPEN_MAX。早期UNIX版本采用的上限值是19（允许每个进程打开20个文件），现在很多系统将其增加至63，Linux为1024。","categories":[],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"http://yoursite.com/tags/Kernel/"}]},{"title":"C语言中fprintf和printf的区别？","slug":"C语言中fprintf和printf的区别？","date":"2019-03-05T13:36:40.000Z","updated":"2019-03-05T13:39:26.619Z","comments":true,"path":"C语言中fprintf和printf的区别？/","link":"","permalink":"http://yoursite.com/C语言中fprintf和printf的区别？/","excerpt":"","text":"原型fprintf的函数原型为： int fprintf( FILE *stream, const char *format, [ argument ]...)； 而printf的函数原型为： int printf( const char *format [, argument]... ); 因此fprintf是将字符输出到流（文件）的，而printf是输出到标准输出设备（stdout）的，一般就是屏幕。","categories":[],"tags":[{"name":"C","slug":"C","permalink":"http://yoursite.com/tags/C/"}]},{"title":"假期论文阅读汇总","slug":"假期论文阅读汇总","date":"2019-03-01T06:09:17.000Z","updated":"2019-03-01T06:34:24.028Z","comments":true,"path":"假期论文阅读汇总/","link":"","permalink":"http://yoursite.com/假期论文阅读汇总/","excerpt":"","text":"《分布式文件系统性能测试和优化研究》文章简介文章对分布式文件系统的关键技术和GlusterFS的系统架构进行了研究，然后对GlusterFS的文件系统进行了测试，根据测试结果，设计了一套在LevelDB上存储GlusterFS元数据及其扩展属性的方案，使系统的元数据性能得到了提高。 论文内容互联网的高速发展使得对大数据的存储需求越来越高，应对高并发的数据访问是互联网技术很大的挑战。分布式系统通过计算机网络把不一定连接在本地的物理存储资源连接成集群，其文件系统管理元数据的方式有三种：一是集中式元数据服务模型，二是分布式元数据服务模型，三是无元数据服务模型。GlusterFS采用了无元数据服务模型。这使得GlusterFS避开了前两种模型不能彻底解决的问题，消除了元数据性能瓶颈、单点故障、数据一致性等一系列相关问题，并且使得系统的扩展性显著提高，获得了接近线性的高扩展性。但是，这也导致了GlusterFS部分元数据操作的缓慢。文章修改了LevelDB存储部分元数据的存储方式，让一部分元数据操作通过LevelDB进行，加快元数据操作的速度，从而能提升了性能。 论文启发 其他分布式文件系统是否也可以使用数据库保存元数据来加快元数据操作速度？ 数据库的选取对元数据操作速度有影响吗？如果有可否选取合适的数据库进行调优？ 在集中式元数据服务模型和分布式元数据服务模型中应该怎样优化呢？ 总结文章对GlusterFS分布式文件系统进行了详细的分析。试图通过使用LevelDB保存GlusterFS元数据来加快GlusterFS元数据操作的速度。 《分布式文件系统海量小文件性能优化技术研究》论文简介文章的主要研究对象是实验室自主独立开发的分布式文件系统Cappella，将小文件访问主要耗时定位到元数据或数据访问时的磁盘I/O，对该点进行相关优化可以提高系统对小文件的访问性能。通过本文的研究，证实通过改善小文件的访问性能可以有效提高分布式文件系统的总体性能，同时本文的研究方式也可以给今后小文件性能问题研究提供借鉴，文章的研究内容有非常大的研究意义。 论文内容主要对分布式文件系统Cappella的小文件访问过程进行研究分析，主要对访问过程中客户端与服务器之间的交互过程以及小文件访问耗时进行分析，结合小文件的访问特点确定小文件访问过程中的主要瓶颈。根据对小文件访问瓶颈分析，对小文件应用场景下的Cappella文件系统进行优化，主要包括对小文件的访问流程进行精简，然后使用文件聚合存储技术将小文件的元数据信息和数据信息一起存储在元数据服务器，然后优化了小文件访问过程中的I/O路径，对小文件的写操作使用批量刷回技术进行优化，小文件读操作使用缓存预取技术进行优化。最后对比测试了优化前后Cappella文件系统以及Lustre文件系统的元数据IOPS、小文件读写性能、小文件并发访问性能、大文件读写性能进行测试。 文章详细测试了Cappella文件系统对海量小文件优化前后的性能，主要包括元数据服务器吞吐量、系统小文件读写性能、系统小文件并发测试以及系统大文件读写性能测试。根据测试结果分析可得，优化后Cappella文件系统元数据吞吐量大幅增加；对小文件的读写性能提升明显；多线程并发写，小文件性能同样有明显提升；系统大文件读写性能有小幅提升。 论文启发 文章中主要对应的存储介质是HDD，考虑到新型介质发展迅速，可以进一步测试不同存储介质情况下本优化方案的提升空间； 文章中提到的优化方案只是在Cappella这一具体的文件系统上实现，理论上是可以适用于其他分布式文件系统，但是还是需要进行实际的验证，因此本优化方案是否具有普适性就需要更进一步的验证。 文章仅仅验证了小文件数量在千万级时优化方案对性能还有提升效果，但是当小文件数量更大时本文中的优化方案是否依然有效就需要更深入的测试分析。 总结对小文件的访问流程进行精简，然后使用文件聚合存储技术将小文件的元数据信息和数据信息一起存储在元数据服务器，然后优化了小文件访问过程中的I/O路径，对小文件的写操作使用批量刷回技术进行优化，小文件读操作使用缓存预取技术进行优化，从而达到对Cappella文件系统中小文件进行优化的目的。","categories":[],"tags":[{"name":"论文","slug":"论文","permalink":"http://yoursite.com/tags/论文/"}]},{"title":"JavaScript 全栈课程-答疑模块","slug":"JavaScript 全栈课程-答疑模块","date":"2019-02-22T07:37:29.000Z","updated":"2019-02-22T07:38:25.056Z","comments":true,"path":"JavaScript 全栈课程-答疑模块/","link":"","permalink":"http://yoursite.com/JavaScript 全栈课程-答疑模块/","excerpt":"","text":"第一阶段集合运算合集：Q1:./practices/collectionOperator/get_letter_interval_2_spec.js 文件应该怎么写？需要预置一个字符数组吗？A1.1:两种方法123456function getBasicLetter() &#123; let basicLetter = []; for (let i = 97; i &lt; 97 + 26; ++i) basicLetter.push(String.fromCharCode(i)); return basicLetter;&#125;//用unicode编码获取 1let ElseLetter =[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;,&apos;e&apos;,&apos;f&apos;....] //自己写一个字符串数组 A1.2：12345678910111213141516171819202122232425262728293031323334353637&apos;use strict&apos;;function get_letter_interval_2(number_a, number_b) &#123; let rounds = getRounds(number_a &gt; number_b ? number_a : number_b); if (number_a &gt; number_b) return getRoundsLetters(rounds).splice(number_b - 1, number_a - number_b + 1).reverse(); if (number_a &lt; number_b) return getRoundsLetters(rounds).splice(number_a - 1, number_b - number_a + 1); return [getRoundsLetters(rounds)[number_a - 1]];&#125;function getBasicLetter() &#123; let basicLetter = []; for (let i = 97; i &lt; 97 + 26; ++i) basicLetter.push(String.fromCharCode(i)); return basicLetter;&#125;function getRoundsLetters(rounds) &#123; let roundsLetters = getBasicLetter(); let basicLetters = getBasicLetter(); for (let i = 0; i &lt; rounds - 1; ++i) basicLetters.map(letter =&gt; roundsLetters.push(basicLetters[i] + letter)); return roundsLetters;&#125;function getRounds(number) &#123; let rounds = number / 26; if (number % 26 !== 0) rounds += 1; return rounds;&#125;module.exports = get_letter_interval_2; pos机：Q1:怎么回事？A1: 仓库地址：1234tdd测试： https://github.com/Mucheng910/npm-test.git运算合集： https://github.com/Mucheng910/80--es6-.git黄焖鸡： https://github.com/Mucheng910/take-out-food.gitdom： https://github.com/Mucheng910/dom.git tdd测试的pos机测试文件有问题照这个改一下就好了 课程直播的录频：黄焖鸡： 链接: https://pan.baidu.com/s/1_opDqIowOR0vJgD83oiTPg 密码: f78ves6函数：https://pan.baidu.com/s/1pUP8-et6PST76F6ogd3FVg 今日在线直播课程的录屏开发chrome插件：主题：手把手带你开发Chrome插件链接：https://pan.baidu.com/s/1D2kGN89yQEgy9IZegc6VqA 密码：e7we pre course 简书地址https://www.jianshu.com/p/642601569bf7?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=weixin 第二阶段1面向对象基础 https://github.com/Mucheng910/class-es6.git 测试过程 https://www.jianshu.com/p/850b3e870261 # # 第三阶段其他Q1：如果想在浏览器中输入一个未曾注册的域名，例如，www.qinlin.top，浏览器响应的是www.baidu.com，那么这个代码应该怎么写A1： #","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yoursite.com/tags/JavaScript/"}]},{"title":"vmware14 安装 Ubuntu18.04 教程","slug":"vmware14 安装 Ubuntu18.04 教程","date":"2019-02-22T07:31:42.000Z","updated":"2019-02-22T07:33:50.925Z","comments":true,"path":"vmware14 安装 Ubuntu18.04 教程/","link":"","permalink":"http://yoursite.com/vmware14 安装 Ubuntu18.04 教程/","excerpt":"","text":"作者：王星 有问题请发邮件：admin@stormxing.com 准备必要文件首先需要用到两个文件，你可以用我给的地址下载： VMware 14 pro https://dl.stormxing.com/share/VMware-workstation-full-14.1.1.exe Ubuntu 18.04 LTS https://dl.stormxing.com/share/ubuntu-18.04-desktop-amd64.iso Ubuntu 16.04 LTS （备用，非必须） https://dl.stormxing.com/share/ubuntu-16.04.3-desktop-amd64.iso 有小伙伴反应，Ubuntu 18.04 安装不上，可能是刚出来，vmware 对它的支持还不好，换成Ubuntu16.04 就好了。 安装 VMware 14 pro 打开软件之后先点下一步。 建议把安装位置改一下，软件比较大，默认是安装到 C 盘的。这个增强型键盘驱动程序无需安装。 最后，要把这两个打钩的去掉。 激活 VMware 14 Pro 在软件安装完成的时候点击「许可证」。 输入一下密匙后点「输入」 CG54H-D8D0H-H8DHY-C6X7X-N2KG6 之后打开 vmware ，点击「帮助」——&gt;「关于」，可以看到软件是激活的。 安装 Ubuntu 18.04 点击「创建新的虚拟机」，按默认的安装方式点下一步。 点击浏览，然后选择刚下载好的镜像，打开之后点下一步。 设置 Ubuntu 的用户名和密码，我这里输入的都是 test，你要换成你自己的。 然后选择安装位置，这个位置一定要改一下，默认的是 c 盘。 设置 Ubuntu 最大可用空间，我这里设置的 20 G，你可以设置大一点。其他的不要动，直接点下一步。 接着可以自定义硬件，如果你不太懂的话，我也建议你无需更改，默认的设置就很好。 最后，他就开始安装了，可惜的是我这里报错了，不要惊慌！如果你跟我一样，则接着进行下面的设置。 打开电脑的「控制面板」——&gt;「程序」——&gt;「启用或关闭 Windows 功能」。 找到 「Hyper-V」,将勾去掉，然后点确定。最后它会提示要重启电脑，这个也是一定要重启的。 重启电脑之后，点击「开启此虚拟机」 接着就会自动安装 Ubuntu，这个过程大概会持续 10 到 20 分钟左右。如果你电脑配置较好的话，需要的时间则更短。 安装完成之后点击用户，登录即可。 电脑竟然卡住了，点击「重新启动客户机」即可。 然后就顺利的进入到 Ubuntu 18.04 了。请尽情体验吧。 个人觉得只需要掌握虚拟机的开机、关机、全屏这些操作即可，其他的自己探索吧。","categories":[],"tags":[{"name":"教程","slug":"教程","permalink":"http://yoursite.com/tags/教程/"}]},{"title":"关系型数据库和非关系型数据库的区别","slug":"关系型数据库和非关系型数据库的区别","date":"2019-02-22T06:06:29.000Z","updated":"2019-02-22T06:08:15.996Z","comments":true,"path":"关系型数据库和非关系型数据库的区别/","link":"","permalink":"http://yoursite.com/关系型数据库和非关系型数据库的区别/","excerpt":"","text":"定义非关系型数据库：非关系型数据库产品是传统关系型数据库的功能阉割版本，通过减少用不到或很少用的功能，来大幅度提高产品性能。非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合。 关系型数据库：是指采用了关系模型来组织数据的数据库。关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织。 可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。对于安全性能很高的数据访问要求可以实现。 价格目前基本上大部分主流的非关系型数据库都是免费的。而比较有名气的关系型数据库，比如Oracle、DB2、MSSQL是收费的。虽然Mysql免费，但它需要做很多工作才能正式用于生产。 功能实际开发中，有很多业务需求，其实并不需要完整的关系型数据库功能，非关系型数据库的功能就足够使用了。这种情况下，使用性能更高、成本更低的非关系型数据库当然是更明智的选择。 对于这两类数据库，对方的优势就是自己的弱势，反之亦然。 其他 参考资料 关系型数据库和非关系型数据库的区别","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"}]},{"title":"未来技术猜测","slug":"未来技术猜测","date":"2019-02-20T07:45:37.000Z","updated":"2019-02-20T08:07:01.579Z","comments":true,"path":"未来技术猜测/","link":"","permalink":"http://yoursite.com/未来技术猜测/","excerpt":"","text":"开源带来的影响：主线 与 分支 基类 与 继承 计算 与 存储 物联网带来的影响：物物互联，信息共享 人工智能带来的影响：辅助人类，取代计算机 区块链带来的影响：去中心化，交易透明 生产关系更加透明 大数据带来的影响：预测结果越来越接近未来发生 5G带来的影响：云计算的加速 高速带宽使得传统存储方式发生改变，对硬盘、U盘等大容量存储设备的依赖降低 高清视屏得到普及 提高用户体验（使用云端硬件资源） 智能家居营造一个理想化的生态使得人类能够专心去做自己喜欢的事情","categories":[],"tags":[{"name":"未来","slug":"未来","permalink":"http://yoursite.com/tags/未来/"}]},{"title":"关于区块链的五个问题","slug":"五个问题","date":"2019-02-18T10:50:00.000Z","updated":"2019-02-18T10:52:09.506Z","comments":true,"path":"五个问题/","link":"","permalink":"http://yoursite.com/五个问题/","excerpt":"","text":"作者 ：陈哲 西安邮电大学计算机学院研究生大佬一枚 五个问题： 我们经常说区块链，那么区块究竟是什么？ 所谓挖矿是怎么回事？ 比特币是什么？ 节点之间的信息如何交换？ 区块在节点上是如何存储，如何查找的？ 首先我们介绍”比特币核心“（bitcoin core），是由中本聪指定的人选组建的团队,通常被认为是比特币的唯一官方开发团队，其在最初的“中本聪客户端”bitcoin-qt的基础上开发了Bitcoin core钱包也被公认为是比特币的官方钱包。 在bitcoin core中区块信息被存储在一个个.dat文件中，该文件的结构如下， 一个.bat文件包含多个区块的信息。 为了查找方便将区块头等信息另外组织，存放在level DB数据库，这是一个轻量级的K/V数据库，具有很好的写性能。 查询时可以通过区块哈希值在数据库中查找到相应的.bat文件名及在该文件中的偏移，从而找到区块的完整信息。 区块链 PoW（Proof of work）各节点贡献自己的计算资源来竞争解决一个难度可动态调整的数学问题。 区块链系统的五个要素 公共的区块链账本 分布式的点对点网络 去中心化的共识算法 适度的经济激励机制 可编程的脚本代码（智能合约） 数字加密货币面临的两个问题 双重支付 现金是实体自然避免。其它数字形式货币需要第三方中心机构来保证，例如支付宝。 拜占庭将军问题 分布式节点如何达成共识和建立互信。 区块链技术的基础模型 数据层 数据区块 区块头 123456789101112131415struct header_structure &#123; // BYTES NAMEuint32_t nVersion; // 4 versionuint8_t hashPrevBlock[32]; // 32 previous block header hashuint8_t hashMerkleRoot[32]; // 32 merkle root hashuint32_t nTime; // 4 timeuint32_t nBits; // 4 targetuint32_t nNonce; // 4 nonce&#125;; 区块体 包含一定时间段内的交易数据，及交易信息的Merkel树结构。 哈希函数–SHA256算法 SHA（Secure Hash Algorithm）是一种密码散列函数算法标准。由美国国家安全局研发，由美国国家标准与技术研究院发布，是美国政府标准。 其摘要长度为256bits，故称为SHA256。 其特点为，不可以从消息摘要中复原信息；两个不同的消息不会产生同样的消息摘要。 SHA将消息当成一个位（bit）字符串来处理。 描述： 常量初始化 8个哈希初值，由自然数中前8个质数取平方根后，将小数部分转化为16进制，再取前32bit构成。 123456789101112131415h0 := 0x6a09e667h1 := 0xbb67ae85h2 := 0x3c6ef372h3 := 0xa54ff53ah4 := 0x510e527fh5 := 0x9b05688ch6 := 0x1f83d9abh7 := 0x5be0cd19 64个哈希常量，由自然数中前64个质数取立方根后，将小数部分转化为16进制，再取前32bit构成。这里记为Kt。 12345678910111213141516171819202122232425262728293031428a2f98 71374491 b5c0fbcf e9b5dba53956c25b 59f111f1 923f82a4 ab1c5ed5d807aa98 12835b01 243185be 550c7dc372be5d74 80deb1fe 9bdc06a7 c19bf174e49b69c1 efbe4786 0fc19dc6 240ca1cc2de92c6f 4a7484aa 5cb0a9dc 76f988da983e5152 a831c66d b00327c8 bf597fc7c6e00bf3 d5a79147 06ca6351 1429296727b70a85 2e1b2138 4d2c6dfc 53380d13650a7354 766a0abb 81c2c92e 92722c85a2bfe8a1 a81a664b c24b8b70 c76c51a3d192e819 d6990624 f40e3585 106aa07019a4c116 1e376c08 2748774c 34b0bcb5391c0cb3 4ed8aa4a 5b9cca4f 682e6ff3748f82ee 78a5636f 84c87814 8cc7020890befffa a4506ceb bef9a3f7 c67178f2 信息预处理 消息必须进行补位，以使其长度对512取模后余数为448，先补1，再之后补0。 附加长度值，用64bit表示补位前消息的长度，并附加在第一步处理后的消息之后。这样总的消息长度能被512整除。 逻辑运算 迭代计算消息摘要 1, 将原始消息分解为512bit大小的块 2, 对于每一块，将其分解为16个32bit字记为W[0]…W[15] 3, 根据如下公式，再构造出48个字 Wt=σ1(Wt−2)+Wt−7+σ0(Wt−15)+Wt−1 这样我们一共获得了64个32位字Wt 下面开始进行迭代计算： 对每一块512bit长的消息块需要进行64次迭代，初始的ABCDEFGH即为h0…h7 123456789101112131415for i from 0 to 63s0 := (a rightrotate 2) xor (a rightrotate 13) xor(a rightrotate 22)maj := (a and b) xor (a and c) xor(b and c)t2 := s0 + majs1 := (e rightrotate 6) xor (e rightrotate 11) xor(e rightrotate 25)ch := (e and f) xor ((not e) and g)t1 := h + s1 + ch + k[i] + w[i]h := gg := ff := ee := d + t1d := cc := bb := aa := t1 + t2 迭代完成后的最后一组ABCDEFG即为该块数据的摘要。 接着进行下一块数据的迭代，重新初始化8个变量： 123456789101112131415h0 := h0 + ah1 := h1 + bh2 := h2 + ch3 := h3 + dh4 := h4 + eh5 := h5 + fh6 := h6 + gh7 := h7 + h 最终，当最后一块数据迭代完毕后，我们得到了原始数据的摘要： digest = hash = h0 append h1 append h2 append h3 append h4 append h5 append h6 append h7 将原始数据编码为特定长度的字符串记入区块链 双SHA256哈希函数： 将任意长度的原始数据经过两次SHA256哈希运算后转为长度为256位的二进制数字。 SHA256算法的散列空间为2^256^ ，好的哈希函数具备的特点：单向性，定时性，定长性，随机性。 验证一个区块头信息 首先是真实区块信息 接着将数据处理成十六进制，注意时间戳要先转换为UTC时间戳（从1970年1月1日至此时的秒数），再转十六进制。 big-endian转为little-endian 拼接字符串 做两次SHA256 二叉Merkle树–快速归纳和校验区块数据的存在和完整性 Merkle树是一种哈希树，其中每个叶子结点存放数据块的哈希值，而非叶结点存放其孩子结点数据的哈希值。如下图所示： Merkel树逐层记录哈希值，底层数据有任何变动，都能传递到他的父结点，一层层传递到树根。根结点实际上记录了全部数据的数字指纹。 比特币采用Merkel实现SPV（简化支付验证）协议, 即在不运行完整区块链网络节点的情况下, 也能够对 (交易) 数据进行检验。例如, 为验证上图 中交易 L1, 一个没有下载完整区块链数据的客户端可以通过向其他节点索要包括从交易L1 哈希值沿 Merkle 树上溯至区块头根哈希处的哈希序列 (即哈希节点 0-1, 1,TOP) 来快速确认交易的存在性和正确性. 一般说来, 在 N个交易组成的区块体中确认任一交易的算法复杂度仅为 log~2~N. 非对称加密–公私钥 发送者记为A，接受者记为B 信息加密：A使用B的公钥加密信息后发送给B，保证只有B能解密。 数字签名：A使用A的私钥加密信息后发送给B，B使用A的公钥解密，确保信息是由A发送的。 登录认证：客户端用私钥加密登录信息，服务器用客户端的公钥解密后进行验证。 比特币私钥：随机生成的256位随机数（私钥空间2^256^，对比IPV6 2^128^个地址，可以为世界上每粒沙子分配IP），再由SHA256和Base58转换为50个字符长度的便于书写的私钥提供给用户。 比特币公钥：由私钥经过Secp256k1椭圆曲线算法加密生成65字节长度的随机数。 比特币交易地址：由公钥进行SHA256和RIPEMD160两次哈希生成20字节长度的结果，再经过SHA256和Base58转换成33字符长度的比特币地址。 网络层 在去中心化的区块链网络中，每一个节点都拥有同等的地位，当然也需要为整个网络尽同等的责任。 节点的任务主要是网络路由，验证区块数据，传播区块数据，发现新节点等。 1.寻找比特币网络中的有效节点，此步骤通常有两种方法： 使用“DNS种子”（DNS seeds），DNS种子提供比特币节点的IP地址列表，Bitcoin Core客户端提供五种不同的DNS种子，通常默认使用即可 手动通过-seednode命令指定一个比特币节点的IP地址作为比特币种子节点 2.与发现的有效比特币节点进行初始“握手”，建立连接 节点发送一条包含基本认证内容的version消息开始“握手”通信过程。 3.新节点建立更多的连接，使节点在网络中被更多节点接收，保证连接更稳定** 发送一条包含自身IP地址的addr发送给已连接的节点，这些节点收到后将此转发给它们各自的连接节点，使网络中更多的节点接收到新节点 发送一条getaddr消息，要求已连接节点返回其已知的节点IP地址列表，通过这种方式，节点可以找到更多可连接的节点。 已建立连接的节点会定期发送信息维持连接，如果某个节点长达90分钟没有通信，会被认为已经断开，网络会开始寻找一个新的节点。 每个节点连接不超过1000个对等节点，超过数量的IP地址会被忽略，连接过多的节点浪费网络资源，没有必要。 4.交换“区块清单”（注：该步骤仅在全节点上会执行，且从与节点建立连接就开始进行） 全节点在连接到其他节点后，需要构建完整的区块链，如果是新节点，它仅包含静态植入客户端中的0号区块（创世区块）。 通过version消息中的BestHeight字段可知双方节点的区块高度，然后节点之间交换一个getblocks消息，其中包含本地区块链顶部区块的Hash，这样节点间就可以判断谁的链更长。 拥有更长链的节点识别出其他节点需要“补充”的区块后，开始分批发送区块（500个区块为一批），通过inv消息先将第一批的区块清单发送给对端节点（inv消息包含500个区块的Hash清单）。限制每次同步区块的数量，是为了减少新节点同步区块对网络造成的影响。 缺少区块的节点发送getdata消息向所有已连接的节点请求全区块数据，“正在传输”的区块数量不能超过客户端MAX_BLOCKS_IN_TRANSIT_PER_PEER参数设置的值。 共识层 PoW共识–分布式节点的算力竞争 解决一个求解复杂但验证容易的SHA256数学难题（所谓挖矿）。最快解决这一问题的节点获得区块记账权和系统生成的比特币奖励。 这样数学问题可表述为：根据当前目标值（难度值），通过搜索一个合适的随机数（Nonce）使得区块头元数据两次SHA256后的哈希值小于等于目标值。 123456block_header = version + previous_block_hash + merkle_root + time + target_bits + nonce for i in range(0, 2**32): if sha256(sha256(block_header)) &lt; target_bits: break else: continue 计算难度的调整： 比特币系统定时调整目标值（难度值）以保证，每10分钟生成一个区块。 新目标值= 当前目标值 实际2016个区块出块时间 / 理论2016个区块产生时间(600s2016=2周)。 链式结构和分叉 总是选择延长累计工作量证明最大的区块链和六次确认 激励层 奖励金 获得区块记账权的矿工，同时获得系统奖励的比特币，这一奖励信息也被打包在该区块的交易信息中。初始挖到每个区块奖励50BTC ，之后每21万个区块，奖励金减半，最总整个系统共生成2100万BTC 。目前是12.5BTC /块。 手续费 小额交易：小于0.01BTC 每笔支付0.0001BTC 千字节收费：当前每笔交易的手续费大部分是0.0001BTC /KB（约3.8元/KB）,最初比特币区块限制1MB。 非强制，但矿工在组建数据块时通常会优先考虑带有较高手续费的交易，以便在挖矿成功时能获得较高的报酬，因此无附带任何手续费的交易，可能会需要等待较长的时间才能被处理并纳入区块链中。 （satoshi，即比特币最小单位，0.000 000 01 BTC = 1 satoshi） 合约层 应用层 参考 《区块链技术发展现状与展望》袁勇 王飞跃 《區塊鍊(区块链)解密：: 构建基于信用的下一代互联网》 作者：黄步添， 蔡亮编 《SHA256算法原理详解》 《Merkel Tree学习》 《比特币的挖矿到底在计算什么？ - Tony的回答 - 知乎》","categories":[],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"什么是分布式文件系统？","slug":"什么是分布式文件系统？","date":"2019-02-17T08:15:33.000Z","updated":"2019-02-22T08:17:22.465Z","comments":true,"path":"什么是分布式文件系统？/","link":"","permalink":"http://yoursite.com/什么是分布式文件系统？/","excerpt":"","text":"维基百科上给出的定义相对于本机端的文件系统而言，分布式文件系统（英语：Distributed file system, DFS），或是网络文件系统（英语：Network File System），是一种允许文件透过网络在多台主机上分享的文件系统，可让多机器上的多用户分享文件和存储空间。在这样的文件系统中，客户端并非直接访问底层的数据存储区块，而是透过网络，以特定的通信协议和服务器沟通。借由通信协议的设计，可以让客户端和服务端都能根据访问控制清单或是授权，来限制对于文件系统的访问。相对地，在一个分享的磁盘文件系统中，所有节点对数据存储区块都有相同的访问权，在这样的系统中，访问权限就必须由客户端程序来控制。分布式文件系统可能包含的功能有：透通的数据复制与容错。也就是说，即使系统中有一小部分的节点脱机，整体来说系统仍然可以持续运作而不会有数据损失。分布式文件系统和分布式数据存储的界线是模糊的，但一般来说，分布式文件系统是被设计用在局域网[1]，比较强调的是传统文件系统概念的延伸，并透过软件方法来达成容错。而分布式数据存储，则是泛指应用分布式运算技术的文件和数据库等提供数据存储服务的系统。 性能指标一个普遍用来量测网络文件系统性能的方式是：它需要用多少时间来完成服务请求？在传统的系统中，完成请求所需要的时间包括了实际的硬盘访问时间，和一小部分的中央处理器处理时间。但在一个网络文件系统中，由于分布式架构的关系，远程访问动作会产生额外的经常性负担，包括：把请求从客户端送到服务端的时间、把回应从服务端传回客户端的时间、以及这两个传输过程中用来运行网络传输协议的中央处理处时间。一个网络文件系统的性能，可被视为是评估它透通性的一个维度，拿来与本地磁盘进行充分的对比。 CAP定理著名的CAP定理指出：在一个分布式数据存储架构中，数据的一致性（Consistency）、可用性（Availability）、和网络分隔的容忍程度（Partition tolerance）只能取二来做最优化，无法三者兼具。当代的分布式数据存储服务均是各自针对服务的内容和性质来作取舍，很难说有哪一个是通用的最佳解。 发展路线传统纸笔——&gt;磁盘磁带光盘——&gt;单机时代——&gt;独立文件服务器——&gt;存储服务器/设备——&gt;分布式文件系统——&gt;未来量子通信 目前主流的分布式文件系统介绍常见的分布式文件系统有，GFS、HDFS、Lustre 、Ceph 、GridFS 、mogileFS、TFS、FastDFS等。各自适用于不同的领域。它们都不是系统级的分布式文件系统，而是应用级的分布式文件存储服务。 GFS（Google File System）Google公司为了满足本公司需求而开发的基于Linux的专有分布式文件系统。。尽管Google公布了该系统的一些技术细节，但Google并没有将该系统的软件部分作为开源软件发布。下面分布式文件系统都是类 GFS的产品。 HDFSHadoop 实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。 Hadoop是Apache Lucene创始人Doug Cutting开发的使用广泛的文本搜索库。它起源于Apache Nutch，后者是一个开源的网络搜索引擎，本身也是Luene项目的一部分。Aapche Hadoop架构是MapReduce算法的一种开源应用，是Google开创其帝国的重要基石。 Ceph是加州大学圣克鲁兹分校的Sage weil攻读博士时开发的分布式文件系统。并使用Ceph完成了他的论文。说 ceph 性能最高，C++编写的代码，支持Fuse，并且没有单点故障依赖， 于是下载安装， 由于 ceph 使用 btrfs 文件系统， 而btrfs 文件系统需要 Linux 2.6.34 以上的内核才支持。可是ceph太不成熟了，它基于的btrfs本身就不成熟，它的官方网站上也明确指出不要把ceph用在生产环境中。 LustreLustre是一个大规模的、安全可靠的，具备高可用性的集群文件系统，它是由SUN公司开发和维护的。该项目主要的目的就是开发下一代的集群文件系统，可以支持超过10000个节点，数以PB的数据量存储系统。目前Lustre已经运用在一些领域，例如HP SFS产品等。 参考链接 分布式文件系统 当前主流分布式文件系统有哪些?各有什么优缺点","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/分布式/"}]},{"title":"Linux内核是什么？","slug":"Linux内核是什么？","date":"2019-02-10T12:03:33.000Z","updated":"2019-02-11T03:11:32.526Z","comments":true,"path":"Linux内核是什么？/","link":"","permalink":"http://yoursite.com/Linux内核是什么？/","excerpt":"","text":"Linux内核定义 底层驱动Linux内核[kernel]是整个操作系统的最底层，它负责整个硬件的驱动，以及提供各种系统所需的核心功能，包括防火墙机制、是否支持LVM或Quota等文件系统等等，如果内核不认识某个最新的硬件，那么硬件也就无法被驱动，你也就无法使用该硬件。 芯片控制计算机真正工作的东西其实是硬件，例如数值运算要使用到CPU、数据储存要使用到硬盘、图形显示会用到显示适配器、音乐发声要有音效芯片、连接Internet 可能需要网络卡等等。内核就是控制这些芯片如何工作。 Linux操作系统的三层模型 最底层的硬件系统，包括CPU、内存、硬盘、网卡等； 硬件系统之上是内核，这是操作系统的核心，负责管理硬件系统，同时为上层的应用程序提供操作接口； 用户进程在这表示计算机中运行的所有程序，它们运行于用户空间，由内核统一管理； Linux内核主的五个子系统 进程调度 内存管理 虚拟文件系统 网络接口 进程间通信 进程调度位于中心位置，所有子系统都依赖于它，因为每个子系统都需要挂起和恢复进程。一般情况下，当一个进程等待硬件操作完成时，它就被挂起；当操作完成时，进程就被恢复执行例如：当一个进程通过网络发送一条消息时，网络接口需要挂起发送进程，直到硬件成功地完成消息的发送，当消息被成功地发送出去后，网络接口给进程返回一个代码，表示操作成功或失败。其它子系统都是与此相似地依赖进程调度 Linux组成kernel的功能 kernel提供的功能都通过系统调用给用户接口 kernel包括：进程管理 、内存管理 、网络管理 、驱动程序、安全管理 、文件系统 库函数功能模块集合，调用接口是二进制程序，要想运行，必须别其他程序调用，即其他程序面向硬件的一个中间层，有两种情形 过程调用（procedure）无返回值 函数调用（function ）：有返回值 rootfslinux一切皆文件，除了一级文件外，其他文件需要挂载至根文件系统 程序开机过程开机 –&gt;内核运行 –&gt; 内核加载根文件系统 –&gt;运行根文件系统上的第一个应用程序init init：它是负责后面的总的应用程序的启动回收等，启动可能需要向内核申请，这一切都在用户空间运行，如果init程序终止了，则用户空间的所有程序终止 配置文件让程序按照我们需要的方式一直运行下去 Linux内核特点结合了unix操作系统的一些基础概念 支持模块化 linux内核会将其各部分功能模块化，这使得在安装linux内核时，可以仅保持最基本的内核和功能，不过内核中模块数量会变多。linux内核中的.ko（kernel object）文件就是可以被内核调用的内核模块。 做以下假设：驱动是内核提供的，编译好一个内核之后，在装在主机上，在未来添加新的硬件设备没有新的驱动的话。是重新编译一次内核？这种设计是一件反人类的设计啊，因此引入了模块设计。 模块化设计得以避免这种情况，故各大厂商可以通过模块化的形式开发自己的驱动，只需针对某一特定设备开发自己驱动程序即可，在编译驱动模块。由于linux支持动态装载和卸载模块，因此当我需要和不需要某一功能时，可自行拆卸，此操作并不影响核心的正常运行。 Linux内核的任务 从技术层面讲，内核是硬件与软件之间的一个中间层。作用是将应用层序的请求传递给硬件，并充当底层驱动程序，对系统中的各种设备和组件进行寻址。 从应用程序的层面讲，应用程序与硬件没有联系，只与内核有联系，内核是应用程序知道的层次中的最底层。在实际工作中内核抽象了相关细节。 内核是一个资源管理程序。负责将可用的共享资源(CPU时间、磁盘空间、网络连接等)分配得到各个系统进程。 内核就像一个库，提供了一组面向系统的命令。系统调用对于应用程序来说，就像调用普通函数一样。 参考资料 Linux内核简介 linux内核管理 《深入理解linux内核》","categories":[],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"http://yoursite.com/tags/Kernel/"}]},{"title":"Rust语言的优势","slug":"Rust语言的优势","date":"2019-02-01T14:23:38.000Z","updated":"2019-02-01T14:51:37.354Z","comments":true,"path":"Rust语言的优势/","link":"","permalink":"http://yoursite.com/Rust语言的优势/","excerpt":"","text":"一门编程语言的开发追求的是快速、安全性、易于编写三个方面，但大多数的编程语言的现状只满足两个方面，安全性和简单的编程语言往往编译速度很慢，比如Python;编译快又满足安全性的却又很难学，比方说C与C++。那么有没有一门语言同时满足快速、安全、简单三个方面呢? 由Graydon Hoare开发、Mozilla Research赞助的Rust语言一直在致力于快速、安全、简单三方面的追求，虽然谷歌的Go语言近些月以来都被炒得很热，但Rust语言可以说也是新晋黑马的一员，Rust语言为何能与Go相媲美?它的优势在哪里? 满足更高的速度需求Rust代码可跨多个平台编译成本机代码，且二进制文件是自包含的，无需运行。生成的代码意味要执行与C或者C++编写的类似的代码。 更加注重安全性大多数内存错误都是在程序运行时才被发现，其他语言中常见的内存问题——空指针、野指针以及数据竞争等绝不会在Rust中产生。Rust编译器会将这些问题标记出来，在程序运行之前进行修复。 无需内存管理Rust的记忆管理系统在语言语法中通过一个叫做所有权的隐喻进行了阐述语言中的任何给定值都可以被控制或者操纵，且一次只能由一个变量来控制。对象之间传输所有权受到编译器的严格控制，所以在运行时没有内存分配形式的错误。所有权也意味着Rust没有像GO或C#这样的垃圾回收的内存管理。 Rust程序中的所有内存都通过所有权自动跟踪和释放。 使用简单Rust相对于C入门简单，这也是Rust受欢迎的重要原因之一。所有在Rust中生成的二进制文件都会放在一个包里;像GCC那样的外部编译器只有在编译Rust原生系统之外的其他组件(比如从源代码中编译C库)时才需要。Rust同样适用于Linux、MacOS以及Windows。 其他优势 支持多架构、多平台 支持三种操作系统，支持交叉编译以及跨架构、平台二进制文件的产生。 强大的语言功能 Rust拥有 “宏”，泛型，模式匹配等，功能毫不逊色于C++。 标准库 拥有像C和C++的标准库，可使用容器、集合、迭代器等工具，执行字符串操作，管理进程和线程等。 IDE工具Visual Studio等工具 参考资料 为什么我说Rust是靠谱的编程语言 Rust官网","categories":[],"tags":[{"name":"Rust","slug":"Rust","permalink":"http://yoursite.com/tags/Rust/"}]},{"title":"Docker与虚拟机、物理机的区别？","slug":"Docker与虚拟机、物理机的区别？","date":"2019-01-31T15:22:44.000Z","updated":"2019-01-31T15:34:49.597Z","comments":true,"path":"Docker与虚拟机、物理机的区别？/","link":"","permalink":"http://yoursite.com/Docker与虚拟机、物理机的区别？/","excerpt":"","text":"初次接触Docker时，感觉它就像一种轻量级的虚拟机。Docker最初的成功秘诀是因为它比虚拟机更节省内存，启动更快。然而事实并非如此，Docker并非虚拟机，那么什么是Docker呢？它和虚拟机、物理机又有什么区别呢？ 极简类比一、物理机是这样的 二、虚拟机是这样的 三、容器是这样的 什么是Docker?Docker是一个开源的引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台。 集装箱比方集装箱解决了什么问题呢？在一艘大船上，可以把货物规整的摆放起来。并且各种各样的货物被集装箱标准化了，集装箱和集装箱之间不会互相影响。那么我就不需要专门运送水果的船和专门运送化学品的船了。只要这些货物在集装箱里封装的好好的，那我就可以用一艘大船把他们都运走。docker也是类似的理念。我们可以在一台机器上跑多个互相毫无关联的docker容器，每一个容器就相当于一个集装箱。 Docker的应用场景 web应用的自动化打包和发布； 自动化测试和持续集成、发布； 在服务型环境中部署和调整数据库或其他的后台应用； 从头编译或者扩展现有的OpenShift或Cloud Foundry平台来搭建自己的PaaS环境。 Docker里的几个基本概念镜像镜像可以理解为一堆静态的文件 容器容器则是镜像run起来之后的一个实例。镜像之于容器就好比面向对象编程里的class之于object。 仓库镜像需要地方保存，这个地方就是仓库上层建立不同的容器，不同的应用镜像打包在不同的容器中，他们互相隔离。 理解Docker容器使用Docker容器运行多个相互隔离的应用时，如下图: 不难发现，相比于虚拟机，Docker要简洁很多。因为我们不需要运行一个臃肿的从操作系统了。从下到上理解上图: 基础设施(Infrastructure)。 主操作系统(Host Operating System)。所有主流的Linux发行版都可以运行Docker。对于MacOS和Windows，也有一些办法”运行”Docker。 Docker守护进程(Docker Daemon)。Docker守护进程取代了Hypervisor，它是运行在操作系统之上的后台进程，负责管理Docker容器。 各种依赖。对于Docker，应用的所有依赖都打包在Docker镜像中，Docker容器是基于Docker镜像创建的。 应用。应用的源代码与它的依赖都打包在Docker镜像中，不同的应用需要不同的Docker镜像。不同的应用运行在不同的Docker容器中，它们是相互隔离的。 虚拟机使用虚拟机运行多个相互隔离的应用时，如下图: 从下到上理解上图: 基础设施(Infrastructure)。它可以是你的个人电脑，数据中心的服务器，或者是云主机。 主操作系统(Host Operating System)。你的个人电脑之上，运行的可能是MacOS，Windows或者某个Linux发行版。 虚拟机管理系统(Hypervisor)。利用Hypervisor，可以在主操作系统之上运行多个不同的从操作系统。类型1的Hypervisor有支持MacOS的HyperKit，支持Windows的Hyper-V以及支持Linux的KVM。类型2的Hypervisor有VirtualBox和VMWare。 从操作系统(Guest Operating System)。假设你需要运行3个相互隔离的应用，则需要使用Hypervisor启动3个从操作系统，也就是3个虚拟机。这些虚拟机都非常大，也许有700MB，这就意味着它们将占用2.1GB的磁盘空间。更糟糕的是，它们还会消耗很多CPU和内存。 各种依赖。每一个从操作系统都需要安装许多依赖。如果你的的应用需要连接PostgreSQL的话，则需要安装libpq-dev；如果你使用Ruby的话，应该需要安装gems；如果使用其他编程语言，比如Python或者Node.js，都会需要安装对应的依赖库。 应用。安装依赖之后，就可以在各个从操作系统分别运行应用了，这样各个应用就是相互隔离的。 对比虚拟机与Dockerdocker设计小巧，部署迁移快速，运行高效，应用之间相互独立，管理人员可以看到所有容器的内容，虚拟化技术比较臃肿，不论什么应用都需要先创建新的系统，并且并非按照应用隔离，而是按照系统隔离，管理员无法看到系统内部信息。 Docker守护进程可以直接与主操作系统进行通信，为各个Docker容器分配资源；它还可以将容器与主操作系统隔离，并将各个容器互相隔离。虚拟机启动需要数分钟，而Docker容器可以在数毫秒内启动。由于没有臃肿的从操作系统，Docker可以节省大量的磁盘空间以及其他系统资源。 应用场景虚拟机更擅长于彻底隔离整个运行环境。例如，云服务提供商通常采用虚拟机技术隔离不同的用户。而Docker通常用于隔离不同的应用，例如前端，后端以及数据库。 APP与某信举个例子，Docker就是手机中的各种APP，只需要一个系统就可以下载自己所需的应用，但是虚拟化技术相当于你的苹果手机安装一个庞大软件，这个软件上安装安卓系统、魅族系统等，每个系统上还要安装各类应用，比较麻烦。 但两者没有绝对的好坏，主要还是看应用场景，根据不同的需求选择不同的解决方案即可。 具体对比 docker启动快速属于秒级别，虚拟机通常需要几分钟去启动。 docker需要的资源更少，docker在操作系统级别进行虚拟化，docker容器和内核交互，几乎没有性能损耗，性能优于通过Hypervisor层与内核层的虚拟化。 docker更轻量，docker的架构可以共用一个内核与共享应用程序库，所占内存极小。同样的硬件环境，Docker运行的镜像数远多于虚拟机数量。对系统的利用率非常高 与虚拟机相比，docker隔离性更弱，docker属于进程之间的隔离，虚拟机可实现系统级别隔离； 安全性： docker的安全性也更弱。Docker的租户root和宿主机root等同，一旦容器内的用户从普通用户权限提升为root权限，它就直接具备了宿主机的root权限，进而可进行无限制的操作。虚拟机租户root权限和宿主机的root虚拟机权限是分离的，并且虚拟机利用如Intel的VT-d和VT-x的ring-1硬件隔离技术，这种隔离技术可以防止虚拟机突破和彼此交互，而容器至今还没有任何形式的硬件隔离，这使得容器容易受到攻击。 可管理性：docker的集中化管理工具还不算成熟。各种虚拟化技术都有成熟的管理工具，例如VMware vCenter提供完备的虚拟机管理能力。 高可用和可恢复性：docker对业务的高可用支持是通过快速重新部署实现的。虚拟化具备负载均衡，高可用，容错，迁移和数据保护等经过生产实践检验的成熟保障机制，VMware可承诺虚拟机99.999%高可用，保证业务连续性。 快速创建、删除：虚拟化创建是分钟级别的，Docker容器创建是秒级别的，Docker的快速迭代性，决定了无论是开发、测试、部署都可以节约大量时间。 交付、部署：虚拟机可以通过镜像实现环境交付的一致性，但镜像分发无法体系化；Docker在Dockerfile中记录了容器构建过程，可在集群中实现快速分发和快速部署 参考资料 docker中文社区 comparing-virtual-machines-vs-docker-containers docker容器与虚拟机有什么区别？","categories":[],"tags":[{"name":"云计算","slug":"云计算","permalink":"http://yoursite.com/tags/云计算/"}]},{"title":"什么是“平均负载”(二)？","slug":"什么是“平均负载”(二)？","date":"2019-01-30T12:23:21.000Z","updated":"2019-02-17T06:49:38.196Z","comments":true,"path":"什么是“平均负载”(二)？/","link":"","permalink":"http://yoursite.com/什么是“平均负载”(二)？/","excerpt":"","text":"平均负载与 CPU 使用率现实工作中，我们经常容易把平均负载和 CPU 使用率混淆，所以在这里，进行一个区分。 可能你也会有这样的疑惑，既然平均负载代表的是活跃进程数，那平均负载高了，是不是也就意味着 CPU 使用率高？ 我们来看看平均负载的含义，平均负载是指单位时间内，处于可运行状态和不可中断状态的进程数。所以，它不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待 I/O 的进程。 而 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如： CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的； I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高； 大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高。 平均负载案例分析下面，我们以三个示例分别来看这三种情况，并用 iostat、mpstat、pidstat 等工具，找出平均负载升高的根源。 实验准备下面的案例都是基于 Ubuntu 18.04，案例环境如下所示。 机器配置：2 CPU，2GB 内存。 预先安装 stress 和 sysstat 包，如 apt install stress sysstat。 首先介绍一下 stress 和 sysstat。 stress 是一个 Linux 系统压力测试工具，这里用作异常进程模拟平均负载升高的场景。而 sysstat 包含了常用的 Linux 性能工具，用来监控和分析系统的性能。我们的案例会用到这个包的两个命令 mpstat 和 pidstat。 mpstat 是一个常用的多核 CPU 性能分析工具，用来实时查看每个 CPU 的性能指标，以及所有 CPU 的平均指标。 pidstat 是一个常用的进程性能分析工具，用来实时查看进程的 CPU、内存、I/O 以及上下文切换等性能指标。 此外，每个场景都需要开三个终端，登录到同一台 Linux 机器中。 注意，下面的所有命令，默认以普通用户运行。所以，如果遇到权限不够时，一定要运行 sudo su root 命令切换到 root 用户。 如果上面的环境准备都已经完成了，先用 uptime 命令，看一下测试前的平均负载情况： 场景一：CPU 密集型进程首先，在第一个终端运行 stress 命令，模拟一个 CPU 使用率 100% 的场景： 接着，在第二个终端运行 uptime 查看平均负载的变化情况： # -d 参数表示高亮显示变化的区域 $ watch -d uptime 最后，在第三个终端运行 mpstat 查看 CPU 使用率的变化情况： # -P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据 $ mpstat -P ALL 5 从终端二中可以看到，1 分钟的平均负载会慢慢增加到 1.00，而从终端三中还可以看到，正好有一个 CPU 的使用率为 100%，但它的 iowait 只有 0。这说明，平均负载的升高正是由于 CPU 使用率为 100% 。那么，到底是哪个进程导致了 CPU 使用率为 100% 呢？你可以使用 pidstat 来查询： # 间隔 5 秒后输出一组数据 $ pidstat -u 5 1 从这里可以明显看到，stress 进程的 CPU 使用率为 99.60%，接近100%。 场景二：I/O 密集型进程首先还是运行 stress 命令，但这次模拟 I/O 压力，即不停地执行 sync： $ stress -i 1 --timeout 600 注意： 在虚拟机中$ stress -i 1 --timeout 600iowait无法升高，与理论不符？ iowait无法升高的问题，是因为物理机中stress使用的是 sync() 系统调用，它的作用是刷新缓冲区内存到磁盘中。对于虚拟机，缓冲区可能比较小，无法产生大的IO压力，这样大部分就都是系统调用的消耗了。所以，只会看到只有系统CPU使用率升高。解决方法是使用stress的下一代stress-ng，它支持更丰富的选项，比如 stress-ng -i 1 --hdd 1 --timeout 600（--hdd表示读写临时文件）。 stress-ng -i 1 --hdd 1 --timeout 600 在第二个终端运行 uptime 查看平均负载的变化情况： $ watch -d uptime 然后，第三个终端运行 mpstat 查看 CPU 使用率的变化情况： # 显示所有 CPU 的指标，并在间隔 5 秒输出一组数据 $ mpstat -P ALL 5 1 从这里可以看到，1 分钟的平均负载会慢慢增加到 0.95，接近1，其中一个 CPU 的系统 CPU 使用率升高到了 6.16，而 iowait 高达 87.44%。这说明，平均负载的升高是由于 iowait 的升高。那么到底是哪个进程，导致 iowait 这么高呢？使用 pidstat 来查询： # 间隔 5 秒后输出一组数据，-u 表示 CPU 指标 $ pidstat -u 5 1 可以发现，还是 stress 进程导致的。 场景三：大量进程的场景当系统中运行进程超出 CPU 运行能力时，就会出现等待 CPU 的进程。比如，我们还是使用 stress，但这次模拟的是 8 个进程： $ stress -c 8 --timeout 600 由于系统只有 2 个 CPU，明显比 8 个进程要少得多，因而，系统的 CPU 处于严重过载状态，平均负载高达 7.76： $ uptime 或者 $ watch -d uptime 接着再运行 pidstat 来看一下进程的情况： # 间隔 5 秒后输出一组数据 $ pidstat -u 5 1 可以看出，8 个进程在争抢 2 个 CPU，每个进程等待 CPU 的时间（也就是代码块中的 %wait 列）高达 76%左右。这些超出 CPU 计算能力的进程，最终导致 CPU 过载。 案例小结分析完这三个案例，归纳一下平均负载的理解。 平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但只看平均负载本身，并不能直接发现，到底是哪里出现了瓶颈。所以，在理解平均负载时，需要注意： 平均负载高有可能是 CPU 密集型进程导致的； 平均负载高并不一定代表 CPU 使用率高，还有可能是 I/O 更繁忙了； 当发现负载高的时候，你可以使用 mpstat、pidstat 等工具，辅助分析负载的来源。 文章总结什么是平均负载 正确定义：单位时间内，系统中处于可运行状态和不可中断状态的平均进程数。 错误定义：单位时间内的cpu使用率。 可运行状态的进程：正在使用cpu或者正在等待cpu的进程，即ps aux命令下STAT处于R状态的进程 不可中断状态的进程：处于内核态关键流程中的进程，且不可被打断，如等待硬件设备IO响应，ps命令D状态的进程 理想状态：每个cpu上都有一个活跃进程，即平均负载数等于cpu数 过载经验值：平均负载高于cpu数量70%的时候 相关命令 cpu核数: lscpu、 grep ‘model name’ /proc/cpuinfo | wc -l 显示平均负载：uptime、top，显示的顺序是最近1分钟、5分钟、15分钟，从此可以看出平均负载的趋势 watch -d uptime: -d会高亮显示变化的区域 strees: 压测命令，–cpu cpu压测选项，-i io压测选项，-c 进程数压测选项，–timeout 执行时间 mpstat: 多核cpu性能分析工具，-P ALL监视所有cpu pidstat: 进程性能分析工具，-u 显示cpu利用率 平均负载与cpu使用率的区别CPU使用率：单位时间内cpu繁忙情况的统计 情况1：CPU密集型进程，CPU使用率和平均负载基本一致 情况2：IO密集型进程，平均负载升高，CPU使用率不一定升高 情况3：大量等待CPU的进程调度，平均负载升高，CPU使用率也升高 平均负载过高时调优工具：stress、sysstat CPU密集型进程case mpstat -P ALL 5：-P ALL表示监控所有CPU，5表示每5秒刷新一次数据，观察是否有某个cpu的%usr会很高，但iowait应很低 pidstat -u 5 1：每5秒输出一组数据，观察哪个进程%cpu很高，但是%wait很低，极有可能就是这个进程导致cpu飚高 IO密集型进程case mpstat -P ALL 5：观察是否有某个cpu的%iowait很高，同时%usr也较高 pidstat -u 5 1：观察哪个进程%wait较高，同时%CPU也较高 大量进程case pidstat -u 5 1：观察那些%wait较高的进程是否有很多 参考资料 Linux性能优化实战 倪朋飞","categories":[],"tags":[{"name":"系统优化","slug":"系统优化","permalink":"http://yoursite.com/tags/系统优化/"}]},{"title":"什么是“平均负载”(一)？","slug":"什么是“平均负载”(一)？","date":"2019-01-29T11:24:27.000Z","updated":"2019-02-11T02:42:26.405Z","comments":true,"path":"什么是“平均负载”(一)？/","link":"","permalink":"http://yoursite.com/什么是“平均负载”(一)？/","excerpt":"","text":"查看系统平均负载uptimeubuntu@localhost:~$ uptime 21:41:11 up 57 min, 1 user, load average: 0.28, 0.09, 0.24 命令输出的最后内容表示在过去的1、5、15分钟内运行队列中的平均进程数量。一般来说只要每个 CPU 的当前活动进程数不大于3那么系统的性能就是良好的，如果每个 CPU 的任务数大于5，那么就表示这台机器的性能有严重问题。通过 ubuntu@localhost:~$ grep &apos;model name&apos; /proc/cpuinfo | wc -l 1 可知该系统此时只有一个 CPU ，则表示其系统性能是良好的。 w top glances tload loadavg这些工具中的平均负载是从 /proc/loadavg 文件中读取的，也可以直接使用 cat 命令查看： ubuntu@localhost:~$ cat /proc/loadavg 0.48 0.69 0.42 5/452 6570 “平均负载”是什么？当系统变慢时，我们做的第一件事就是在Linux系统终端中输入uptime、w、top、glances、tload等命令来了解系统的负载情况，这几个命令都会有系统平均负载load average的输出，那么系统平均负载是什么呢？ 运行队列中的平均进程数Load Average是 CPU 的Load，它所包含的信息不是 CPU 的使用率状况，而是在一段时间内 CPU 正在处理以及等待 CPU 处理的进程数之和的统计信息，也就是 CPU 使用队列的长度的统计信息。 也就是说： 系统平均负载被定义为在特定时间间隔内运行队列中的平均进程数。如果一个进程满足以下条件则其就会位于运行队列中： 它没有在等待I/O操作的结果 它没有主动进入等待状态(也就是没有调用’wait’) 没有被停止(例如：等待终止) 平均活跃进程数简单来说，平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和 CPU 利用率并没有直接关系。这里先解释下，可运行状态和不可中断状态这俩词儿。 可运行状态所谓可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。 不可中断状态不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。 比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。如果此时的进程被打断了，就容易出现磁盘数据与进程数据不一致的问题。 所以，不可中断状态实际上是系统对进程和硬件设备的一种保护机制。 因此，你可以简单理解为，平均负载其实就是平均活跃进程数。平均活跃进程数，直观上的理解就是单位时间内的活跃进程数，但它实际上是活跃进程数的指数衰减平均值。这个“指数衰减平均”的详细含义你不用计较，这只是系统的一种更快速的计算方式，你把它直接当成活跃进程数的平均值也没问题。 理解系统平均负载和 CPU 核心数的关系考虑了 CPU 核心数的影响，才能解释系统负载。 多处理器 Vs 多核处理器 多处理器 – 一个计算机系统中集成两个或多个物理 CPU 多核处理器 – 单个物理 CPU 有两个或多个单独的核并行工作（也叫处理单元）。双核意味着有两个处理单元，4核有4个处理单元，以此类推。 此外，Intel 引入了超线程技术用来提高并行计算能力。通过超线程技术，在操作系统中，单个物理 CPU 表现的和两个逻辑 CPU 一样。（实际在硬件上只有一个 CPU）。 注意，单个 CPU 核同一时间只能执行一个任务，于是产生了多 CPU/处理器、多核 CPU，以及多线程技术。 多 CPU 时，多个程序可以同时执行。如今的 Intel CPU 使用了多核心和超线程技术。可以使用 nproc 或 lscpu 命令查看系统中的处理器单元数量。 ubuntu@localhost:~$ nproc 4 # 或者 lscpu 也可以使用 grep 命令： ubuntu@localhost:~$ grep &apos;model name&apos; /proc/cpuinfo | wc -l 4 为了进一步理解系统负载，需要做一些假设。假设系统负载如下： 23:16:49 up 10:49, 5 user, load average: 1.00, 0.40, 3.35 在单核系统中意味着：• CPU 被充分利用（100%）；最近的 1 分钟有 1 个进程在运行。 • CPU 有 60% 处于空闲状态；在最近的 5 分钟没有进程等待 CPU 时间。 • CPU 平均过载了 235%；最近的 15 分钟平均有 2.35 个进程在等待 CPU 时间。 在双核系统中意味着：• 有一个 CPU 处于完全空闲状态，另一个 CPU 被使用；最近的 1 分钟没有进程等待 CPU 时间。 • CPU 平均 160% 处于空闲状态；最近的 5 分钟没有进程等待 CPU 时间。 • CPU 平均过载了 135%；最近的 15 分钟有 1.35 个进程等待 CPU 时间。 Load average的算法上面的输出数据是每隔5秒钟检查一次活跃的进程数，然后根据这个数值算出来的。如果这个数除以 CPU 的数目，结果高于5的时候就表明系统在超负荷运转了。其算法(摘自Linux 2.6 的内核代码)如下： 文件: include/linux/sched.h: #define FSHIFT 11 /* nr of bits of precision */ #define FIXED_1 (1&lt;&lt;FSHIFT) /* 1.0 as fixed-point */ #define LOAD_FREQ (5*HZ) /* 5 sec intervals */ #define EXP_1 1884 /* 1/exp(5sec/1min) as fixed-point */ #define EXP_5 2014 /* 1/exp(5sec/5min) */ #define EXP_15 2037 /* 1/exp(5sec/15min) */ #define CALC_LOAD(load,exp,n) \\ load *= exp; \\ load += n*(FIXED_1-exp); \\ load &gt;&gt;= FSHIFT; 文件: kernel/timer.c: unsigned long avenrun[3]; /* * calc_load - given tick count, update the avenrun load estimates. * This is called while holding a write_lock on xtime_lock. */ static inline void calc_load(unsigned long ticks) { unsigned long active_tasks; /* fixed-point */ static int count = LOAD_FREQ; count -= ticks; if (count &lt; 0) { count += LOAD_FREQ; active_tasks = count_active_tasks(); CALC_LOAD(avenrun[0], EXP_1, active_tasks); CALC_LOAD(avenrun[1], EXP_5, active_tasks); CALC_LOAD(avenrun[2], EXP_15, active_tasks); } } 文件: fs/proc/proc_misc.c: #define LOAD_INT(x) ((x) &gt;&gt; FSHIFT) #define LOAD_FRAC(x) LOAD_INT(((x) &amp; (FIXED_1-1)) * 100) /* * Warning: stuff below (imported functions) assumes that its output will fit * into one page. For some of those functions it may be wrong. Moreover, we * have a way to deal with that gracefully. Right now I used straightforward * wrappers, but this needs further analysis wrt potential overflows. */ extern int get_hardware_list(char *); extern int get_stram_list(char *); extern int get_chrdev_list(char *); extern int get_filesystem_list(char *); extern int get_exec_domain_list(char *); extern int get_dma_list(char *); extern int get_locks_status (char *, char **, off_t, int); static int proc_calc_metrics(char *page, char **start, off_t off, int count, int *eof, int len) { if (len &lt;= off+count) *eof = 1; *start = page + off; len -= off; if (len&gt;count) len = count; if (len&lt;0) len = 0; return len; } static int loadavg_read_proc(char *page, char **start, off_t off, int count, int *eof, void *data) { int a, b, c; int len; a = avenrun[0] + (FIXED_1/200); b = avenrun[1] + (FIXED_1/200); c = avenrun[2] + (FIXED_1/200); len = sprintf(page,&quot;%d.%02d %d.%02d %d.%02d %ld/%d %d\\n&quot;, LOAD_INT(a), LOAD_FRAC(a), LOAD_INT(b), LOAD_FRAC(b), LOAD_INT(c), LOAD_FRAC(c), nr_running(), nr_threads, last_pid); return proc_calc_metrics(page, start, off, count, eof, len); } 平均负载的意义既然平均的是活跃进程数，那么最理想的，就是每个 CPU 上都刚好运行着一个进程，这样每个 CPU 都得到了充分利用。比如当平均负载为 2 时，意味着什么呢？ 在只有 2 个 CPU 的系统上，意味着所有的 CPU 都刚好被完全占用。 在 4 个 CPU 的系统上，意味着 CPU 有 50% 的空闲。 而在只有 1 个 CPU 的系统中，则意味着有一半的进程竞争不到 CPU。 平均负载为多少时合理回到前面的例子，不知道能否判断出，在那些命令的结果里，其中三个时间段的平均负载数，多大的时候能说明系统负载高？或是多小的时候就能说明系统负载很低呢？ 我们知道，平均负载最理想的情况是等于 CPU 个数。所以在评判平均负载时，首先需要知道系统有几个 CPU，这可以通过 top 命令或者从文件 /proc/cpuinfo 中读取。有了 CPU 个数，我们就可以判断出，当平均负载比 CPU 个数还大的时候，系统已经出现了过载。 不过，新的问题又来了。在前面的例子中可以看到，平均负载有三个数值，到底该参考哪一个呢？实际上，都要看。三个不同时间间隔的平均值，其实给我们提供了，分析系统负载趋势的数据来源，可以更全面、更立体地理解目前的负载状况。 平均负载的三个时间段打个比方，就像初秋时北京的天气，如果只看中午的温度，你可能以为还在 7 月份的大夏天呢。但如果你结合了早上、中午、晚上三个时间点的温度来看，基本就可以全方位了解这一天的天气情况了。同样的，前面说到的 CPU 的三个负载时间段也是这个道理。 如果 1 分钟、5 分钟、15 分钟的三个值基本相同，或者相差不大，那就说明系统负载很平稳。 但如果 1 分钟的值远小于 15 分钟的值，就说明系统最近 1 分钟的负载在减少，而过去 15 分钟内却有很大的负载。 反过来，如果 1 分钟的值远大于 15 分钟的值，就说明最近 1 分钟的负载在增加，这种增加有可能只是临时性的，也有可能还会持续增加下去，所以就需要持续观察。一旦 1 分钟的平均负载接近或超过了 CPU 的个数，就意味着系统正在发生过载的问题，这时就得分析调查是哪里导致的问题，并要想办法优化了。 这里举个例子，假设在一个单 CPU 系统上看到平均负载为 1.73，0.60，7.98，那么说明在过去 1 分钟内，系统有 73% 的超载，而在 15 分钟内，有 698% 的超载，从整体趋势来看，系统的负载在降低。 实际环境中的平均负载在实际生产环境中，平均负载多高时，需要我们重点关注呢？ 一般情况，当平均负载高于 CPU 数量 70% 的时候，就应该分析排查负载高的问题了。一旦负载过高，就可能导致进程响应变慢，进而影响服务的正常功能。 但 70% 这个数字并不是绝对的，最推荐的方法，还是把系统的平均负载监控起来，然后根据更多的历史数据，判断负载的变化趋势。当发现负载有明显升高趋势时，比如说负载翻倍了，再去做分析和调查。 参考资料 Linux性能优化实战 倪朋飞 什么是系统平均负载(Load average) 理解 Linux 的平均负载和性能监控","categories":[],"tags":[{"name":"系统优化","slug":"系统优化","permalink":"http://yoursite.com/tags/系统优化/"}]},{"title":"任务安排","slug":"任务安排","date":"2018-12-11T16:00:00.000Z","updated":"2018-10-08T03:02:48.000Z","comments":true,"path":"任务安排/","link":"","permalink":"http://yoursite.com/任务安排/","excerpt":"","text":"前期准备2018/7/9 熟悉数据库设计基本原理，安装数据库开发环境PostgreSQL环境搭建:原理、安装 2018/7/16 熟悉数据库操作基本流程、数据操作命令、编程接口PostgreSQL语法学习：操作教程、命令语法、编程接口 2018/7/23 研究HTML界面开发框架数据库操作以及相关开发语言前端学习：Electron开源库+blur-admin响应式模板学习、安装、介绍、接口 2018/7/30 分析应用场景（场景1：日志分析）数据操作以及数据展示要求，设计数据库表、字段，设计服务程序，创造数据，写入数据库表格创建：应用场景 2018/8/6 应用场景1：日志分析 中展示要求1，2 界面框架数据库查询接口PostgreSQL连接接口（一）：实现 2018/8/13 “自测功能（包括查询性能），并优化数据库表设计。打包，提供测试版以及查询接口”自测功能（一）： 2018/8/20 应用场景1：日志分析 中展示要求3 界面框架数据库查询接口PostgreSQL接口封装（二）：封装 2018/8/27 “自测功能（包括查询性能），并优化数据库表设计。打包，提供测试版、更新查询接口”自测功能（二）： 2018/9/3 配合HTML界面调试全栈调试（一）： 2018/9/10 配合HTML界面调试全栈调试（二）： 2018/9/17 测试、优化测试优化（一）： 2018/9/24 测试、优化测试优化（二）： 第一阶段一周：9.10 表格设计与查询显示服务器管理 从数据表server中获取所有服务器并显示 可筛选查看 日志查询 通过条件从warning中查询日志并显示 多条件查询，时间、消息类型、电厂名称等 一周：9.17 实时警告模块设计与实现实时告警 实时（通过定时器）从数据表warning中获取最新的日志显示 可选择要显示的日志类型、可清空、对日志可以操作状态（已解决、未解决） 根据重要性统计以饼状图显示（紧急、重要、一般）、并以线性图显示趋势（近一周、近一月、近一年） 上面显示图表，下面以列表显示日志 二周：10.1系统运行统计图9.24柱状图设计与显示： 按消息类型统计，以柱状图显示 按操作类型统计，以柱状图显示 10.1饼状图显示与统计： 按电厂属性统计，以饼状图显示 在线统计 按告警级别统计，以饼状图统计 第二阶段10.8 MariaDB数据库学习 10.15 BLurAdmin界面设计 系统时间、 10.22 内核基础4月初-7月初 Linux基本操作 Linux C编程基础： 工具：gcc、gdb c primer plus 源码 c++ primer plus 原理、实验、心得 Unix实践编程 内核代码阅读 多版本源码注释 新旧版本知识点对比-&gt;内核演化 09-12 Linux内核模块编程入门 list.h 分页 进程","categories":[],"tags":[{"name":"安排","slug":"安排","permalink":"http://yoursite.com/tags/安排/"}]},{"title":"IPFS相关操作","slug":"IPFS相关操作","date":"2018-12-06T04:13:29.000Z","updated":"2019-03-06T04:13:40.295Z","comments":true,"path":"IPFS相关操作/","link":"","permalink":"http://yoursite.com/IPFS相关操作/","excerpt":"","text":"Ipfs私有网络搭建 （5个节点）参考 ： https://blog.csdn.net/oscube/article/details/80598790添加peer : ipfs swarm connectipfs bootstrap add /ip4/10.0.1.85/tcp/4001/ipfs/QmZY1MsysE6SyyQUuE1WvkEZEPy5Wg1Z5M7qWyMKGk5EBQ命令： ipfs daemon &amp; ipfs swarm peers ipfs-cluster集群搭建ipfs-cluster-service daemon &amp;ipfs-cluster-service daemon –bootstrap /ip4/10.0.1.85/tcp/9096/ipfs/QmfGrUNtGWBQk36gBMJ3tTW41wGdi6h5BCTCd3hAT8GKEA参考：https://www.cnblogs.com/sumingk/articles/9434253.html Ipfs-cluster 数据同步（1主4从）ipfs-cluster 命令： 1、统一上传文件ipfs-cluster-ctl add &lt;文件名&gt;该命令可统一上传文件，并且自动在其他节点进行pin命令。 2、统一pin文件ipfs-cluster-ctl pin add 3、统一删除文件ipfs-cluster-ctl pin rm但需要在其他节点上手动进行ipfs repo gc 4、查看通过ipfs-cluster-ctl上传过的文件ipfs-cluster-ctl pin ls 5、查看cluster集群中联通了哪些节点ipfs-cluster-ctl peers ls6、从集群中删除某一节点ipfs-cluster-ctl peers rm &lt;节点id（短hash）&gt; 7、可查看集群中文件的同步状态，此命令在某一节点删除文件后有延迟，延迟时间尚不确定ipfs-cluster-ctl status 8、跟踪集群中文件的同步状态，与上面命令不一样，只会显示同步出现异常的文件，并且可以刷新ipfs-cluster-ctl status的执行结果 ipfs-cluster-ctl sync9、查看集群节点关系图 ipfs-cluster-ctl health graph参考：https://blog.csdn.net/weixin_40741642/article/details/82788072 医疗数据私有网络分布式存储ipfs-cluster-ctl add medical_data/ -r added QmZRuAwu5A6feuBBSbyvgeBuukygTjVhQA715KHrAR7D5s medical_data/ECG/MIT/101.xwsadded Qmc7K6A4FLwm8tLnMg49Eo2W8NYc2iiptkpifx6ZcEvMsh medical_data/ECG/MIT/102.atr……added QmUPouSiTr8cE6hCnzZYUpYgeyPArFwNf8NKdca6iSa7xh medical_data api实现文件存取js版：client-api实现数据上传，未完善go版：简单了解 服务器配置关闭firewall：systemctl stop firewalld.service #停止firewallsystemctl disable firewalld.service #禁止firewall开机启动firewall-cmd –state #查看默认防火墙状态（关闭后显示notrunning，开启后显示running）","categories":[],"tags":[{"name":"IPFS","slug":"IPFS","permalink":"http://yoursite.com/tags/IPFS/"}]},{"title":"IPFS相关问题","slug":"IPFS相关问题","date":"2018-12-06T04:08:58.000Z","updated":"2019-03-06T04:09:47.406Z","comments":true,"path":"IPFS相关问题/","link":"","permalink":"http://yoursite.com/IPFS相关问题/","excerpt":"","text":"IPFS网络上同样的文件只有一份吗？是的，IPFS本质上就是为了解决文件过度冗余问题。如果把人们都有的某个文件，做一次hash计算，只字不差的两个文件hash值相同。哪怕改动一个字，都是一个新版本，hash值都不同。只需要使用相同的hash值，就可以访问那个文件，这个hash值就是文件的地址。这个IPFS网络上同样的hash对应的文件只会保存一份。 IPFS系统可靠吗，会造成用户文件的丢失吗？IPFS系统采用了的冗余备份技术是Erasure coding，那么什么是EC？简单讲：n份原始数据，增加m份校验数据，此时可以通过 n+m份数据中的任意n份数据来恢复原始数据，也就是可容忍的最大失效的数据数量为m。例如，如果想容错4个盘，采用n+4模式。传统的 RAID6 允许两个盘失效，对应 EC就是 n+2模式。EC目前在分布式存储上的应用越来越广。 IPFS允许用户指定 f(n, m) 参数n和m，来增加数据存储的安全性，如果想数据存储更加安全，可以采用增加m的方式，当然，这样做所付的费用也就相应的增加，一切取决于用户。 IPFS系统有自动修复存储的功能，如果系统检测到某些数据有丢失，会启动修复，来恢复到原来的n+m模式。IPFS把整个系统的存储统一调度，所以IPFS自带容灾备份功能。 总结： 空间 换 安全 IPFS文件所有权与保密问题文件所有权的问题，如果我上传一个文件是不是可以任意被其它人查看？是的，在IPFS里面并没有文件所有权的问题。IPFS认为，如果其他人同样拥有文件的哈希，那么他一定拥有文件，这跟我们现在的web使用是一致的。 上传的照片如果没有加密，那么默认所有人都可以查看，前提是对方需要拥有文件的哈希值，这跟你使用百度网盘共享后发过去是一样的。如果你存储的文件是不想别人看到的文件，在存入IPFS之前对文件进行加密即可，这样即便是别人拥有了文件哈希，还需要私钥来查查看数据。 IPFS数据同步问题？https://github.com/ipfs/faq/issues/47 ipfs cluster集群管理工具，同份数据各节点共同存储， 加密协议是否可修改开源性决定可修改创建过程中将通过PKI.genKeyPair()(默认用的RSA非对称加密算法)生成一套公钥（n.PubKey）和私钥（n.PrivKey），NodeId 将通过hash(n.PubKey)公钥进行签名。节点分片公共密钥swarm.key，在搭建私有网络时需要 DAG分片这块应该是IPFS内容寻址的设计精髓，当然，IPFS采用Merkle DAG技术对整个系统带来的优点有很多 Merkle DAG拥有如下的功能： 内容寻址：使用多重哈希来唯一识别一个数据块的内容防篡改：可以方便的检查哈希值来确认数据是否被篡改去重：由于内容相同的数据块哈希是相同的，可以很容去掉重复的数据，节省存储空间参考：http://ipfser.org/2018/01/25/r20/ API JS GO Py 数据分片ipfs当前的数据分片是 256k大 参考资料 IPFS的几个关键问题","categories":[],"tags":[{"name":"IPFS","slug":"IPFS","permalink":"http://yoursite.com/tags/IPFS/"}]},{"title":"IPFS环境搭建与入门教程","slug":"IPFS初探","date":"2018-11-22T06:06:29.000Z","updated":"2019-02-22T08:09:55.689Z","comments":true,"path":"IPFS初探/","link":"","permalink":"http://yoursite.com/IPFS初探/","excerpt":"","text":"IPFS简介和基本原理https://www.jianshu.com/p/fe637149e4cfhttps://blog.csdn.net/omnispace/article/details/79698701https://blog.csdn.net/a791693310/article/details/80612676IPFS vs HTTPhttps://www.jianshu.com/p/ddccae89a49a 环境搭建与入门教程参考：https://atangg.com/index.php/2018/07/09/ipfswindows/ 安装：https://docs.ipfs.io/introduction/install/ 上传文件：ipfs add index.html 查看文件： ipfs cat hash_addr eg : ipfs cat QmSiKZ4kXZEdhsQpXaEyXWiEnp2nwmpNuXWkZhhnoXzgSN https://ipfs.io/ipfs/https://localhost:8080/ipfs/ 上传目录：ipfs add -r index.html 查看视频：http://localhost:8080/ipfs/QmfZTpaNwJTx9qEYGNzFvEFdc1T7ieyNeqWDrKD2PgsQPphttp://localhost:8080/ipfs/QmfA1KVT47g8L9fPS3AT9JSAufL6P9pigX6jtnrLFXK6ZE 搭建自己的ipfs私有网络https://blog.csdn.net/oscube/article/details/80598790 添加peer : ipfs swarm connect Linux系统中两种安装go环境的方法https://blog.csdn.net/qq_27278957/article/details/77180365","categories":[],"tags":[{"name":"IPFS","slug":"IPFS","permalink":"http://yoursite.com/tags/IPFS/"}]},{"title":"Go语言初探","slug":"Go语言初探","date":"2018-11-22T06:06:29.000Z","updated":"2019-02-25T03:38:40.467Z","comments":true,"path":"Go语言初探/","link":"","permalink":"http://yoursite.com/Go语言初探/","excerpt":"","text":"Go语言发展Go 是一个开源的编程语言，它能让构造简单、可靠且高效的软件变得容易。 Go是从2007年末由Robert Griesemer, Rob Pike, Ken Thompson主持开发，后来还加入了Ian Lance Taylor, Russ Cox等人，并最终于2009年11月开源，在2012年早些时候发布了Go 1稳定版本。现在Go的开发已经是完全开放的，并且拥有一个活跃的社区。 Go 语言特色简洁、快速、安全 并行、有趣、开源 内存管理、v数组安全、编译迅速 Go语言优缺点Go语言的9大优势和3大缺点 优势 性能 语言性能很重要 开发者效率&amp;不要过于创新 并发性&amp;通道 快速的编译时间 打造团队的能力 强大的生态系统 GOFMT，强制代码格式 gRPC 和 Protocol Buffers 缺点 缺少框架 错误处理 软件包管理 Go 语言用途Go 语言被设计成一门应用于搭载 Web 服务器，存储集群或类似用途的巨型中央服务器的系统编程语言。 对于高性能分布式系统领域而言，Go 语言无疑比大多数其它语言有着更高的开发效率。它提供了海量并行的支持，这对于游戏服务端的开发而言是再好不过了。 参考资料 Go语言开发环境搭建与配置 Go语言完全自学手册（图文教程） gonote","categories":[],"tags":[{"name":"Go","slug":"Go","permalink":"http://yoursite.com/tags/Go/"}]},{"title":"阿里云￥9.5服务器开通管理及使用","slug":"阿里云￥9.5服务器开通管理及使用","date":"2018-11-20T12:54:27.000Z","updated":"2019-02-22T08:12:16.612Z","comments":true,"path":"阿里云￥9.5服务器开通管理及使用/","link":"","permalink":"http://yoursite.com/阿里云￥9.5服务器开通管理及使用/","excerpt":"","text":"一、阿里云账号注册浏览器打开阿里云官网，右上角点击免费注册 二、学生认证1.点击自己图像进入管理控制台 2.完成学生认证 三、云翼计划前往云翼计划，购买云服务器 注：轻量应用服务器较 云服务器ECS 带宽较大，系统盘为SSD,根据需要付款即可 四、服务器管理1.进入服务器控制台轻量应用服务器管理控制台 2.初始化机器及修改密码 3.远程连接远程连接到Linux操作系统实例注：本地远程云服务器可使用SSH，XShell、Secure CRT等软件，文件传输可通过 WinSCP、Filezilla工具或者scp，ftp等命令完成 4.快照备份 注：快照可备份服务器数据，总快照数量上限为已创建实例数乘以3,但最多不超过15个 五、计划任务 测试阿里云服务器内部网络环境 搭建单台服务器ipfs环境(附脚本) 测试ipfs接口参考资料： 学生机（云翼计划）FAQ - 活动 帮助文档（可搜索） 阿里云ECS建网站","categories":[],"tags":[{"name":"教程","slug":"教程","permalink":"http://yoursite.com/tags/教程/"}]},{"title":"浅谈虚拟内存","slug":"浅谈虚拟内存","date":"2018-11-05T13:51:51.000Z","updated":"2019-03-06T03:30:39.859Z","comments":true,"path":"浅谈虚拟内存/","link":"","permalink":"http://yoursite.com/浅谈虚拟内存/","excerpt":"","text":"什么是物理内存？Wiki上的解释为：物理内存是指由于安装内存条而获得的临时储存空间。主要作用是在计算机运行时为操作系统和各种程序提供临时储存。常见的物理内存规格有256M、512M、1G、2G等，当物理内存不足时，可以用虚拟内存代替。 也就是说，物理内存可抽象理解为内存条本身，类似于数组，从0开始编址，物理地址与内存一一相应 那么什么又是虚拟内存呢？现在的操作系统有物理内存和虚拟内存之分，然而在很久之前，是没有虚拟内存概念的，那时，程序寻址用的都是物理地址，众所周知，物理地址大小取决于CPU的地址总线条数。在8086CPU中，地址总线20位，说明物理内存大小为2^20=1M空间，在IA32架构中，寻址范围是2^32也就是4G大小的固定空间，假设一下，如果没有虚拟内存，则每次开启一个进程都给4G的物理内存，就会遇到各种各样的问题？例如：1)进程地址空间不隔离，没有权限保护。由于程序都是直接访问物理内存，所以一个进程可以修改其他进程的内存数据，甚至修改内核地址空间中的数据。2)内存使用效率低物理内存有限，当多个进程执行时，都要给4G内存，当内存空间不足时，要将其他程序暂时拷贝到硬盘，然后将新的程序装入内存运行。由于大量的数据装入装出，内存使用效率会十分低下。3)程序运行的地址不确定因为内存地址是随机分配的，所以程序运行的地址也是不确定的。 为了解决上面这些问题，引出了虚拟内存，此时，每个进程运行时都会得到4G的虚拟内存，每个进程都认为自己拥有4G空间，当然，这只是一厢情愿，实际上，虚拟内存可能只是对应一点点物理内存，实际用了多少内存，就会对应物理内存，也就是按需分配 进程得到的这4G虚拟内存是一个连续的地址空间，这也只是进程一厢情愿的想法，而实际上，它的物理地址是离散的，通常是被分隔成多个物理内存碎片，还有一部分存储在外部磁盘存储器上，在需要时还需使用请页、交换等技术。虚拟内存在wiki上的定义为：虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如RAM）的使用也更有效率。 进程访问一个地址的流程 每次我要访问地址空间上的某一个地址，都需要把地址翻译为实际物理内存地址 所有进程共享这整一块物理内存，每个进程只把自己目前需要的虚拟地址空间映射到物理内存上 进程需要知道哪些地址空间上的数据在物理内存上，哪些不在（可能这部分存储在磁盘上），还有在物理内存上的哪里，这就需要通过页表来记录 页表的每一个表项分两部分，第一部分记录此页是否在物理内存上，第二部分记录物理内存页的地址（如果在的话） 当进程访问某个虚拟地址的时候，就会先去看页表，如果发现对应的数据不在物理内存上，就会发生缺页异常 缺页异常的处理过程，操作系统立即阻塞该进程，并将硬盘里对应的页换入内存，然后使该进程就绪，如果内存已经满了，没有空地方了，那就找一个页覆盖，至于具体覆盖的哪个页，就需要看操作系统的页面置换算法是怎么设计的了。 虚拟内存与物理内存的联系 图中，通过页表建立物理内存和虚拟内存之间的映射关系，页表的工作原理如下图： 我们的cpu想访问虚拟地址所在的虚拟页(VP3)，根据页表，找出页表中第三条的值.判断有效位。 如果有效位为1，DRMA缓存命中，根据物理页号，找到物理页当中的内容，返回。若有效位为0，参数缺页异常，调用内核缺页异常处理程序。内核通过页面置换算法选择一个页面作为被覆盖的页面，将该页的内容刷新到磁盘空间当中。然后把VP3映射的磁盘文件缓存到该物理页上面。然后页表中第三条，有效位变成1，第二部分存储上了可以对应物理内存页的地址的内容。缺页异常处理完毕后，返回中断前的指令，重新执行，此时缓存命中，执行1。将找到的内容映射到告诉缓存当中，CPU从告诉缓存中获取该值，结束。 虚拟内存的工作流程当每个进程创建的时候，内核会为进程分配4G的虚拟内存，当进程还没有开始运行时，这只是一个内存布局。实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射）。这个时候数据和代码还是在磁盘上的。当运行到对应的程序时，进程去寻找页表，发现页表中地址没有存放在物理内存上，而是在磁盘上，于是发生缺页异常，于是将磁盘上的数据拷贝到物理内存中。 另外在进程运行过程中，要通过malloc来动态分配内存时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。 可以认为虚拟空间都被映射到了磁盘空间中（事实上也是按需要映射到磁盘空间上，通过mmap，mmap是用来建立虚拟空间和磁盘空间的映射关系的） 利用虚拟内存机制的优点既然每个进程的内存空间都是一致而且固定的（32位平台下都是4G），所以链接器在链接可执行文件时，可以设定内存地址，而不用去管这些数据最终实际内存地址，这交给内核来完成映射关系当不同的进程使用同一段代码时，比如库文件的代码，在物理内存中可以只存储一份这样的代码，不同进程只要将自己的虚拟内存映射过去就好了，这样可以节省物理内存在程序需要分配连续空间的时候，只需要在虚拟内存分配连续空间，而不需要物理内存时连续的，实际上，往往物理内存都是断断续续的内存碎片。这样就可以有效地利用我们的物理内存","categories":[],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"http://yoursite.com/tags/Kernel/"}]},{"title":"","slug":"开源大学","date":"2018-11-03T05:02:48.000Z","updated":"2018-10-01T23:29:08.000Z","comments":true,"path":"开源大学/","link":"","permalink":"http://yoursite.com/开源大学/","excerpt":"","text":"开源大学","categories":[],"tags":[]},{"title":"","slug":"第一阶段计划表","date":"2018-11-03T05:02:48.000Z","updated":"2018-10-08T00:35:10.000Z","comments":true,"path":"第一阶段计划表/","link":"","permalink":"http://yoursite.com/第一阶段计划表/","excerpt":"","text":"一周：9.10服务器管理 从数据表server中获取所有服务器并显示 可筛选查看 日志查询 通过条件从warning中查询日志并显示 多条件查询，时间、消息类型、电厂名称等 一周：9.17实时告警 实时（通过定时器）从数据表warning中获取最新的日志显示 可选择要显示的日志类型、可清空、对日志可以操作状态（已解决、未解决） 根据重要性统计以饼状图显示（紧急、重要、一般）、并以线性图显示趋势（近一周、近一月、近一年） 上面显示图表，下面以列表显示日志 二周：10.1系统运行统计图 按消息类型统计，以柱状图显示 按操作类型统计，以柱状图显示 按电厂属性统计，以饼状图显示 在线统计 按告警级别统计，以饼状图统计 第二阶段","categories":[],"tags":[]},{"title":"","slug":"编译和链接","date":"2018-11-03T05:02:48.000Z","updated":"2018-08-28T22:29:22.000Z","comments":true,"path":"编译和链接/","link":"","permalink":"http://yoursite.com/编译和链接/","excerpt":"","text":"第一章 编译和链接C语言是我们熟悉的一门语言，当我们编辑了一个C程序，然后再编译和链接，形成可执行文件在操作系统下执行时，我们是否会发出以下疑问： C语言代码为什么要编译后才能执行？整个过程中编译器都做了什么？ C代码中经常会包含头文件，那么，什么是头文件？什么又是C语言库？ 我们经常说main函数是C语言程序的入口，难道不能把其它函数当入口？ 不同的操作系统上编译好的程序可以直接拷贝过去运行吗？ 如果上面的问题你都能回答的话，那么就可以跳过本节。如果你不知道或者不是很清楚，那么我们就顺着这个思路探究下去。 1. C语言代码为什么要编译后才能执行？整个过程中编译器都做了什么？我们以最经典的HelloWorld程序为例。先使用vim等文本编辑器写好代码，接着在终端执行编译命令（使用的Linux系统是Debian）： gcc HelloWorld.c -o HelloWorld 这条命令在编译的同时进行了链接，形成了可执行文件HelloWorld，最后我们在终端执行 ./HelloWorld，顺利地显示了输出结果。 debian@bogon:~/Documents/HelloWorld$ vim HelloWorld.c debian@bogon:~/Documents/HelloWorld$ gcc HelloWorld.c -o HelloWorld debian@bogon:~/Documents/HelloWorld$ ./HelloWorld Hello World! debian@bogon:~/Documents/HelloWorld$ 可是，简单的命令背后经过了什么样的处理过程？gcc真的就“直接”生成了最后的可执行文件了？当然不是，我们在gcc编译命令行加上参数 –verbose要求gcc输出完整的处理过程(命令行加上 -v 也行)，我们看到了一段较长的过程输出。 debian@bogon:~/Documents/HelloWorld$ gcc --verbose HelloWorld.c -o HelloWorld Using built-in specs. COLLECT_GCC=gcc COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/6/lto-wrapper Target: x86_64-linux-gnu Configured with: ../src/configure -v --with-pkgversion=&apos;Debian 6.3.0-18+deb9u1&apos; --with-bugurl=file:///usr/share/doc/gcc-6/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-6 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --enable-default-pie --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-6-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-6-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-6-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --with-target-system-zlib --enable-objc-gc=auto --enable-multiarch --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu Thread model: posix gcc version 6.3.0 20170516 (Debian 6.3.0-18+deb9u1) COLLECT_GCC_OPTIONS=&apos;-v&apos; &apos;-o&apos; &apos;HelloWorld&apos; &apos;-mtune=generic&apos; &apos;-march=x86-64&apos; /usr/lib/gcc/x86_64-linux-gnu/6/cc1 -quiet -v -imultiarch x86_64-linux-gnu HelloWorld.c -quiet -dumpbase HelloWorld.c -mtune=generic -march=x86-64 -auxbase HelloWorld -version -o /tmp/ccKizfOU.s GNU C11 (Debian 6.3.0-18+deb9u1) version 6.3.0 20170516 (x86_64-linux-gnu) compiled by GNU C version 6.3.0 20170516, GMP version 6.1.2, MPFR version 3.1.5, MPC version 1.0.3, isl version 0.15 GGC heuristics: --param ggc-min-expand=62 --param ggc-min-heapsize=60678 ignoring nonexistent directory &quot;/usr/local/include/x86_64-linux-gnu&quot; ignoring nonexistent directory &quot;/usr/lib/gcc/x86_64-linux-gnu/6/../../../../x86_64-linux-gnu/include&quot; #include &quot;...&quot; search starts here: #include &lt;...&gt; search starts here: /usr/lib/gcc/x86_64-linux-gnu/6/include /usr/local/include /usr/lib/gcc/x86_64-linux-gnu/6/include-fixed /usr/include/x86_64-linux-gnu /usr/include End of search list. GNU C11 (Debian 6.3.0-18+deb9u1) version 6.3.0 20170516 (x86_64-linux-gnu) compiled by GNU C version 6.3.0 20170516, GMP version 6.1.2, MPFR version 3.1.5, MPC version 1.0.3, isl version 0.15 GGC heuristics: --param ggc-min-expand=62 --param ggc-min-heapsize=60678 Compiler executable checksum: b8e5d7f3c4236757ee0871869b8330f3 COLLECT_GCC_OPTIONS=&apos;-v&apos; &apos;-o&apos; &apos;HelloWorld&apos; &apos;-mtune=generic&apos; &apos;-march=x86-64&apos; as -v --64 -o /tmp/ccyb9gCU.o /tmp/ccKizfOU.s GNU assembler version 2.28 (x86_64-linux-gnu) using BFD version (GNU Binutils for Debian) 2.28 COMPILER_PATH=/usr/lib/gcc/x86_64-linux-gnu/6/:/usr/lib/gcc/x86_64-linux-gnu/6/:/usr/lib/gcc/x86_64-linux-gnu/:/usr/lib/gcc/x86_64-linux-gnu/6/:/usr/lib/gcc/x86_64-linux-gnu/ LIBRARY_PATH=/usr/lib/gcc/x86_64-linux-gnu/6/:/usr/lib/gcc/x86_64-linux-gnu/6/../../../x86_64-linux-gnu/:/usr/lib/gcc/x86_64-linux-gnu/6/../../../../lib/:/lib/x86_64-linux-gnu/:/lib/../lib/:/usr/lib/x86_64-linux-gnu/:/usr/lib/../lib/:/usr/lib/gcc/x86_64-linux-gnu/6/../../../:/lib/:/usr/lib/ COLLECT_GCC_OPTIONS=&apos;-v&apos; &apos;-o&apos; &apos;HelloWorld&apos; &apos;-mtune=generic&apos; &apos;-march=x86-64&apos; /usr/lib/gcc/x86_64-linux-gnu/6/collect2 -plugin /usr/lib/gcc/x86_64-linux-gnu/6/liblto_plugin.so -plugin-opt=/usr/lib/gcc/x86_64-linux-gnu/6/lto-wrapper -plugin-opt=-fresolution=/tmp/ccj2W1uU.res -plugin-opt=-pass-through=-lgcc -plugin-opt=-pass-through=-lgcc_s -plugin-opt=-pass-through=-lc -plugin-opt=-pass-through=-lgcc -plugin-opt=-pass-through=-lgcc_s --sysroot=/ --build-id --eh-frame-hdr -m elf_x86_64 --hash-style=gnu -dynamic-linker /lib64/ld-linux-x86-64.so.2 -pie -o HelloWorld /usr/lib/gcc/x86_64-linux-gnu/6/../../../x86_64-linux-gnu/Scrt1.o /usr/lib/gcc/x86_64-linux-gnu/6/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/6/crtbeginS.o -L/usr/lib/gcc/x86_64-linux-gnu/6 -L/usr/lib/gcc/x86_64-linux-gnu/6/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/6/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/lib/gcc/x86_64-linux-gnu/6/../../.. /tmp/ccyb9gCU.o -lgcc --as-needed -lgcc_s --no-as-needed -lc -lgcc --as-needed -lgcc_s --no-as-needed /usr/lib/gcc/x86_64-linux-gnu/6/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/6/../../../x86_64-linux-gnu/crtn.o COLLECT_GCC_OPTIONS=&apos;-v&apos; &apos;-o&apos; &apos;HelloWorld&apos; &apos;-mtune=generic&apos; &apos;-march=x86-64&apos; debian@bogon:~/Documents/HelloWorld$ 在此，我们不截取输出结果的完整图了，但你可以自己试验，然后试着分析整个流程。 图1是gcc编译过程的分解图： 从图中我们大致可以看出gcc处理HelloWorld.c的大致过程： 预处理(Prepressing)—&gt;编译(Compilation)—&gt;汇编(Assembly)—&gt;链接(Linking) 括号中注明了各个过程中实际执行任务的程序名称：预处理器cpp、编译器cc1、汇编器as以及最后的链接器ld。 2. 预处理到底做什么？我们在终端输入命令 gcc -E HelloWorld.c -o HelloWorld.i，然后打开输出文件HelloWorld.i： # 1 &quot;/usr/include/x86_64-linux-gnu/bits/wordsize.h&quot; 1 3 4 # 28 &quot;/usr/include/x86_64-linux-gnu/bits/types.h&quot; 2 3 4 typedef unsigned char __u_char; typedef unsigned short int __u_short; typedef unsigned int __u_int; typedef unsigned long int __u_long; 首先是大段的变量和函数的声明，我们的代码找不到了，到底去哪了？在vim编辑环境的普通模式中按下shift+g(大写G)跳到文件的底部，终于在几千行以后看到了我们可怜兮兮的几行代码。 int main(){ printf(&quot;Hello World!\\n&quot;); return 0; } 前面几千行代码是做什么的？其实它就是 /usr/include/stdio.h 文件的所有内容，预处理器把所有的#include替换为实际文件的内容了。这个过程是递归进行的，所以stdio.h里面的#include也被实际内容所替换了。 而且我在HelloWorld.c里面的所有注释被预处理器全部删除了。就连printf语句前的Tab缩进也被替换为一个空格了，显得代码都不美观了。 通过观察这些内容，我们梳理出预处理器处理的大致所做的事情： 展开所有的宏定义并删除 #define 处理所有的条件编译指令，例如 #if #else #endif #ifndef … 把所有的 #include 替换为头文件实际内容，递归进行 把所有的注释 // 和 / / 替换为空格 添加行号和文件名标识以供编译器使用 保留所有的 #pragma 指令，因为编译器要使用 基本上就是这些内容。（在这里顺便插播一个小技巧，在代码中有时候宏定义比较复杂的时候我们很难判断其处理后的结构是否正确。这个时候我们就可以使用gcc的-E参数输出处理结果来判断） 前文中我们提到头文件中存放的是变量定义和函数声明等等内容。这些内容到底是什么？其实在早期调用函数时并不需要声明，后来因为“笔误”之类的错误实在太多，造成了链接期间的错误过多，所有编译器开始要求对所有使用的变量或者函数给出声明，以支持编译器进行参数检查和类型匹配。头文件包含的基本上就是这些东西和一些预先的宏定义来方便程序员编程。其实对于我们的HelloWorld.c程序来说不需要这个庞大的头文件，只需要在main函数前声明printf函数，不需要#include即可通过编译。 声明如下： int printf(const char *format, ...); 大家可以自行测试。另外再补充一点，gcc其实并不要求函数一定要在被调用之前定义或者声明，因为gcc在处理到某个未知类型的函数时，会为其创建一个隐式声明，并假设该函数返回值类型为int。但gcc此时无法检查传递给该函数的实参类型和个数是否正确，不利于编译器为我们排除错误（而且如果该函数的返回值不是int的话也会出错）。所以还是建议大家在函数调用前，先对其定义或声明。 3. 编译做什么？了解了预处理之后，我们接着看编译和汇编。什么是编译？一句话描述：编译就是把预处理之后的文件进行一系列词法分析、语法分析、语义分析以及优化后生成的相应汇编代码文件。 怎么查看编译后的汇编代码？命令： gcc -S HelloWorld.c -o HelloWorld.s 这样输出了汇编代码文件HelloWorld.s，其实输出的文件名可以随意。顺便说一句，这里生成的汇编是AT&amp;T风格的汇编代码，如果大家更熟悉Intel风格，可以在命令行加上参数 -masm=intel ,这样gcc就会生成Intel风格的汇编代码了（如图）。不过gcc的内联汇编只支持AT&amp;T风格，我们在第二章会给予介绍。 .file &quot;HelloWorld.c&quot; .intel_syntax noprefix .section .rodata .LC0: .string &quot;Hello World!&quot; .text .globl main .type main, @function main: .LFB0: .cfi_startproc push rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 mov rbp, rsp .cfi_def_cfa_register 6 lea rdi, .LC0[rip] call puts@PLT mov eax, 0 pop rbp .cfi_def_cfa 7, 8 ret .cfi_endproc .LFE0: .size main, .-main .ident &quot;GCC: (Debian 6.3.0-18+deb9u1) 6.3.0 20170516&quot; .section .note.GNU-stack,&quot;&quot;,@progbits 4. 汇编做什么？我们继续用一句话来描述：汇编就是将编译后的汇编代码翻译为机器码，几乎每一条汇编指令对应一句机器码。 命令： gcc -c HelloWorld.c 可以让编译器只进行到生成目标文件这一步，这样我们就能在目录下看到HelloWorld.o文件了。 Linux下的可执行文件以及目标文件的格式叫作ELF(Executable Linkable Format)。其实Windows下的PE(Portable Executable)也好，Linux下的ELF也罢，都是COFF(Common file format)格式的一种变种，甚至Windows下的目标文件就是以COFF格式去存储的。不同的操作系统之间的可执行文件的格式通常是不一样的，所以造成了编译好的HelloWorld没有办法直接复制执行，而需要在相关平台上重新编译。当然了，不能运行的原因不只是这一点，不同的操作系统接口（windows API和Linux的API不同）以及相关的类库不同也是原因之一。 更详细的内容可以参看《程序员的自我修养》了解。 5. 链接做什么？这一步是将汇编产生的目标文件和所使用的库函数的目标文件链接生成一个可执行文件的过程。在这里稍微的扩展一下篇幅，稍微详细的说一说链接，一是链接造成的错误通常难以理解和处理，二是在开发中使用第三方库越来越常见了，大家可能更需要稍微了解一些细节。 首先介绍一下gnu binutils工具包，这是一整套的二进制分析处理工具包。详细介绍请大家参考维基百科：http://zh.wikipedia.org/wiki/GNU_Binutils 一般系统安装包中都带了这套工具包，如果你的发行版没有，请自行搜索进行安装。 这套工具包含了足够多的工具，我们甚至可以用来研究ELF文件的格式等内容。不过本节只是抛砖引玉，更多的使用方法和技巧还是需要大家自己去学习和研究。 链接这个话题涉及的内容相当广泛，为了避免本节牵扯到过多的话题导致言之泛泛，我们先设定本节讨论的范围。在这里只讨论链接进行的大致步骤及其规则、静态链接库与动态链接库的创建和使用这两大问题。至于可执行文件的加载、可执行文件的运行时储存器映像之类的内容我们暂时不讨论。那么，什么是链接？我们引用《深入理解计算机系统》中的定义：链接（linking）是将各种代码和数据部分收集起来并组合成为一个单一文件的过程，这个文件可被加载（或被拷贝）到存储器并执行。 需要强调的是，链接可以执行于编译时（compile time），也就是在源代码被翻译成机器代码时；也可以执行于加载时，也就是在程序被加载器（loader）加载到存储器并执行时；甚至执行于运行时（run time），由应用程序来执行。 那么，了解链接到底有什么用？继续引用《深入理解计算机系统》的说法，如下： 理解链接器将帮助你构造大型程序。 理解链接器将帮助你避免一些危险的编程错误。 理解链接将帮助你理解语言的作用域是如何实现的。 理解链接将帮助你理解其他重要的系统概念。 理解链接将使你能够利用共享库。 言归正传。为了避免我们的描述过于枯燥，我们还是以C语言为例。大家通过我们前面的描述，已经知道C代码编译后的目标文件了。目标文件最终要和标准库进行链接生成最后的可执行文件。那么，标准库和我们生成的目标文件是什么关系？ 其实，任何一个程序，它的背后都有一套庞大的代码在支撑着它，以使得该程序能够正常运行。这套代码至少包括入口函数、以及其所依赖的函数构成的函数集合。当然，它还包含了各种标准库函数的实现。 这个“支撑模块”就叫做运行时库（Runtime Library）。而C语言的运行库，即被称为C运行时库（CRT）。 CRT大致包括：启动与退出相关的代码（包括入口函数及入口函数所依赖的其他函数）、标准库函数（ANSI C标准规定的函数实现）、I/O相关、堆的封装实现、语言特殊功能的实现以及调试相关。其中标准库函数的实现占据了主要地位。标准库函数比如我们平时常用的printf，scanf函数等。C语言标准库在不同的平台上实现了不同的版本，我们只要依赖其接口定义，就能保证程序在不同平台上的一致行为。C语言标准库有24个，囊括标准输入输出、文件操作、字符串操作、数学函数以及日期等等内容。大家有兴趣的可以自行搜索。 5.1 静态链接库既然C语言提供了标准库函数供我们使用，那么以什么形式提供？是源代码吗？当然不是。下面引入静态链接库的概念。我们几乎每一次写程序都难免去使用库函数，那么每一次去编译岂不是太麻烦了。干嘛不把标准库函数提前编译好，需要的时候直接链接？是的，标准库就是这么做的。那么，标准库以什么形式存在？是一个目标文件？我们知道，链接的最小单位就是一个个目标文件，如果我们只用到一个printf函数，但需要和整个库链接的话岂不是太浪费资源了么？但是，如果把库函数分别定义在彼此独立的代码文件中，这样编译出后就形成一大堆目标文件。所以，编辑器系统提供了一种机制，将所有的编译出来的目标文件打包成一个单独的文件，叫做静态库（static library）。当链接器和静态库链接的时候，链接器会从这个打包的文件中“解压缩”出需要的部分目标文件进行链接。这样就解决了资源浪费的问题。 Linux/Unix系统下ANSI C的库名叫做libc.a，另外数学函数单独在libm.a库中。当了解以上相关知识后，我们试着自己做一个静态库。为了简单起见我们就做一个只有两个函数的私有库。 在swap.c里定义一个swap函数，在add.c里定义了一个add函数。最后还有含有它们声明的calc.h头文件。 // swap.c void swap(int *num1, int *num2) { int tmp = *num1; *num1 = *num2; *num2 = tmp; } // add.c int add(int a, int b) { return a + b; } // calc.h #ifndef CALC_H_ #define CALC_H_ #ifdef _cplusplus extern &quot;C&quot; { #endif void swap(int *, int *); int add(int, int); #ifdef _cplusplus } #endif #endif // CALC_H_ 我们分别编译它们得到了swap.o和add.o这两个目标文件，最后使用ar命令将其打包为一个静态库。 debian@bogon:~/Documents/link$ gcc add.c -c -o add.o debian@bogon:~/Documents/link$ gcc swap.c -c -o swap.o debian@bogon:~/Documents/link$ ls add.c add.o calc.h swap.c swap.o debian@bogon:~/Documents/link$ ar rcs libcalc.a swap.o add.o debian@bogon:~/Documents/link$ ls add.c add.o calc.h libcalc.a swap.c swap.o debian@bogon:~/Documents/link$ 现在我们怎么使用这个静态库呢？我们写一个test.c使用这个库中的swap函数。代码如下： #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &quot;calc.h&quot; int main(int argc, char *argv[]) { int a = 1, b = 2; swap(&amp;a, &amp;b); printf(&quot;%d %d\\n&quot;, a, b); return EXIT_SUCCESS; } 下来是编译执行，命令行执行gcc test.c ./libcalc.a -o test编译，执行。如图，我们输出了预期的结果。 debian@bogon:~/Documents/link$ gcc test.c ./libcalc.a -o test debian@bogon:~/Documents/link$ ./test 2 1 debian@bogon:~/Documents/link$ 可能你会问，我们使用C语言标准库的时候，编译时并不需要加库名。是的，的确不需要，那是因为标准库已经是标准了，所以会被默认链接。不过因为数学函数库libm.a没有默认链接，所以我们使用了数学函数的代码在编译时需要在命令行指定 -lm 链接（-l是指定链接库，m是去掉lib之后的库名），不过现在好多gcc都默认链接libm.c库了。 正如我们所看到的，静态链接库解决了一些问题，但是它同时带来了另一些问题。比如说每一个使用了相同的C标准函数的程序都需要和相关目标文件进行链接，浪费磁盘空间；当一个程序有多个副本执行时，相同的库代码部分被载入内存，浪费内存；当库代码更新之后，使用这些库的函数必须全部重新编译等等。 5.2 动态链接库是否有更好的办法？当然有。我们接下来引入动态链接库/共享库（shared library）。 动态链接库/共享库是一个目标模块，在运行时可以加载到任意的存储器地址，并和一个正在运行的程序链接起来。这个过程就是动态链接（dynamic linking），是由一个叫做动态链接器（dynamic linker）的程序完成的。 Unix/Linux中共享库的后缀名通常是.so（微软就是DLL文件）。那么，如何建立一个动态链接库？ 我们还是以上面的代码为例，首先删除之前的静态库和目标文件。要建立动态链接库，在命令行输入： gcc swap.c add.c -shared -o libcalc.so 顺便说一下，最好在gcc命令行加上一句-fPIC让其生成与位置无关的代码（PIC），具体原因超出本文范围，故暂不予讨论。 debian@bogon:~/Documents/link$ gcc swap.c add.c -shared -o libcalc.so debian@bogon:~/Documents/link$ ls add.c add.o calc.h libcalc.a libcalc.so swap.c swap.o test test.c debian@bogon:~/Documents/link$ 如何使用动态链接库？我们继续编译测试代码，执行gcc test.c -o test ./libcalc.so即可。运行后我们仍旧得到了预期的结果。 debian@bogon:~/Documents/link$ gcc test.c -o test ./libcalc.so debian@bogon:~/Documents/link$ ./test 2 1 debian@bogon:~/Documents/link$ 这看起来也没什么不一样的。其实不然，我们用ldd命令（ldd是我们推荐的GNU binutils工具包的组成之一）检查test文件的依赖。 debian@bogon:~/Documents/link$ ldd ./test linux-vdso.so.1 (0x00007fff3d3fb000) ./libcalc.so (0x00007f61c97de000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f61c943f000) /lib64/ld-linux-x86-64.so.2 (0x00007f61c9be2000) debian@bogon:~/Documents/link$ 我们看到这个文件能顺利运行需要依赖libcalc.so这个动态库，我们还能看到C语言的标准库默认也是动态链接的（在gcc编译的命令行加上 -static 可以要求静态链接）。 好处何在？第一，库更新之后，只需要替换掉动态库文件即可，无需编译所有依赖库的可执行文件。第二，程序有多个副本执行时，内存中只需要一份库代码，节省空间。 大家想想，C语言标准库好多程序都在用，但内存只有一份代码，这样节省的空间就相当可观了，而且假如库代码发现bug，只需要更新libc.so即可，所有程序即可使用新的代码，代码的可维护性提高。 关于库的内容还很多，就此介绍到这里。 5.3 链接的步骤我们来看看链接过程中具体做的事情。链接的步骤大致包括了地址和空间分配（Address and Storage Allocation）、符号决议（Symbol Resolution）和重定位（Relocation）等主要步骤。 首先是地址和空间分配，我们之前提到的目标文件其实全称叫做可重定位目标文件（这只是一种名称，还有其他名称）。目标文件的格式已经无限度接近可执行文件了，Unix/Linux下的目标文件的格式叫做ELF（Executable and Linkable Format，可执行连接格式）。本节暂不详细讨论可执行文件的格式，我们只需要知道可执行文件中代码，数据，符号等内容分别存储在不同的段中就可以，这也和第二章保护模式下的内存分段是有一定关系的。我们简单叙述了地址和空间分配以及重定位，但是稍微详细说明一下符号决议。 什么是符号（symbol）？简单说我们在代码中定义的函数和变量可以统称为符号。符号名（symbol name）就是函数名和变量名了。 目标文件的拼合其实也就是对目标文件之间相互的符号引用的一个修正。我们知道一个C语言代码文件只要所有的符号被声明过就可以通过编译了，可是对某符号的引用怎么知道位置呢？比如我们调用了printf函数，编译时留下了要填入的函数地址，那么printf函数的实际地址在哪里？这个空位什么时候修正呢？当然是链接的时候，重定位那一步就是做这个的。但是在修改地址之前需要做符号决议，那什么是符号决议？正如前文所说，编译期间留下了很多需要重新定位的符号，所以目标文件中会有一块区域专门保存符号表。链接器如何知道具体位置？其实链接器并不知道，所以链接器会搜索全部的待链接的目标文件，寻找这个符号的位置，然后修正每一个符号的地址。 在此我们要重点介绍一下在编译程序时几乎所有人会遇见的问题——符号查找问题。在编译时通常会碰到两种编译错误，即找不到某符号或者符号重定义。 首先介绍找不到符号的情况，比如，当我们声明了一个swap函数却没有定义它的时候，我们调用这个函数的代码可以通过编译，但是在链接期间却会遇到错误。形如“test.c:(.text+0x29): undefined reference to ‘swap’”这样，特别的，MSVC编译器报错是找不到符号_swap。这个下划线从哪里来的？这得从C语言刚诞生说起。当C语言刚面世的时候，已经存在不少用汇编语言写好的库了，因为链接器的符号唯一规则，假如该库中存在main函数，我们就不能在C代码中出现main函数了，因为会遭遇符号重定义错误，倘若放弃这些库又是一大损失。所以当时的编译器会对代码中的符号进行修饰（name decoration），C语言的代码会在符号前加下划线，fortran语言在符号前后都加下划线，这样各个目标文件就不会同名了，就解决了符号冲突的问题。随着时间的流逝，操作系统和编译器都被重写了好多遍，当前的这个问题已经可以忽略。所以新版的gcc一般不会再加下划线做符号修饰（也可以在编译的命令行加上-fleading-underscore/-fno-fleading-underscore开打开/关闭这个是否加下划线）。而MSVC依旧保留了这个传统，所以我们可以看到_swap这样的修饰。 顺便说一下，符号冲突是很常见的事情，特别是在大型项目的开发中，所以我们需要一个约定良好的命名规则。C++也引入了命名空间来帮助我们解决这些问题，因为C++中存在函数重载，所以C++的符号修饰更加复杂难懂（Linux下有c++filt命令帮助我们翻译一个被C++编译器修饰过的符号）。 那么，当出现同名符号时链接器到底如何处理。刚才说过会报告重名错误，为什么还要进行探讨？实际上，不仅仅这么简单。在编译时，编译器会向汇编器输出每个全局符号，分为强（strong）符号和弱符号（weak），汇编器把这个信息隐含的编码在可重定位目标文件的符号表里。其中函数和已初始化过的全局变量是强符号，未初始化的全局变量是弱符号。根据强弱符号的定义，GNU链接器采用的规则如下： 不允许多个强符号 如果有一个强符号和一个或多个弱符号，则选择强符号 如果有多个弱符号，则随机选择一个 其中，第一条会报符号重名错误的，而后两条默认情况下甚至连警告都不会有。关键就在这里，默认甚至连警告都没有。 我们来个实验具体说一下： // link1.c #include &lt;stdio.h&gt; int n; int main(int argc, char *argv[]) { printf(&quot;It is %d\\n&quot;, n); return 0; } // link2.c int n = 5; 这两个文件编译运行会输出什么呢？想必你已经知道了结果，没错，就是5 debian@bogon:~/Documents/link$ vim link1.c debian@bogon:~/Documents/link$ vim link2.c debian@bogon:~/Documents/link$ gcc link1.c link2.c -o link debian@bogon:~/Documents/link$ ./link It is 5 debian@bogon:~/Documents/link$ 初始化过的n是强符号，被优先选择了。但是，在很复杂的项目代码中，这样的错误很难发现，特别是多线程的代码，不过当我们怀疑代码中的bug可能是因为此原因引起的时候，我们可以在gcc命令行加上-fno-common这个参数，这样链接器在遇到多重定义的符号时，都会给出一条警告信息，而无关强弱符号。如下所示： debian@bogon:~/Documents/link$ gcc link1.c link2.c -o link -fno-common /tmp/ccJnlWp9.o:(.data+0x0): multiple definition of `n&apos; /tmp/ccM5uYLR.o:(.bss+0x0): first defined here collect2: error: ld returned 1 exit status debian@bogon:~/Documents/link$","categories":[],"tags":[]},{"title":"","slug":"编译、链接与装载","date":"2018-11-03T05:02:48.000Z","updated":"2018-09-02T02:31:50.000Z","comments":true,"path":"编译、链接与装载/","link":"","permalink":"http://yoursite.com/编译、链接与装载/","excerpt":"","text":"第一章 编译、链接与装载C语言是我们熟悉的一门语言，当我们编辑了一个C程序，然后再编译和链接，形成可执行文件在操作系统下执行时，我们是否会发出以下疑问： C语言代码为什么要编译后才能执行？整个过程中编译器都做了什么？ C代码中经常会包含头文件，那么，什么是头文件？什么又是C语言库？ 我们经常说main函数是C语言程序的入口，难道不能把其它函数当入口？ 不同的操作系统上编译好的程序可以直接拷贝过去运行吗？ 如果上面的问题你都能回答的话，那么就可以跳过本节。如果你不知道或者不是很清楚，那么我们就顺着这个思路探究下去。 1. C语言代码为什么要编译后才能执行？整个过程中编译器都做了什么？我们以最经典的HelloWorld程序为例。先使用vim等文本编辑器写好代码，接着在终端执行编译命令（使用的Linux系统是Debian）： gcc HelloWorld.c -o HelloWorld 这条命令在编译的同时进行了链接，形成了可执行文件HelloWorld，最后我们在终端执行 ./HelloWorld，顺利地显示了输出结果。 debian@bogon:~$ vim HelloWorld.c debian@bogon:~$ gcc HelloWorld.c -o HelloWorld debian@bogon:~$ ./HelloWorld Hello World! debian@bogon:~$ 可是，简单的命令背后经过了什么样的处理过程？gcc真的就“直接”生成了最后的可执行文件了？当然不是，我们在gcc编译命令行加上参数 –verbose要求gcc输出完整的处理过程(命令行加上 -v 也行)，我们看到了一段较长的过程输出。 debian@bogon:~$ gcc --verbose HelloWorld.c -o HelloWorld Using built-in specs. COLLECT_GCC=gcc COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/6/lto-wrapper Target: x86_64-linux-gnu Configured with: ../src/configure -v --with-pkgversion=&apos;Debian 6.3.0-18+deb9u1&apos; ...... 在此，我们不截取输出结果的完整图了，但你可以自己试验，然后试着分析整个流程。 图1是gcc编译过程的分解图： 从图中我们大致可以看出gcc处理HelloWorld.c的大致过程： 预处理(Prepressing)—&gt;编译(Compilation)—&gt;汇编(Assembly)—&gt;链接(Linking) 括号中注明了各个过程中实际执行任务的程序名称：预处理器cpp、编译器cc1、汇编器as以及最后的链接器ld。 2. 预处理到底做什么？我们在终端输入命令 gcc -E HelloWorld.c -o HelloWorld.i，然后打开输出文件HelloWorld.i： # 1 &quot;/usr/include/x86_64-linux-gnu/bits/wordsize.h&quot; 1 3 4 # 28 &quot;/usr/include/x86_64-linux-gnu/bits/types.h&quot; 2 3 4 typedef unsigned char __u_char; typedef unsigned short int __u_short; typedef unsigned int __u_int; typedef unsigned long int __u_long; 首先是大段的变量和函数的声明，我们的代码找不到了，到底去哪了？在vim编辑环境的普通模式中按下shift+g(大写G)跳到文件的底部，终于在几千行以后看到了我们可怜兮兮的几行代码。 int main(){ printf(&quot;Hello World!\\n&quot;); return 0; } 前面几千行代码是做什么的？其实它就是 /usr/include/stdio.h 文件的所有内容，预处理器把所有的#include替换为实际文件的内容了。这个过程是递归进行的，所以stdio.h里面的#include也被实际内容所替换了。 而且我在HelloWorld.c里面的所有注释被预处理器全部删除了。就连printf语句前的Tab缩进也被替换为一个空格了，显得代码都不美观了。 通过观察这些内容，我们梳理出预处理器处理的大致所做的事情： 展开所有的宏定义并删除 #define 处理所有的条件编译指令，例如 #if #else #endif #ifndef … 把所有的 #include 替换为头文件实际内容，递归进行 把所有的注释 // 和 / / 替换为空格 添加行号和文件名标识以供编译器使用 保留所有的 #pragma 指令，因为编译器要使用 基本上就是这些内容。（在这里顺便插播一个小技巧，在代码中有时候宏定义比较复杂的时候我们很难判断其处理后的结构是否正确。这个时候我们就可以使用gcc的-E参数输出处理结果来判断） 前文中我们提到头文件中存放的是变量定义和函数声明等等内容。这些内容到底是什么？其实在早期调用函数时并不需要声明，后来因为“笔误”之类的错误实在太多，造成了链接期间的错误过多，所有编译器开始要求对所有使用的变量或者函数给出声明，以支持编译器进行参数检查和类型匹配。头文件包含的基本上就是这些东西和一些预先的宏定义来方便程序员编程。其实对于我们的HelloWorld.c程序来说不需要这个庞大的头文件，只需要在main函数前声明printf函数，不需要#include即可通过编译。 声明如下： int printf(const char *format, ...); 大家可以自行测试。另外再补充一点，gcc其实并不要求函数一定要在被调用之前定义或者声明，因为gcc在处理到某个未知类型的函数时，会为其创建一个隐式声明，并假设该函数返回值类型为int。但gcc此时无法检查传递给该函数的实参类型和个数是否正确，不利于编译器为我们排除错误（而且如果该函数的返回值不是int的话也会出错）。所以还是建议大家在函数调用前，先对其定义或声明。 3. 编译做什么？了解了预处理之后，我们接着看编译和汇编。什么是编译？一句话描述：编译就是把预处理之后的文件进行一系列词法分析、语法分析、语义分析以及优化后生成的相应汇编代码文件。 怎么查看编译后的汇编代码？命令： gcc -S HelloWorld.c -o HelloWorld.s 这样输出了汇编代码文件HelloWorld.s，其实输出的文件名可以随意。顺便说一句，这里生成的汇编是AT&amp;T风格的汇编代码，如果大家更熟悉Intel风格，可以在命令行加上参数 -masm=intel ,这样gcc就会生成Intel风格的汇编代码了（如图）。不过gcc的内联汇编只支持AT&amp;T风格，我们在第二章会给予介绍。 .file &quot;HelloWorld.c&quot; .intel_syntax noprefix .section .rodata .LC0: .string &quot;Hello World!&quot; .text .globl main .type main, @function main: .LFB0: .cfi_startproc push rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 mov rbp, rsp .cfi_def_cfa_register 6 lea rdi, .LC0[rip] call puts@PLT mov eax, 0 pop rbp .cfi_def_cfa 7, 8 ret .cfi_endproc .LFE0: .size main, .-main .ident &quot;GCC: (Debian 6.3.0-18+deb9u1) 6.3.0 20170516&quot; .section .note.GNU-stack,&quot;&quot;,@progbits 4. 汇编做什么？我们继续用一句话来描述：汇编就是将编译后的汇编代码翻译为机器码，几乎每一条汇编指令对应一句机器码。 命令： gcc -c HelloWorld.c 可以让编译器只进行到生成目标文件这一步，这样我们就能在目录下看到HelloWorld.o文件了。 Linux下的可执行文件以及目标文件的格式叫作ELF(Executable Linkable Format)。其实Windows下的PE(Portable Executable)也好，Linux下的ELF也罢，都是COFF(Common file format)格式的一种变种，甚至Windows下的目标文件就是以COFF格式去存储的。不同的操作系统之间的可执行文件的格式通常是不一样的，所以造成了编译好的HelloWorld没有办法直接复制执行，而需要在相关平台上重新编译。当然了，不能运行的原因不只是这一点，不同的操作系统接口（windows API和Linux的API不同）以及相关的类库不同也是原因之一。 更详细的内容可以参看《程序员的自我修养》了解。 5. 链接做什么？这一步是将汇编产生的目标文件和所使用的库函数的目标文件链接生成一个可执行文件的过程。在这里稍微的扩展一下篇幅，稍微详细的说一说链接，一是链接造成的错误通常难以理解和处理，二是在开发中使用第三方库越来越常见了，大家可能更需要稍微了解一些细节。 首先介绍一下gnu binutils工具包，这是一整套的二进制分析处理工具包。详细介绍请大家参考维基百科：http://zh.wikipedia.org/wiki/GNU_Binutils 一般系统安装包中都带了这套工具包，如果你的发行版没有，请自行搜索进行安装。 这套工具包含了足够多的工具，我们甚至可以用来研究ELF文件的格式等内容。不过本节只是抛砖引玉，更多的使用方法和技巧还是需要大家自己去学习和研究。 链接这个话题涉及的内容相当广泛，为了避免本节牵扯到过多的话题导致言之泛泛，我们先设定本节讨论的范围。在这里只讨论链接进行的大致步骤及其规则、静态链接库与动态链接库的创建和使用这两大问题。至于可执行文件的加载、可执行文件的运行时储存器映像之类的内容我们暂时不讨论。那么，什么是链接？我们引用《深入理解计算机系统》中的定义：链接（linking）是将各种代码和数据部分收集起来并组合成为一个单一文件的过程，这个文件可被加载（或被拷贝）到存储器并执行。 需要强调的是，链接可以执行于编译时（compile time），也就是在源代码被翻译成机器代码时；也可以执行于加载时，也就是在程序被加载器（loader）加载到存储器并执行时；甚至执行于运行时（run time），由应用程序来执行。 那么，了解链接到底有什么用？继续引用《深入理解计算机系统》的说法，如下： 理解链接器将帮助你构造大型程序。 理解链接器将帮助你避免一些危险的编程错误。 理解链接将帮助你理解语言的作用域是如何实现的。 理解链接将帮助你理解其他重要的系统概念。 理解链接将使你能够利用共享库。 言归正传。为了避免我们的描述过于枯燥，我们还是以C语言为例。大家通过我们前面的描述，已经知道C代码编译后的目标文件了。目标文件最终要和标准库进行链接生成最后的可执行文件。那么，标准库和我们生成的目标文件是什么关系？ 其实，任何一个程序，它的背后都有一套庞大的代码在支撑着它，以使得该程序能够正常运行。这套代码至少包括入口函数、以及其所依赖的函数构成的函数集合。当然，它还包含了各种标准库函数的实现。 这个“支撑模块”就叫做运行时库（Runtime Library）。而C语言的运行库，即被称为C运行时库（CRT）。 CRT大致包括：启动与退出相关的代码（包括入口函数及入口函数所依赖的其他函数）、标准库函数（ANSI C标准规定的函数实现）、I/O相关、堆的封装实现、语言特殊功能的实现以及调试相关。其中标准库函数的实现占据了主要地位。标准库函数比如我们平时常用的printf，scanf函数等。C语言标准库在不同的平台上实现了不同的版本，我们只要依赖其接口定义，就能保证程序在不同平台上的一致行为。C语言标准库有24个，囊括标准输入输出、文件操作、字符串操作、数学函数以及日期等等内容。大家有兴趣的可以自行搜索。 5.1 静态链接库既然C语言提供了标准库函数供我们使用，那么以什么形式提供？是源代码吗？当然不是。下面引入静态链接库的概念。我们几乎每一次写程序都难免去使用库函数，那么每一次去编译岂不是太麻烦了。干嘛不把标准库函数提前编译好，需要的时候直接链接？是的，标准库就是这么做的。那么，标准库以什么形式存在？是一个目标文件？我们知道，链接的最小单位就是一个个目标文件，如果我们只用到一个printf函数，但需要和整个库链接的话岂不是太浪费资源了么？但是，如果把库函数分别定义在彼此独立的代码文件中，这样编译出后就形成一大堆目标文件。所以，编辑器系统提供了一种机制，将所有的编译出来的目标文件打包成一个单独的文件，叫做静态库（static library）。当链接器和静态库链接的时候，链接器会从这个打包的文件中“解压缩”出需要的部分目标文件进行链接。这样就解决了资源浪费的问题。 Linux/Unix系统下ANSI C的库名叫做libc.a，另外数学函数单独在libm.a库中。当了解以上相关知识后，我们试着自己做一个静态库。为了简单起见我们就做一个只有两个函数的私有库。 在swap.c里定义一个swap函数，在add.c里定义了一个add函数。最后还有含有它们声明的calc.h头文件。 // swap.c void swap(int *num1, int *num2) { int tmp = *num1; *num1 = *num2; *num2 = tmp; } // add.c int add(int a, int b) { return a + b; } // calc.h #ifndef CALC_H_ #define CALC_H_ #ifdef _cplusplus extern &quot;C&quot; { #endif void swap(int *, int *); int add(int, int); #ifdef _cplusplus } #endif #endif // CALC_H_ 我们分别编译它们得到了swap.o和add.o这两个目标文件，最后使用ar命令将其打包为一个静态库。 debian@bogon:~/link$ gcc add.c -c -o add.o debian@bogon:~/link$ gcc swap.c -c -o swap.o debian@bogon:~/link$ ls add.c add.o calc.h swap.c swap.o debian@bogon:~/link$ ar rcs libcalc.a swap.o add.o debian@bogon:~/link$ ls add.c add.o calc.h libcalc.a swap.c swap.o debian@bogon:~/link$ 现在我们怎么使用这个静态库呢？我们写一个test.c使用这个库中的swap函数。代码如下： #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &quot;calc.h&quot; int main(int argc, char *argv[]) { int a = 1, b = 2; swap(&amp;a, &amp;b); printf(&quot;%d %d\\n&quot;, a, b); return EXIT_SUCCESS; } 下来是编译执行，命令行执行gcc test.c ./libcalc.a -o test编译，执行。如图，我们输出了预期的结果。 debian@bogon:~/link$ gcc test.c ./libcalc.a -o test debian@bogon:~/link$ ./test 2 1 debian@bogon:~/link$ 可能你会问，我们使用C语言标准库的时候，编译时并不需要加库名。是的，的确不需要，那是因为标准库已经是标准了，所以会被默认链接。不过因为数学函数库libm.a没有默认链接，所以我们使用了数学函数的代码在编译时需要在命令行指定 -lm 链接（-l是指定链接库，m是去掉lib之后的库名），不过现在好多gcc都默认链接libm.c库了。 正如我们所看到的，静态链接库解决了一些问题，但是它同时带来了另一些问题。比如说每一个使用了相同的C标准函数的程序都需要和相关目标文件进行链接，浪费磁盘空间；当一个程序有多个副本执行时，相同的库代码部分被载入内存，浪费内存；当库代码更新之后，使用这些库的函数必须全部重新编译等等。 5.2 动态链接库是否有更好的办法？当然有。我们接下来引入动态链接库/共享库（shared library）。 动态链接库/共享库是一个目标模块，在运行时可以加载到任意的存储器地址，并和一个正在运行的程序链接起来。这个过程就是动态链接（dynamic linking），是由一个叫做动态链接器（dynamic linker）的程序完成的。 Unix/Linux中共享库的后缀名通常是.so（微软就是DLL文件）。那么，如何建立一个动态链接库？ 我们还是以上面的代码为例，首先删除之前的静态库和目标文件。要建立动态链接库，在命令行输入： gcc swap.c add.c -shared -o libcalc.so 顺便说一下，最好在gcc命令行加上一句-fPIC让其生成与位置无关的代码（PIC），具体原因超出本文范围，故暂不予讨论。 debian@bogon:~/link$ gcc swap.c add.c -shared -o libcalc.so debian@bogon:~/link$ ls add.c add.o calc.h libcalc.a libcalc.so swap.c swap.o test test.c debian@bogon:~/link$ 如何使用动态链接库？我们继续编译测试代码，执行gcc test.c -o test ./libcalc.so即可。运行后我们仍旧得到了预期的结果。 debian@bogon:~/link$ gcc test.c -o test ./libcalc.so debian@bogon:~/link$ ./test 2 1 debian@bogon:~/link$ 这看起来也没什么不一样的。其实不然，我们用ldd命令（ldd是我们推荐的GNU binutils工具包的组成之一）检查test文件的依赖。 debian@bogon:~/link$ ldd ./test linux-vdso.so.1 (0x00007fff3d3fb000) ./libcalc.so (0x00007f61c97de000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f61c943f000) /lib64/ld-linux-x86-64.so.2 (0x00007f61c9be2000) debian@bogon:~/link$ 我们看到这个文件能顺利运行需要依赖libcalc.so这个动态库，我们还能看到C语言的标准库默认也是动态链接的（在gcc编译的命令行加上 -static 可以要求静态链接）。 好处何在？第一，库更新之后，只需要替换掉动态库文件即可，无需编译所有依赖库的可执行文件。第二，程序有多个副本执行时，内存中只需要一份库代码，节省空间。 大家想想，C语言标准库好多程序都在用，但内存只有一份代码，这样节省的空间就相当可观了，而且假如库代码发现bug，只需要更新libc.so即可，所有程序即可使用新的代码，代码的可维护性提高。 关于库的内容还很多，就此介绍到这里。 5.3 链接的步骤我们来看看链接过程中具体做的事情。链接的步骤大致包括了地址和空间分配（Address and Storage Allocation）、符号决议（Symbol Resolution）和重定位（Relocation）等主要步骤。 首先是地址和空间分配，我们之前提到的目标文件其实全称叫做可重定位目标文件（这只是一种名称，还有其他名称）。目标文件的格式已经无限度接近可执行文件了，Unix/Linux下的目标文件的格式叫做ELF（Executable and Linkable Format，可执行连接格式）。本节暂不详细讨论可执行文件的格式，我们只需要知道可执行文件中代码，数据，符号等内容分别存储在不同的段中就可以，这也和第二章保护模式下的内存分段是有一定关系的。我们简单叙述了地址和空间分配以及重定位，但是稍微详细说明一下符号决议。 什么是符号（symbol）？简单说我们在代码中定义的函数和变量可以统称为符号。符号名（symbol name）就是函数名和变量名了。 目标文件的拼合其实也就是对目标文件之间相互的符号引用的一个修正。我们知道一个C语言代码文件只要所有的符号被声明过就可以通过编译了，可是对某符号的引用怎么知道位置呢？比如我们调用了printf函数，编译时留下了要填入的函数地址，那么printf函数的实际地址在哪里？这个空位什么时候修正呢？当然是链接的时候，重定位那一步就是做这个的。但是在修改地址之前需要做符号决议，那什么是符号决议？正如前文所说，编译期间留下了很多需要重新定位的符号，所以目标文件中会有一块区域专门保存符号表。链接器如何知道具体位置？其实链接器并不知道，所以链接器会搜索全部的待链接的目标文件，寻找这个符号的位置，然后修正每一个符号的地址。 在此我们要重点介绍一下在编译程序时几乎所有人会遇见的问题——符号查找问题。在编译时通常会碰到两种编译错误，即找不到某符号或者符号重定义。 首先介绍找不到符号的情况，比如，当我们声明了一个swap函数却没有定义它的时候，我们调用这个函数的代码可以通过编译，但是在链接期间却会遇到错误。形如“test.c:(.text+0x29): undefined reference to ‘swap’”这样，特别的，MSVC编译器报错是找不到符号_swap。这个下划线从哪里来的？这得从C语言刚诞生说起。当C语言刚面世的时候，已经存在不少用汇编语言写好的库了，因为链接器的符号唯一规则，假如该库中存在main函数，我们就不能在C代码中出现main函数了，因为会遭遇符号重定义错误，倘若放弃这些库又是一大损失。所以当时的编译器会对代码中的符号进行修饰（name decoration），C语言的代码会在符号前加下划线，fortran语言在符号前后都加下划线，这样各个目标文件就不会同名了，就解决了符号冲突的问题。随着时间的流逝，操作系统和编译器都被重写了好多遍，当前的这个问题已经可以忽略。所以新版的gcc一般不会再加下划线做符号修饰（也可以在编译的命令行加上-fleading-underscore/-fno-fleading-underscore开打开/关闭这个是否加下划线）。而MSVC依旧保留了这个传统，所以我们可以看到_swap这样的修饰。 顺便说一下，符号冲突是很常见的事情，特别是在大型项目的开发中，所以我们需要一个约定良好的命名规则。C++也引入了命名空间来帮助我们解决这些问题，因为C++中存在函数重载，所以C++的符号修饰更加复杂难懂（Linux下有c++filt命令帮助我们翻译一个被C++编译器修饰过的符号）。 那么，当出现同名符号时链接器到底如何处理。刚才说过会报告重名错误，为什么还要进行探讨？实际上，不仅仅这么简单。在编译时，编译器会向汇编器输出每个全局符号，分为强（strong）符号和弱符号（weak），汇编器把这个信息隐含的编码在可重定位目标文件的符号表里。其中函数和已初始化过的全局变量是强符号，未初始化的全局变量是弱符号。根据强弱符号的定义，GNU链接器采用的规则如下： 不允许多个强符号 如果有一个强符号和一个或多个弱符号，则选择强符号 如果有多个弱符号，则随机选择一个 其中，第一条会报符号重名错误的，而后两条默认情况下甚至连警告都不会有。关键就在这里，默认甚至连警告都没有。 我们来个实验具体说一下： // link1.c #include &lt;stdio.h&gt; int n; int main(int argc, char *argv[]) { printf(&quot;It is %d\\n&quot;, n); return 0; } // link2.c int n = 5; 这两个文件编译运行会输出什么呢？想必你已经知道了结果，没错，就是5 debian@bogon:~/link$ vim link1.c debian@bogon:~/link$ vim link2.c debian@bogon:~/link$ gcc link1.c link2.c -o link debian@bogon:~/link$ ./link It is 5 debian@bogon:~/link$ 初始化过的n是强符号，被优先选择了。但是，在很复杂的项目代码中，这样的错误很难发现，特别是多线程的代码，不过当我们怀疑代码中的bug可能是因为此原因引起的时候，我们可以在gcc命令行加上-fno-common这个参数，这样链接器在遇到多重定义的符号时，都会给出一条警告信息，而无关强弱符号。如下所示： debian@bogon:~/link$ gcc link1.c link2.c -o link -fno-common /tmp/ccJnlWp9.o:(.data+0x0): multiple definition of `n&apos; /tmp/ccM5uYLR.o:(.bss+0x0): first defined here collect2: error: ld returned 1 exit status debian@bogon:~/link$ 进程虚拟地址空间每个程序被运行起来以后，将拥有独立的虚拟地址空间（virtual address space），该虚拟地址空间的大小由计算机的硬件平台决定，具体的说由CPU的位数决定。硬件决定了地址空间的最大理论上限，即硬件的寻址空间大小，比如32位的硬件平台决定了虚拟地址空间的地址为 0 到 2^32 - 1 ，即0x00000000 ~ 0xFFFFFFFF，也就是常说的4GB虚拟空间大小；而64位的硬件平台具有64位寻址能力，它的虚拟地址空间达到了 2^64 字节，即0x0000000000000000 ~ 0xFFFFFFFFFFFFFFFF，总共17 179 869 184 GB. 从程序的角度看，可以通过判断C语言程序中的指针所占的空间来计算虚拟地址空间的大小，一般来说，C语言指针大小的位数与虚拟空间的位数相同，如 32 位平台下的指针为 32 位，即 4字节； 64位平台下的指针为64位，即8字节。有些特殊情况这种规则不成立。 对于32平台来说，4GB的虚拟内存空间，只有较低的3GB（从虚地址0x00000000 到 0xBFFFFFFF）供各个进程自己使用，称为用户空间；而最高的1GB（从虚地址0xC0000000 到 0xFFFFFFFF）供内核使用（所有的进程共享），称为内核空间，如下图所示。 装载的方式程序执行时所需要的指令和数据必须在内存中才能正常运行，最简单的就是将程序运行所需要的指令和数据全都装入内存中，这就是最简单的静态装入的办法。但是大多数情况程序所需的内存大于物理内存，内存昂贵，希望在不添加内存时让更多的程序运行起来。研究发现，程序运行时是有局部性原理的，所以我们可以将程序最常用的部分驻留在内存中，而将一些不太常用的数据存放在磁盘里面，这就是动态装入的基本原理。 覆盖装入（Overlay）和页映射（Paging）是两种很典型的动态装载方法。动态装入的思想是程序用到哪个模块，就将哪个模块装入内存，如果不用就暂时不装入，存放在磁盘中。 覆盖装入在没有虚拟存储之前使用广泛，现在已经淘汰，跳过。 页映射页映射是虚拟存储机制的一部分，随着虚拟存储的发明而诞生。将内存和所有磁盘中的数据和指令按照“页（Page）”为单位划分成若干个页。 实例：假设有台32位机器，共16KB内存，每个页为4KB（4096字节）。假设程序所有的指令和数据总和为32KB，那么程序总共被分为8个页，编号P0~P7.16KB的物理内存无法同时装入32KB程序，按照动态装入的原理进行整个装入过程。若程序刚开始执行时的入口地址在P0，这时装载管理器发现程序的P0不在内存中，于是将物理内存F0分配给P0，，并且将P0的内容装入F0；运行一段时间后，程序需要用到P5，于是装载管理器将P5装入F1；当程序用到P3、P6时，分别被装入F2和F3，如下映射： 如图此时程序用到了P0、P3、P5和P6，占据了所有的物理内存，若程序需要访问P4，那么装载管理器（OS的存储管理器）必须做出抉择，它必须放弃目前正在使用的4个内存页中的一个来装载P4。至于选择哪个页，有多种算法可以选择，比如可以选择F0，因为它是第一个被分配掉的内存页（FIFO，先进先出算法）；假设装载管理器发现F2很少被访问到，那么可以选择F2（LRU，Least Recently Used，最少使用算法）。目前主流的操作系统都是按照这种方式装载可执行文件。 从操作系统角度看可执行文件的装载从OS角度看，一个进程最关键的特征是它拥有独立的虚拟地址空间，使得它有别于其他进程。很多时候一个程序被执行同时伴随着一个新进程的创建：创建一个进程，装载相应的可执行文件并且执行。在有虚拟存储的情况下，上述过程最开始只需要做三件事情： 创建一个独立的虚拟地址空间。 读取可执行文件头，并且建立虚拟空间与可执行文件的映射关系。 将CPU的指令寄存器设置成可执行文件的入口地址，启动运行。 1.创建虚拟地址空间 一个虚拟空间由一组页映射函数将虚拟空间的各个页映射至相应的物理空间，创建一个虚拟空间实际上并不是创建空间而是创建映射函数所需要的相应的数据结构。 2.读取可执行文件头，并且建立虚拟空间与可执行文件的映射关系上一步的页映射关系函数是虚拟空间到物理内存的映射关系，这一步所做的是虚拟空间与可执行文件的映射关系。当程序执行发生页错误时，操作系统从物理内存中分配一个物理页，然后将该“缺页”从磁盘中读取到内存中，再设置缺页的虚拟页和物理页的映射关系，这样程序才得以正常运行。当操作系统捕获到缺页错误时，应该知道程序当前所需要的页在可执行文件中的哪一个位置。这就是虚拟空间与可执行文件之间的映射关系。这是整个装载过程中最重要的一步。 可执行文件在装载时实际上是被映射到虚拟空间，所以可执行文件又被叫做映像文件image。Linux中将进程虚拟空间中的一个段叫做虚拟内存区域（VMA，Virtual Memory Area）。VMA是一个很重要的概念，对于我们理解程序的装载执行和操作系统如何管理进程的虚拟空间有非常重要的帮助。 3.将CPU指令寄存器设置成可执行文件入口，启动运行操作系统通过设置CPU的指令寄存器将控制权转交给进程，由此进程开始执行。这一步在操作系统层面上比较复杂，涉及内核堆栈和用户堆栈的切换、CPU运行权限的切换。在进程的角度看可以简单地认为操作系统执行了一条跳转指令，直接跳转至可执行文件的入口地址，也就是ELF文件头保存的地址。 页错误上面的步骤执行完以后，实际上可执行文件的真正指令和数据都没有被转入到内存中。操作系统只是通过可执行文件头部的信息建立起可执行文件和进程虚存之间的映射关系而已。当CPU准备执行某个地址的指令时，发现其是个空页面，就认为是一个页错误（Page Fault）。CPU将控制权交给操作系统，操作系统有专门的页错误处理例程来处理这种情况，这时候转载过程的第二步建立的数据结构起到了关键作用，操作系统将查询这个数据结构，然后找到空页面所在的VMA，计算出相应的页面在可执行文件中的偏移，然后在物理内存中分配一个物理页面，将进程中该虚拟页与分配的物理页之间建立映射关系，然后把控制权交还给进程，进程从刚才页错误的位置重新开始执行。 进程虚存空间分布操作系统只关心一些跟装载相关的问题，最主要的就是段的权限（可读、可写、可执行）。ELF问减重往往只有为数不多的几种组合，基本如下三种： 以代码段为代表的权限为可读可执行的段。 以数据段和BSS段为代表的权限为可读可写的段。 以只读数据段为代表的权限为只读的段。 操作系统通过使用VMA来对进程的地址空间进行管理，栈、堆在进程的虚拟空间中同样也是以VMA的形式存在。在Linux下，可以通过查看/proc/$PID/maps获取指定进程的虚拟空间分布： 第一列是VMA的地址范围； 第二列是VMA的权限，r-读，w-写，x-可执行，p-表示私有（COW,Copy on Write），s-共享； 第三列是偏移，表示VMA对应的Segment在映像文件中的偏移； 第四列表示映像文件所在设备的主设备号和次设备号； 第五列表示映像文件的节点号； 最后一列是映像文件的路径。 该进程的5个VMA中，只有前两个是映射到可执行文件中的两个segment，另外3个主次设备号和节点号都是0，没有映射到文件中，这种VMA叫做匿名虚拟内存区域（Anonymous Virtual Memory Area）。堆占140KB，栈占88KB，这两个VMA几乎所有的进程都存在，malloc内存分配就是从堆里分配，堆由系统库管理。最后一个VMA叫做“vdso”，它的地址已经位于内核空间（即大于0xC0000000的地址），事实上它是一个内核模块，进程可以通过访问这个VMA来跟内核进行一些通信。 操作系统通过给进程空间划分出一个个VMA来管理进程的虚拟空间；基本原则是将相同权限属性的、有相同映像文件的映射成一个VMA；一个进程基本上可以分为如下几个VMA区域： 代码VMA，只读、可执行；有映像文件。 数据VMA，可读写、可执行；有映像文件。 堆VMA，可读写，可执行；无映像文件，匿名，可向上扩展。 栈VMA，可读写、不可执行；无映像文件，匿名，可向下扩展。 Linux内核装载ELF过程在Linux的bash下输入一个命令执行某个ELF程序时，首先在用户层面，bash进程会调用fork系统调用创建一个新的进程，然后新的进程调用execve系统调用执行指定的ELF文件，原先的bash进程继续返回等待刚才启动的新进程结束，然后继续等待用户输入命令。 在进入execve系统调用之后，Linux内核就开始进行真正的装载工作。在内核中，execve系统调用相应函数定义在exec.c(3.14版内核)文件中： SYSCALL_DEFINE3(execve, const char __user *, filename, const char __user *const __user *, argv, const char __user *const __user *, envp) { return do_execve(getname(filename), argv, envp); } 最终调用do_execve会查找被执行的文件，如果找到文件检查权限，则读取文件的前128字节(BINPRM_BUF_SIZE)。 为什么要读取前128字节呢?众所周知，Linux支持的可执行文件不止ELF一种，还有a.out、Java程序和以“#！”开始的脚本程序，读取文件的前128字节目的是判断文件的格式，每种可执行文件的格式开头几个字节都是很特殊的，特别是开头4个字节，常常被称为魔数（Magic Number），通过对魔数的判断可以确定文件的格式和类型。比如ELF的可执行文件格式的头4个字节为0x7F、e、l、f；而java的可执行文件格式头4个字节为c、a、f、e；如果被执行的是Shell或者perl、python等解释型脚本语言，那么他的第一行往往是”#!/bin/bash”或“#!/usr/bin/perl”或“#!/usr/bin/python”，这时候前两个字节‘#’和“！”就构成了魔数，系统一旦判断到这两个字节，就对后面的字符串进行解析，以确定具体的解释程序的路径。 当do_execve()读取了前128字节的文件头部之后，然后调用search_binary_handle()去搜索和匹配合适的可执行文件装载处理过程。Linux中所有被支持的可执行文件格式都有相应的装载处理过程，search_binary_handle()会通过判断文件头部的魔数确定文件的格式，并且调用相应的装载处理过程。比如ELF可执行文件的装载处理过程叫做load_elf_bingary()；a.out可执行文件的装载处理过程叫做load_aout_binary()；而装载可执行脚本程序的处理过程叫做load_script()。ELF的load_elf_binary()被定义在fs/Binfmt_elf.c，主要步骤是： 检查ELF可执行文件格式的有效性。比如魔数、程序头表中段（segment）的数量； 寻找动态链接的“.interp”段，设置动态链接器路径（与动态链接有关）。 根据ELF可执行文件程序头表的描述，对ELF文件进行映射，比如代码、数据、只读数据。 初始化ELF进程环境，比如进程启动时EDX寄存器的地址应该是DT_FINI的地址。 将系统调用的返回地址修改成ELF可执行文件的入口点，这个入口点取决于程序的链接方式，对于静态链接的ELF可执行文件，这个程序入口就是iELFwenjian的文件头中e_entry所指的地址了对于动态链接的ELF可执行文件，程序入口点是动态链接器。 当load_elf_binary()执行完毕，返回至do_execve，上面的第5步中已经把系统调用的返回地址改成了被装载的ELF程序的入口地址了。所以当execve()系统调用从内核态返回到用户态时，EIP寄存器直接跳转到了ELF程序的入口地址，于是新的程序开始执行，ELF可执行文件装载完成。","categories":[],"tags":[]},{"title":"","slug":"JavaScript笔记","date":"2018-11-03T05:02:46.000Z","updated":"2018-06-05T01:36:38.000Z","comments":true,"path":"JavaScript笔记/","link":"","permalink":"http://yoursite.com/JavaScript笔记/","excerpt":"","text":"JavaScript笔记 在 JavaScript 中，用分号来结束语句是可选的。 块的作用是使语句序列一起执行。 反斜杠对代码行进行换行 JavaScript 中的所有事物都是对象：字符串、数字、数组、日期，等等 如果把数字与字符串相加，结果将成为字符串。 JavaScript 库常被称为 JavaScript 框架：jQuery、Prototype、MooTools","categories":[],"tags":[]},{"title":"","slug":"Linux内核分析-孟宁","date":"2018-11-03T05:02:46.000Z","updated":"2018-06-13T16:15:42.000Z","comments":true,"path":"Linux内核分析-孟宁/","link":"","permalink":"http://yoursite.com/Linux内核分析-孟宁/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"影梭教程","slug":"影梭教程","date":"2018-10-27T02:36:00.000Z","updated":"2019-03-06T04:18:32.766Z","comments":true,"path":"影梭教程/","link":"","permalink":"http://yoursite.com/影梭教程/","excerpt":"","text":"购买VPS用户注册www.vultr.com 账号充值机器创建 选择centos 获取VPS登录信息VPS服务器配置ssh连接VPS一键搭建shadowsocksRyum -y install gitgit clone https://github.com/flyzy2005/ss-flyss-fly/ss-fly.sh –ssr记录相关参数相关操作*命令启动：/etc/init.d/shadowsocks start停止：/etc/init.d/shadowsocks stop重启：/etc/init.d/shadowsocks restart状态：/etc/init.d/shadowsocks status** 配置文件路径：/etc/shadowsocks.json日志文件路径：/var/log/shadowsocks.log代码安装目录：/usr/local/shadowsocks6.卸载***服务./shadowsocksR.sh uninstall 一键开启BBR加速ss-fly/ss-fly.sh -bbr装完后需要重启系统，输入y即可立即重启，或者之后输入reboot命令重启。判断BBR加速有没有开启成功。输入以下命令：sysctl net.ipv4.tcp_available_congestion_control如果返回值为：net.ipv4.tcp_available_congestion_control = bbr cubic reno后面有bbr，则说明已经开启成功了。 客户端配置WIndows客户端配置双击运行shadowsocks.exe，之后会在任务栏有一个小飞机图标，右击小飞机图标，选择服务器-&gt;编辑服务器： 安卓客户端配置 参考链接：https://github.com/Shadowsocks-Wiki/shadowsockshttp://blog.51cto.com/13756513/2118075https://www.banpie.info/shadowsocks-pac-gfw/https://shadowsocks.org/en/download/clients.htmlhttps://shadowsocks.org/en/download/clients.html","categories":[],"tags":[{"name":"教程","slug":"教程","permalink":"http://yoursite.com/tags/教程/"}]},{"title":"什么是中断？","slug":"什么是中断？","date":"2018-10-22T06:06:29.000Z","updated":"2019-02-23T03:11:48.805Z","comments":true,"path":"什么是中断？/","link":"","permalink":"http://yoursite.com/什么是中断？/","excerpt":"","text":"定义从物理学的角度看，中断是一种电信号，由硬件设备产生，并直接送入中断控制器（如 8259A）的输入引脚上，然后再由中断控制器向处理器发送相应的信号。处理器一经检测到该信号，便中断自己当前正在处理的工作，转而去处理中断。此后，处理器会通知 OS 已经产生中断。这样，OS 就可以对这个中断进行适当的处理。不同的设备对应的中断不同，而每个中断都通过一个唯一的数字标识，这些值通常被称为中断请求线。 注意：操作系统显然不能任由每个中断都各自为政，统一管理是必须的 最简单的中断机制最简单的中断机制就是像芯片手册上讲的那样，在中断向量表中填入跳转到对应处理函数的指令，然后在处理函数中实现需要的功能。类似下图： 这种方式在原来的单片机课程中常常用到，一些简单的单片机系统也是这样用。它的好处很明显，简单，直接。 分离中断接收与中断处理过程中断处理函数所作的第一件事情是什么？答案是屏蔽中断（或者是什么都不做，因为常常是如果不清除IF位，就等于屏蔽中断了），当然只屏蔽同一种中断。之所以要屏蔽中断，是因为新的中断会再次调用中断处理函数，导致原来中断处理现场的破坏。即，破坏了 interrupt context。 随着系统的不断复杂，中断处理函数要做的事情也越来越多，多到都来不及接收新的中断了。于是发生了中断丢失，这显然不行，于是产生了新的机制：分离中断接收与中断处理过程。中断接收在屏蔽中断的情况下完成；中断处理在时能中断的情况下完成，这部分被称为中断下半部。 从上图中看，只看int0的处理。Func0为中断接收函数。中断只能简单的触发func0，而func0则能做更多的事情，它与funcA之间可以使用队列等缓存机制。当又有中断发生时，func0被触发，然后发送一个中断请求到缓存队列，然后让funcA去处理。 由于func0做的事情是很简单的，所以不会影响int0的再次接收。而且在func0返回时就会使能int0，因此funcA执行时间再长也不会影响int0的接收。 软中断下面看看linux中断处理。作为一个操作系统显然不能任由每个中断都各自为政，统一管理是必须的。我们不可中断部分的共同部分放在函数do_IRQ中，需要添加中断处理函数时，通过request_irq实现。下半部放在do_softirq中，也就是软中断，通过open_softirq添加对应的处理函数。 tasklet旧事物跟不上历史的发展时，总会有新事物出现。随着中断数的不停增加，软中断不够用了，于是下半部又做了进化。软中断用轮询的方式处理。假如正好是最后一种中断，则必须循环完所有的中断类型，才能最终执行对应的处理函数。显然当年开发人员为了保证轮询的效率，于是限制中断个数为32个。 为了提高中断处理数量，顺道改进处理效率，于是产生了tasklet机制。 Tasklet采用无差别的队列机制，有中断时才执行，免去了循环查表之苦。 CDMA因为频谱重叠问题，必须降功率。而功率降低后，又发现原来功率低了有助于环保。 Tasklet作为一种新机制，显然可以承担更多的优点。正好这时候SMP越来越火了，因此又在tasklet中加入了SMP机制，保证同种中断只 在一个cpu上执行。在软中断时代，显然没有这种考虑。因此同一种中断可以在两个cpu上同时执行，很可能造成冲突。 总结下tasklet的优点： （1）无类型数量限制；（2）效率高，无需循环查表；（3）支持SMP机制； 参考资料 Linux中的中断处理机制","categories":[],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"http://yoursite.com/tags/Kernel/"}]},{"title":"BLurAdmin界面设计","slug":"BLurAdmin界面设计","date":"2018-10-14T16:00:00.000Z","updated":"2018-10-08T02:13:46.000Z","comments":true,"path":"BLurAdmin界面设计/","link":"","permalink":"http://yoursite.com/BLurAdmin界面设计/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践操作 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章前言文章目的AI操作系统，以01为基因，内核为灵魂， 文章前景0x01-知识储备0x02-测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 PostgreSQL WebStorm Node.js Git0x03-方案设计 复杂系统，标准的过程应当在业务建模，需求分析，分析设计，实施开发，测试，部署完整过程的分析设计（与开发语言无关）或实施开发（分析设计的成果映射为具体语言，例如Java、.NET等）阶段才考虑设计模式、架构模式的引入。设计模式的使用会经历僵化-&gt;固化-&gt;优化的阶段，类似禅修中“看山是山、看水是水”的三个阶段，才能体会模式的运用之妙。 方案A方案B0x04-实践操作0x05-总结分析0x06-程序源码代码A代码B0x07-参考资料 百度一下 百度一下 考虑到： 理论与实践 抽象与具体 现状与未来 调试优化（折中与平衡）用户体验：应用性能： 截图时间点（I/O）： 输入：命令、按钮 输出：变化、结果 ——&gt;I/O截图法","categories":[],"tags":[{"name":"模板","slug":"模板","permalink":"http://yoursite.com/tags/模板/"}]},{"title":"MariaDB数据库学习","slug":"MariaDB数据库学习","date":"2018-10-07T16:00:00.000Z","updated":"2018-10-09T02:59:16.000Z","comments":true,"path":"MariaDB数据库学习/","link":"","permalink":"http://yoursite.com/MariaDB数据库学习/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践验证 0x05-总结分析 0x06-参考资料 0x00-文章前言文章目的 熟悉数据库操作基本流程、数据操作命令、编程接口 建立一个简单表格，可以通过相关语句进行操作 了解MariaDB的相关语法，为后期项目开发做准备 文章前景 有益于对数据库基本操作的掌握 有助于对MariDB语法的学习 有利于对后期相关项目的顺利进展 0x01-知识储备MariaDB命令大全MariaDB语法大全0x02-测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 MariaDB 0x03-方案设计UI操作操作起来较为简单，适合于小量数据，用户体验度高 命令操作使用SQL语句操作，由于使用命令，可复用操作大量数据，效率高 0x04-实践验证安装 创建数据库查看数据库删除数据库 创建表格 删除表格 插入数据 查询数据 更新数据 删除数据 0x05-总结分析0x06-参考资料 百度一下 百度一下","categories":[],"tags":[{"name":"MariaDB","slug":"MariaDB","permalink":"http://yoursite.com/tags/MariaDB/"}]},{"title":"饼状图显示与统计","slug":"表格操作与功能完善","date":"2018-09-30T16:00:00.000Z","updated":"2018-10-08T02:12:36.000Z","comments":true,"path":"表格操作与功能完善/","link":"","permalink":"http://yoursite.com/表格操作与功能完善/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践验证 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章前言文章目的文章前景0x01-知识储备linux系统数据结构深入理解计算机系统操作系统原理0x02-测试环境硬件环境软件环境0x03-方案设计方案A方案B0x04-实践验证实践操作实践结果0x05-总结分析文章结论文章分析0x06-程序源码代码A代码B0x07-参考资料 百度一下 百度一下","categories":[],"tags":[{"name":"BlurAdmin","slug":"BlurAdmin","permalink":"http://yoursite.com/tags/BlurAdmin/"},{"name":"MariaDB","slug":"MariaDB","permalink":"http://yoursite.com/tags/MariaDB/"}]},{"title":"柱状图设计与显示","slug":"柱状图设计与显示","date":"2018-09-23T16:00:00.000Z","updated":"2018-10-08T02:11:44.000Z","comments":true,"path":"柱状图设计与显示/","link":"","permalink":"http://yoursite.com/柱状图设计与显示/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践操作 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章前言文章目的AI操作系统，以01为基因，内核为灵魂， 文章前景0x01-知识储备0x02-测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 PostgreSQL WebStorm Node.js Git0x03-方案设计 复杂系统，标准的过程应当在业务建模，需求分析，分析设计，实施开发，测试，部署完整过程的分析设计（与开发语言无关）或实施开发（分析设计的成果映射为具体语言，例如Java、.NET等）阶段才考虑设计模式、架构模式的引入。设计模式的使用会经历僵化-&gt;固化-&gt;优化的阶段，类似禅修中“看山是山、看水是水”的三个阶段，才能体会模式的运用之妙。 方案A方案B0x04-实践操作0x05-总结分析0x06-程序源码代码A代码B0x07-参考资料 百度一下 百度一下 考虑到： 理论与实践 抽象与具体 现状与未来 调试优化（折中与平衡）用户体验：应用性能： 截图时间点（I/O）： 输入：命令、按钮 输出：变化、结果 ——&gt;I/O截图法","categories":[],"tags":[{"name":"BlurAdmin","slug":"BlurAdmin","permalink":"http://yoursite.com/tags/BlurAdmin/"}]},{"title":"list.h源码解读","slug":"list.h源码解读","date":"2018-09-18T16:00:00.000Z","updated":"2018-09-25T00:29:36.000Z","comments":true,"path":"list.h源码解读/","link":"","permalink":"http://yoursite.com/list.h源码解读/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践验证 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章前言文章目的文章前景0x01-知识储备条件编译 0x02-测试环境硬件环境软件环境0x03-方案设计方案B0x04-实践验证实践操作实践结果0x05-总结分析文章结论文章分析0x06-程序源码linux-2.6.11 代码A代码B0x07-参考资料 百度一下 百度一下","categories":[],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"http://yoursite.com/tags/Kernel/"}]},{"title":"实时警告模块设计与实现","slug":"实时警告模块设计与实现","date":"2018-09-16T16:00:00.000Z","updated":"2018-10-08T02:10:56.000Z","comments":true,"path":"实时警告模块设计与实现/","link":"","permalink":"http://yoursite.com/实时警告模块设计与实现/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践操作 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章前言文章目的AI操作系统，以01为基因，内核为灵魂， 文章前景0x01-知识储备0x02-测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 PostgreSQL WebStorm Node.js Git0x03-方案设计 复杂系统，标准的过程应当在业务建模，需求分析，分析设计，实施开发，测试，部署完整过程的分析设计（与开发语言无关）或实施开发（分析设计的成果映射为具体语言，例如Java、.NET等）阶段才考虑设计模式、架构模式的引入。设计模式的使用会经历僵化-&gt;固化-&gt;优化的阶段，类似禅修中“看山是山、看水是水”的三个阶段，才能体会模式的运用之妙。 方案A方案B0x04-实践操作0x05-总结分析0x06-程序源码代码A代码B0x07-参考资料 百度一下 百度一下 考虑到： 理论与实践 抽象与具体 现状与未来 调试优化（折中与平衡）用户体验：应用性能： 截图时间点（I/O）： 输入：命令、按钮 输出：变化、结果 ——&gt;I/O截图法","categories":[],"tags":[{"name":"BlurAdmin","slug":"BlurAdmin","permalink":"http://yoursite.com/tags/BlurAdmin/"}]},{"title":"表格设计与查询显示","slug":"表格设计与查询显示","date":"2018-09-09T16:00:00.000Z","updated":"2018-10-08T02:04:14.000Z","comments":true,"path":"表格设计与查询显示/","link":"","permalink":"http://yoursite.com/表格设计与查询显示/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践操作 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章前言文章目的服务器管理 从数据表server中获取所有服务器并显示 可筛选查看 日志查询 通过条件从warning中查询日志并显示 多条件查询，时间、消息类型、电厂名称等 文章前景0x01-知识储备0x02-测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 PostgreSQL WebStorm Node.js Git0x03-方案设计 方案Aserver服务器管理 warning日志查询实时警告 系统运行图 方案B0x04-实践操作0x05-总结分析文章结论文章分析0x06-程序源码代码A代码B0x07-参考资料 百度一下 百度一下","categories":[],"tags":[{"name":"BlurAdmin","slug":"BlurAdmin","permalink":"http://yoursite.com/tags/BlurAdmin/"}]},{"title":"Ajax数据显示","slug":"Ajax数据显示","date":"2018-09-02T16:00:00.000Z","updated":"2018-10-08T02:03:50.000Z","comments":true,"path":"Ajax数据显示/","link":"","permalink":"http://yoursite.com/Ajax数据显示/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践操作 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章前言文章目的 实现页面数据动态刷新，而不是全部刷新整个页面 页面在首次加载后，剩下的所有数据通过Ajax更新 文章前景 节约系统资源，使得浏览器页面占用更少硬件资源 加快响应速度，使得浏览器运行更加流畅，机器效率更高 0x01-知识储备Ajax基础Ajax框架介绍 Ajax的全称是Asynchronous JavaScript and XML（异步的 JavaScript 和 XML），其中，Asynchronous 是 异步 的意思，它有别于传统web开发中采用的同步的方式。 Ajax不是编程语言，是一种在与服务器交换数据无需重新加载整个网页的情况下，能够更新部分网页的技术。 Ajax是一种用于创建快速动态网页的技术。通过在后台与服务器进行少量数据交换。Ajax可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。而传统的网页（不使用Ajax）如果需要更新内容，必须重载整个网页面。 Ajax的应用使用支持以上技术的web浏览器作为运行平台。这些浏览器目前包括：Mozilla、Firefox、Internet Explorer、Opera、Konqueror及Safari。但是Opera不支持XSL格式对象，也不支持XSLT。 Ajax工作原理 Ajax工作原理是提供与服务器异步通信的能力，从而使用户从请求/响应的循环中解脱出来。 借助于Ajax，可以在用户单击按钮时，使用JavaScript和DHTML立即更新UI，并向服务器发出异步请求，以执行更新或查询数据库。 当请求返回时，就可以使用JavaScript和CSS来相应地更新UI，而不是刷新整个页面。 最重要的是，用户甚至不知道浏览器正在与服务器通信：Web站点看起来是即时响应的。 Node.js基础 Node.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境。 Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型，使其轻量又高效。 Node.js 的包管理器 npm，是全球最大的开源库生态系统。 Node.JS逐渐发展成一个成熟的开发平台，吸引了许多开发者。有许多大型高流量网站都采用Node.JS进行开发，此外，开发人员还可以使用它来开发一些快速移动Web框架。 除了Web应用外，Node.JS也被应用在许多方面，包括应用程序监控、媒体流、远程控制、桌面和移动应用等等 0x02-测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 PostgreSQL WebStorm Node.js Git 0x03-方案设计静态数据方案使用Ajax框架传递静态数据给页面，查看页面数据 动态数据方案使用Ajax框架传递动态数据给页面，观察页面数据变化 0x04-实践操作静态数据方案启动服务器node server 打开页面index.html 动态数据方案打开页面index2.html 修改重启 数据库数据显示基于PostgreSQL操作接口中所创建的数据库表Log_Inf，server3.js和index.html为数据库数据显示代码 安装pg模块 启动服务器 打开页面index3.html 查看数据库表格 插入数据 查看当前表格 查看GitBash输出 查看页面 0x05-总结分析Ajax特点 Ajax请求是限时的，所以错误警告被捕获并处理后，可以用来提升用户体验。 AJAX请求是异步执行的，也就是说，要通过回调函数获得响应 传统交互模型 浏览器直接将请求发送给服务器，服务器回送响应，直接发给浏览器 同步交互模式，客户端提交请求，等待，在响应回到客户端前，客户端无法进行其他操作 Ajax交互模型 浏览器首先将请求 发送 Ajax引擎（以XMLHttpRequest为核心），AJax引擎再将请求发送给 服务器，服务器回送响应先发给Ajax引擎，再由引擎传给浏览器显示 异步交互模型，客户端将请求提交给Ajax引擎，客户端可以继续操作，由Ajax引擎来完成与服务武器端通信 0x06-程序源码server.jsvar http = require(&apos;http&apos;); var urlLib = require(&apos;url&apos;); var data = { content:`你好`//动态数据方案中需修改 content:`你好` 为： content:`你好呀！` }; http.createServer(function(req,res){ //parse用于从一个字符串中解析出json对象 var parms = urlLib.parse(req.url,true); //stringify()用于从一个对象解析出字符串 var str = parms.query.callback + &apos;(&apos; + JSON.stringify(data) +&apos;)&apos;; res.end(str); }).listen(8088); console.log(&apos;Server running on port http://127.0.0.1:8088/&apos;); index.html&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script src=&quot;http://code.jquery.com/jquery-1.7.1.min.js&quot;&gt;&lt;/script&gt; &lt;body&gt; &lt;div id=&quot;date&quot;&gt;&lt;/div&gt; &lt;!-- &lt;button id=&quot;btn&quot;&gt;请点击&lt;/button&gt;--&gt; &lt;script type=&quot;text/javascript&quot;&gt; $(document).ready(function() { // $(&quot;#btn&quot;).click(function(){ $.ajax({ url: &apos;http://127.0.0.1:8088/&apos;, dataType: &quot;jsonp&quot;,//jsonp是针对于get的跨域解决办法 data: &apos;{&quot;data&quot;: &quot;TEST&quot;}&apos;, type: &apos;GET&apos;, jsonpCallback: &apos;callback&apos;, // 这与POST不相关 success: function (data) { console.log(data); // var ret = jQuery.parseJSON(data);//jQuery.parseJSON() 函数用于将格式完好的JSON字符串转为与之对应的JavaScript对象。 //所谓&quot;格式完好&quot;，就是要求指定的字符串必须符合严格的JSON格式，例如：属性名称必须加双引号、字符串值也必须用双引号。 $(&apos;#date&apos;).html(data.content); // console.log(&apos;Success!&apos;) }, error: function (xhr, status, error) { console.log(&apos;Error: &apos; + error.message); $(&apos;#lblResponse&apos;).html(&apos;Error connecting to the server.&apos;); }, }); // }); }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; index2.html&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script src=&quot;http://code.jquery.com/jquery-1.7.1.min.js&quot;&gt;&lt;/script&gt; &lt;body&gt; &lt;div id=&quot;date&quot;&gt;&lt;/div&gt; &lt;!-- &lt;button id=&quot;btn&quot;&gt;请点击&lt;/button&gt;--&gt; &lt;script type=&quot;text/javascript&quot;&gt; function doUpdate() { $(document).ready(function() { // $(&quot;#btn&quot;).click(function(){ $.ajax({ url: &apos;http://127.0.0.1:8088/&apos;, dataType: &quot;jsonp&quot;,//jsonp是针对于get的跨域解决办法 data: &apos;{&quot;data&quot;: &quot;TEST&quot;}&apos;, type: &apos;GET&apos;, jsonpCallback: &apos;callback&apos;, // 这与POST不相关 success: function (data) { console.log(data); // var ret = jQuery.parseJSON(data);//jQuery.parseJSON() 函数用于将格式完好的JSON字符串转为与之对应的JavaScript对象。 //所谓&quot;格式完好&quot;，就是要求指定的字符串必须符合严格的JSON格式，例如：属性名称必须加双引号、字符串值也必须用双引号。 $(&apos;#date&apos;).html(data.content); // console.log(&apos;Success!&apos;) }, error: function (xhr, status, error) { console.log(&apos;Error: &apos; + error.message); $(&apos;#lblResponse&apos;).html(&apos;Error connecting to the server.&apos;); }, }); // }); }); console.log(&quot;doUpdate&quot;); window.setTimeout(&quot;doUpdate()&quot;, 3000); } doUpdate(); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; server3.jsvar http = require(&apos;http&apos;); var urlLib = require(&apos;url&apos;); var data; function doUpdate(){ function _select(client,selectSQLString) { // console.log(&quot;select beginning&quot;); client.query(selectSQLString, function selectCb(error, results, fields) { // console.log(&quot;in select callback function&quot;); if (error) { console.log(&apos;GetData Error: &apos; + error.message), client.end(); return; } if(results.rowCount &gt; 0) { var firstResult, resultSet = &apos;&apos;; for(var i = 0, len = results.rowCount; i &lt; len; i++) { firstResult = results.rows[i]; resultSet += &apos;id:&apos; + firstResult[&apos;id&apos;] + &apos; &apos; + &apos;type:&apos; + firstResult[&apos;type&apos;] + &apos; &apos; + &apos;rank:&apos; + firstResult[&apos;rank&apos;] + &apos; &apos;; } } console.log(resultSet); data = { content:&apos;你好吗？&apos;, content1:resultSet }; /* 添加功能：使查询结果集返回到客户端并保证此函数的通用性. */ }); // console.log(&quot;select end\\n&quot;); } var pg = require(&apos;pg&apos;); var conString = &quot;tcp://postgres:111111@localhost:5432/test&quot;;//1.连接 var client = new pg.Client(conString); selectSQLString = &apos;select * from Log_Inf&apos;; client.connect(function(error, results) { if(error){ console.log(&apos;ClientConnectionReady Error: &apos; + error.message); client.end(); return; } _select(client,selectSQLString); }); console.log(&quot;hello&quot;); setTimeout(doUpdate,3000); } doUpdate(); http.createServer(function(req,res){ //parse用于从一个字符串中解析出json对象 var parms = urlLib.parse(req.url,true); //stringify()用于从一个对象解析出字符串 var str = parms.query.callback + &apos;(&apos; + JSON.stringify(data) +&apos;)&apos;; res.end(str); }).listen(8088); console.log(&apos;Server running on port http://127.0.0.1:8088/&apos;); index3.html&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script src=&quot;http://code.jquery.com/jquery-1.7.1.min.js&quot;&gt;&lt;/script&gt; &lt;body&gt; 文件数据： &lt;div id=&quot;date&quot;&gt;&lt;/div&gt; &lt;br&gt; 数据库数据： &lt;div id=&quot;date1&quot;&gt;&lt;/div&gt; &lt;script type=&quot;text/javascript&quot;&gt; function doUpdate() { $(document).ready(function() { // $(&quot;#btn&quot;).click(function(){ $.ajax({ url: &apos;http://127.0.0.1:8088/&apos;, dataType: &quot;jsonp&quot;,//jsonp是针对于get的跨域解决办法 data: &apos;{&quot;data&quot;: &quot;TEST&quot;}&apos;, type: &apos;GET&apos;, jsonpCallback: &apos;callback&apos;, // 这与POST不相关 success: function (data) { console.log(data); // var ret = jQuery.parseJSON(data);//jQuery.parseJSON() 函数用于将格式完好的JSON字符串转为与之对应的JavaScript对象。 //所谓&quot;格式完好&quot;，就是要求指定的字符串必须符合严格的JSON格式，例如：属性名称必须加双引号、字符串值也必须用双引号。 $(&apos;#date&apos;).html(data.content); $(&apos;#date1&apos;).html(data.content1); // console.log(&apos;Success!&apos;) }, error: function (xhr, status, error) { console.log(&apos;Error: &apos; + error.message); $(&apos;#lblResponse&apos;).html(&apos;Error connecting to the server.&apos;); }, }); // }); }); console.log(&quot;hello&quot;); window.setTimeout(&quot;doUpdate()&quot;, 3000); } doUpdate(); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 源码打包Ajax-Demo（密码：busg） 0x07-参考资料 AJAX教程 AJAX-廖雪峰的官方网站 PostgreSQL操作接口","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yoursite.com/tags/JavaScript/"}]},{"title":"大佬们说","slug":"大佬们说","date":"2018-09-01T13:41:51.000Z","updated":"2019-03-06T03:15:55.629Z","comments":true,"path":"大佬们说/","link":"","permalink":"http://yoursite.com/大佬们说/","excerpt":"","text":"并行就像一个奶爸左右手同时喂奶，并发就像一个奶爸喂一下左再喂一下右 I simply know better than you, that’s why I’m your god. –Linus Torvalds 天下大事必做于细，天下难事必做于易 –孟宁 唯有深入分析过内核，才能“万行代码过，bug不沾身”。 犯其至难，图其至远。–刘帅","categories":[],"tags":[{"name":"师者","slug":"师者","permalink":"http://yoursite.com/tags/师者/"}]},{"title":"陈老师讲","slug":"陈老师讲","date":"2018-09-01T13:41:51.000Z","updated":"2019-03-06T03:10:57.744Z","comments":true,"path":"陈老师讲/","link":"","permalink":"http://yoursite.com/陈老师讲/","excerpt":"","text":"以原理为主，会穿插Linux的内容，如果想学Linux内核，可以加开放分享班391045 学Linux有三个层面，底层的内核层，最体现功力的，第二层系统编程，有一定深度，第三层命令的使用和Shell 的应用，就是所谓的运维。三个层面，第一层和第二层要求比较高，第三层比较低，但有功底的话也很厉害。 借阅Linux下 C 编程的书籍，比如《Unix/Linux编程实战教程》哈佛大学教授写的，还可以配合其他教材。 I/O出错涉及硬件出错还是应用出错，很值得探究的 一个程序被编译连接后形成的地址空间就放在虚拟内存中，虚拟内存相当于中介，是链接程序和操作系统之间的一个中转站，进程执行时一定得装到物理内存，页表就是虚拟内存和物理内存之间的桥梁。这些内容第四章会讲到，但目前提出来是非常好的学习困惑。分页文件这个概念可以忽略，不是很确切。 一个程序被编译连接后形成的地址空间就放在虚拟内存中，虚拟内存相当于中介，是链接程序和操作系统之间的一个中转站，进程执行时一定得装到物理内存，页表就是虚拟内存和物理内存之间的桥梁。这些内容第四章会讲到，但目前提出来是非常好的学习困惑。分页文件这个概念可以忽略，不是很确切。 问的太好了，内存碎片是永远的话题，这个问题目前还没有终极的解决方案。 你在思考调度问题了，调度的确是操作系统的核心，有各种调度算法，比如时间片，优先级等 挂起，比如进程的执行过程中，要对其进行观察（比如，一个人在单位表现有问题就会将其挂起，暂时不给工作做）或者调试（也是一种观察，进程在执行过程中出现了什么问题），这是暂时把进程挂起，与阻塞不同，挂起不放弃CPU。 如果阅读操作系统内核的代码，就会涉及到汇编。或者反汇编源代码，也会涉及。根据你使用的机器，如果是Intel CPU就用x86汇编，如果是Arm，就用Arm汇编 心不穷就是富 我觉得Thoughtworks的训练是有一定必要的，你个人摸索的很多东西是小米加步枪，看起来什么都会，但缺乏正规军的作战能力","categories":[],"tags":[{"name":"师者","slug":"师者","permalink":"http://yoursite.com/tags/师者/"}]},{"title":"BlurAdmin应用开发","slug":"BlurAdmin应用开发","date":"2018-08-26T16:00:00.000Z","updated":"2018-10-06T06:08:20.000Z","comments":true,"path":"BlurAdmin应用开发/","link":"","permalink":"http://yoursite.com/BlurAdmin应用开发/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践操作 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章前言文章目的 以BlurAdmin模板开发为主，结合Electron打包成桌面应用 学会使用基于Gulp的脚手架进行简单的构建，完善BlurAdmin应用开发 文章前景 一次开发产生多类应用，赋予应用跨平台特点，增加了产品的可移植性 Electron套用BlurAdmin模板打通了B/S架构与跨平台桌面应用程序之间的界限 结合自身需求选择合适的开发方式，提高开发效率，避免未来将会产生的一些问题 0x01-知识储备BlurAdmin简介 BlurAdmin是Angular前端Admin Dashboard模板。这意味着您可以在图表，图表表格中看到的所有数据都在Javascript中进行硬编码。您可以无限制地使用任何您想要的后端。 目前很多业务应用程序都有一些管理界面。有时它并不那么明显，但很多Web应用程序都有仪表板，带有面板，图表分析。 BlurAdmin旨在引导您的产品开发，并为构建原型甚至生产就绪应用程序提供生态系统。 尽管像Bootstrap这样的框架提供了许多组件，但通常它们还不足以构建真实世界的应用程序。此模板带有许多流行的UI组件和统一的配色方案。 Gulp基础Gulp简介Gulp是基于node.js的一个前端自动化构建工具，可以使用它构建自动化工作流程（前端集成开发环境）。使用Gulp你可以简化工作量，让你把重点放在功能的开发上，从而提高你的开发效率和工作质量。 Gulp特性 易于使用：通过代码优于配置的策略，Gulp 让简单的任务简单，复杂的任务可管理。 构建快速：利用 Node.js 流的威力，你可以快速构建项目并减少频繁的 IO 操作。 插件高质：Gulp 严格的插件指南确保插件如你期望的那样简洁高质得工作。 易于学习：通过最少的 API，掌握 Gulp 毫不费力，构建工作尽在掌握：如同一系列流管道。 脚手架简介“脚手架”是一种元编程的方法，用于构建基于数据库的应用。许多MVC框架都有运用这种思想。程序员编写一份specification（规格说明书），来描述怎样去使用数据库；而由（脚手架的）编译器来根据这份specification生成相应的代码，进行增、删、改、查数据库的操作。我们把这种模式称为”脚手架”，在脚手架上面去更高效的建造出强大的应用！ 优势由“程序员手写代码”跨越到了“程序员指挥机器自动生成代码”的时代，并且利用脚手架，我们可以爬到更高的地方、建更高的楼房 0x02-测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 WebStorm Node.js Git 0x03-方案设计方案A：父子目录下开发bluradmin单独开发，完成后在父目录下通过electron .启动应用 方案B：单级目录下开发将electron代码添加到bluradmin代码目录中 blur-admin源码中已存在Gulp脚手架,使用gulp dev-release即可生成打包未压缩文件（存放在dev-release目录中） 移动electron目录下main.js到子目录blur-admin中，并修改main.js、package.json文件，使electron开发和blur-admin开发在同一个目录下进行 创建后端数据库连接文件夹，为将来后端连接预留位置 0x04-实践操作下载源码 electron-v1.1.0（密码：tmb5），解压后修改子目录blur-admin-v1.1.0为blur-admin-v1.2.0,并将blur-admin-v1.2.0文件夹移动到开发目录（个人习惯移动到桌面~_~） 移动electron-v1.1.0目录下main.js文件到子目录blur-admin-v1.2.0中 Gulp构建安装Gulp$ npm install --global gulp 打包生成$ gulp dev-release 修改文件main.js package.json 启动应用 0x05-总结分析 使用Gulp构建出打包未压缩的文件，相对于打包压缩后的文件更加容易修改 将两种不同的开发从父子目录下集中到单级目录下进行，简化了开发步骤，是全栈开发的关键一步 一次开发可以产生Web网站和桌面应用两种产品，提高了开发效率，扩充了平台兼容性，增强了开发模式的多样性 0x06-程序源码main.jsconst {app, BrowserWindow} = require(&apos;electron&apos;); let win; let windowConfig = { width:800, height:600 }; function createWindow(){ win = new BrowserWindow(windowConfig); //加载index.html文件 win.loadURL(`file://${__dirname}/dev-release/index.html`); //开启调试工具 //win.webContents.openDevTools(); win.on(&apos;close&apos;,() =&gt; { //回收BrowserWindow对象 win = null; }); //调整页面大小后重新加载整个页面 //win.on(&apos;resize&apos;,() =&gt; { // win.reload(); //}) } app.on(&apos;ready&apos;,createWindow); app.on(&apos;window-all-closed&apos;,() =&gt; { app.quit(); }); app.on(&apos;activate&apos;,() =&gt; { if(win == null){ createWindow(); } }) package.json{ &quot;name&quot;: &quot;blur_admin&quot;, &quot;version&quot;: &quot;1.3.1&quot;, &quot;devDependencies&quot;: { &quot;bower&quot;: &quot;~1.8.4&quot;, &quot;browser-sync&quot;: &quot;^2.24.7&quot;, &quot;browser-sync-spa&quot;: &quot;~1.0.3&quot;, &quot;chalk&quot;: &quot;~1.1.1&quot;, &quot;del&quot;: &quot;~2.2.2&quot;, &quot;eslint-plugin-angular&quot;: &quot;~0.12.0&quot;, &quot;estraverse&quot;: &quot;~4.2.0&quot;, &quot;gulp&quot;: &quot;~3.9.0&quot;, &quot;gulp-angular-filesort&quot;: &quot;^1.2.1&quot;, &quot;gulp-angular-templatecache&quot;: &quot;~2.0.0&quot;, &quot;gulp-autoprefixer&quot;: &quot;~3.1.1&quot;, &quot;gulp-eslint&quot;: &quot;~1.0.0&quot;, &quot;gulp-filter&quot;: &quot;~4.0.0&quot;, &quot;gulp-flatten&quot;: &quot;~0.3.1&quot;, &quot;gulp-gh-pages&quot;: &quot;^0.5.4&quot;, &quot;gulp-inject&quot;: &quot;~4.1.0&quot;, &quot;gulp-load-plugins&quot;: &quot;~1.4.0&quot;, &quot;gulp-minify-css&quot;: &quot;~1.2.1&quot;, &quot;gulp-minify-html&quot;: &quot;~1.0.4&quot;, &quot;gulp-ng-annotate&quot;: &quot;~2.0.0&quot;, &quot;gulp-prompt&quot;: &quot;^0.2.0&quot;, &quot;gulp-protractor&quot;: &quot;~3.0.0&quot;, &quot;gulp-rename&quot;: &quot;^1.2.2&quot;, &quot;gulp-replace&quot;: &quot;~0.5.4&quot;, &quot;gulp-rev&quot;: &quot;~7.1.2&quot;, &quot;gulp-rev-replace&quot;: &quot;~0.4.2&quot;, &quot;gulp-sass&quot;: &quot;^4.0.1&quot;, &quot;gulp-shell&quot;: &quot;^0.5.2&quot;, &quot;gulp-size&quot;: &quot;~2.1.0&quot;, &quot;gulp-sourcemaps&quot;: &quot;~1.6.0&quot;, &quot;gulp-uglify&quot;: &quot;~2.0.0&quot;, &quot;gulp-useref&quot;: &quot;~1.3.0&quot;, &quot;gulp-util&quot;: &quot;~3.0.6&quot;, &quot;gulp-zip&quot;: &quot;^3.0.2&quot;, &quot;http-proxy-middleware&quot;: &quot;~0.17.2&quot;, &quot;lodash&quot;: &quot;~4.17.2&quot;, &quot;main-bower-files&quot;: &quot;~2.13.1&quot;, &quot;uglify-save-license&quot;: &quot;~0.4.1&quot;, &quot;wiredep&quot;: &quot;~4.0.0&quot;, &quot;wrench&quot;: &quot;~1.5.8&quot; }, &quot;main&quot;: &quot;main.js&quot;, &quot;scripts&quot;: { &quot;postinstall&quot;: &quot;bower install&quot;, &quot;start&quot;: &quot;electron .&quot; } } 源码打包blur-admin-v1.2.0（密码：he5r） 0x07-参考资料 Gulp中文网 Electron官网 Electron应用开发","categories":[],"tags":[{"name":"BlurAdmin","slug":"BlurAdmin","permalink":"http://yoursite.com/tags/BlurAdmin/"}]},{"title":"Electron应用开发","slug":"Electron应用开发","date":"2018-08-20T12:54:27.000Z","updated":"2018-10-06T05:56:10.000Z","comments":true,"path":"Electron应用开发/","link":"","permalink":"http://yoursite.com/Electron应用开发/","excerpt":"","text":"0x00-文章背景 0x01-技能储备 0x02-开发环境 0x03-方案设计 0x04-实践操作 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章背景文章目的 实现Electron应用原型开发，同时预留相应扩展接口及功能使得后续维护及扩展变得相对容易 完善Electron应用交互开发，结合具体需求添加相应功能使得整个开发周期、产品功能可控可调 文章前景 Electron套用BlurAdmin模板打通了B/S架构与跨平台桌面应用程序之间的界限 结合自身需求选择合适的开发方式，提高开发效率，避免未来将会产生的一些问题 原型开发的复用，使得一些相似应用也能直接使用这种开发成果，缩短开发周期，提高开发效率 0x01-技能储备BlurAdmin简介 BlurAdmin是Angular前端Admin Dashboard模板。这意味着您可以在图表，图表表格中看到的所有数据都在Javascript中进行硬编码。您可以无限制地使用任何您想要的后端。 目前很多业务应用程序都有一些管理界面。有时它并不那么明显，但很多Web应用程序都有仪表板，带有面板，图表分析。 BlurAdmin旨在引导您的产品开发，并为构建原型甚至生产就绪应用程序提供生态系统。 尽管像Bootstrap这样的框架提供了许多组件，但通常它们还不足以构建真实世界的应用程序。此模板带有许多流行的UI组件和统一的配色方案。 Electron简介Electron 基于 Chromium 和 Node.js, 让你可以使用 HTML, CSS 和 JavaScript 构建应用。这是一个整合了Node，Chromium，V8的一个框架，通过它可以使用JavaScript，HTML, CSS技术来开发桌面应用程序 Node.js简介 Node.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境。 Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型，使其轻量又高效。 Node.js 的包管理器 npm，是全球最大的开源库生态系统。 Node.JS逐渐发展成一个成熟的开发平台，吸引了许多开发者。有许多大型高流量网站都采用Node.JS进行开发，此外，开发人员还可以使用它来开发一些快速移动Web框架。 除了Web应用外，Node.JS也被应用在许多方面，包括应用程序监控、媒体流、远程控制、桌面和移动应用等等 混合开发随着前端技术的发展，现在越来越多的桌面应用程序会嵌入一些Web技术来进行混合开发，结合了web端和传统桌面软件各自的优点。 全栈开发 权衡服务器、网络和服务器环境、数据建模、业务逻辑、API层、Action层、MVC、UI、用户体验等因素，找到适合当前环境应用开发的最优解。 开发者既要了解后端开发，也要了解前端开发。是“全方位”的工程师，熟悉服务端的同时又懂客户端用户体验。理解Web开发进程的每一个方面，同时又会就整体策略与最佳实践对相关方面提出建议与指导。 0x02-开发环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 WebStorm Node.js Git 0x03-方案设计方案A:单独开发Electron开发Electron直接开发，调用Node.js等相关API，编写应用 BlurAdmin开发BlurAdmin单独开发使用一些前端语言，使得变为一个Web网站项目 方案B:混合开发BlurAdmin开发完成后打包成Electron应用套用HTML5模板，使用Electron将网站变为应用 使用BlurAdmin打包压缩后的文件，结合Electron开发利用打包压缩后的BlurAdmin模板，将其变为应用，再在其基础上开发 使用BlurAdmin打包未压缩的文件，结合Electron开发利用打包未压缩的BlurAdmin模板，将其变为应用，再在其基础上开发 方案C:全栈开发BlurAdmin开发+使用BlurAdmin打包未压缩的文件+Electron开发在BlurAdmin模板基础上开发出网站，然后打包产生未压缩文件，结合Electron再次开发 0x04-实践操作下载源码 electron-v1.0.0（密码：dkes），解压改名为electron-v1.1.0，删除除main.js和package.json外其它文件 blur-admin-v1.0.0（密码：l48u）），解压改名为blur-admin-v1.1.0 将blur-admin-v1.1.0移到electron-v1.1.0文件夹中 修改文件 修改main.js中win.loadURL里的路径，使其指向release文件夹下index.html页面 注释掉mian.js中win.on()语句，避免重复加载整个页面 //调整页面大小后重新加载整个页面 //win.on(&apos;resize&apos;,() =&gt; { // win.reload(); //}) 修改package.json中name、vision、description main.jsconst {app, BrowserWindow} = require(&apos;electron&apos;); let win; let windowConfig = { width:800, height:600 }; function createWindow(){ win = new BrowserWindow(windowConfig); //加载index.html文件 win.loadURL(`file://${__dirname}/blur-admin-v1.1.0/release/index.html`); //开启调试工具 //win.webContents.openDevTools(); win.on(&apos;close&apos;,() =&gt; { //回收BrowserWindow对象 win = null; }); //调整页面大小后重新加载整个页面 //win.on(&apos;resize&apos;,() =&gt; { // win.reload(); //}) } app.on(&apos;ready&apos;,createWindow); app.on(&apos;window-all-closed&apos;,() =&gt; { app.quit(); }); app.on(&apos;activate&apos;,() =&gt; { if(win == null){ createWindow(); } }) package.json{ &quot;name&quot;: &quot;electron-v1.1.0&quot;, &quot;version&quot;: &quot;1.1.0&quot;, &quot;description&quot;: &quot;an electron application&quot;, &quot;main&quot;: &quot;main.js&quot;, &quot;build&quot;: { &quot;appId&quot;: &quot;com.xxx.app&quot;, &quot;win&quot;: { &quot;target&quot;: [ &quot;nsis&quot;, &quot;zip&quot; ] }, &quot;publish&quot;: [ { &quot;provider&quot;: &quot;generic&quot;, &quot;url&quot;: &quot;http://localhost:4000/version&quot; } ] }, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot;, &quot;start&quot;: &quot;electron .&quot;, &quot;dist&quot;: &quot;electron-builder --win --x64&quot; }, &quot;author&quot;: &quot;xiafei_xupt&quot;, &quot;license&quot;: &quot;ISC&quot; } 添加语句说明：由于BlurAdmin和Electron所用的模块有所不同，所以直接Electron直接引用BlurAdmin打包生成的文件是会报错的，故添加模块兼容语句，使其根据环境自动选择合适的模块，避免了模板不兼容情况的发生。 &lt;!--添加模块兼容语句--&gt; &lt;script&gt;if (typeof module === &apos;object&apos;) {window.module = module; module = undefined;}&lt;/script&gt; 启动应用浏览器中查看gulp serve:dist 注：blur-admin-v1.1.0目录下运行gulp serve:dist，既能查看BlurAdmin模板页面，又能生成打包后的release文件夹 Electron中查看electron . 0x05-总结分析单独开发优点：开发效率高，相关接口框架等比较成熟缺点：功能单一，先天不足，后期几乎无法扩充相关功能 混合开发优点：效率高，前后端混合开发，避免了前后端对接这一开发流程，缩短开发周期缺点：较难维护，高耦合低内聚 全栈开发（前后端分离开发）优点：前后端分离仍是当前主流开发模式，符合现代编程低耦合高内聚的要求，后端逻辑与页面显示完全解耦，容易维护与完善缺点：前后端分离是存在沟通成本，只有真正理解“全栈”，熟悉整个技术栈，权衡各个技术点与用户体验才有可能找到最优解 0x06-程序源码main.jsconst {app, BrowserWindow} = require(&apos;electron&apos;); let win; let windowConfig = { width:800, height:600 }; function createWindow(){ win = new BrowserWindow(windowConfig); //加载index.html文件 win.loadURL(`file://${__dirname}/blur-admin-v1.1.0/release/index.html`); //开启调试工具 //win.webContents.openDevTools(); win.on(&apos;close&apos;,() =&gt; { //回收BrowserWindow对象 win = null; }); //调整页面大小后重新加载整个页面 //win.on(&apos;resize&apos;,() =&gt; { // win.reload(); //}) } app.on(&apos;ready&apos;,createWindow); app.on(&apos;window-all-closed&apos;,() =&gt; { app.quit(); }); app.on(&apos;activate&apos;,() =&gt; { if(win == null){ createWindow(); } }) package.json{ &quot;name&quot;: &quot;electron-v1.1.0&quot;, &quot;version&quot;: &quot;1.1.0&quot;, &quot;description&quot;: &quot;an electron application&quot;, &quot;main&quot;: &quot;main.js&quot;, &quot;build&quot;: { &quot;appId&quot;: &quot;com.xxx.app&quot;, &quot;win&quot;: { &quot;target&quot;: [ &quot;nsis&quot;, &quot;zip&quot; ] }, &quot;publish&quot;: [ { &quot;provider&quot;: &quot;generic&quot;, &quot;url&quot;: &quot;http://localhost:4000/version&quot; } ] }, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot;, &quot;start&quot;: &quot;electron .&quot;, &quot;dist&quot;: &quot;electron-builder --win --x64&quot; }, &quot;author&quot;: &quot;xiafei_xupt&quot;, &quot;license&quot;: &quot;ISC&quot; } index.html&lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot; ng-app=&quot;BlurAdmin&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt; &lt;title&gt;Blur Admin&lt;/title&gt; &lt;!--添加模块兼容语句--&gt; &lt;script&gt;if (typeof module === &apos;object&apos;) {window.module = module; module = undefined;}&lt;/script&gt; &lt;link href=&apos;https://fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,400italic,500,500italic,700,700italic,900italic,900&amp;subset=latin,greek,greek-ext,vietnamese,cyrillic-ext,latin-ext,cyrillic&apos; rel=&apos;stylesheet&apos; type=&apos;text/css&apos;&gt; &lt;link rel=&quot;icon&quot; type=&quot;image/png&quot; sizes=&quot;16x16&quot; href=&quot;assets/img/favicon-16x16.png&quot;&gt; &lt;link rel=&quot;icon&quot; type=&quot;image/png&quot; sizes=&quot;32x32&quot; href=&quot;assets/img/favicon-32x32.png&quot;&gt; &lt;link rel=&quot;icon&quot; type=&quot;image/png&quot; sizes=&quot;96x96&quot; href=&quot;assets/img/favicon-96x96.png&quot;&gt; &lt;!-- build:css({.tmp/serve,src}) styles/vendor.css --&gt; &lt;!-- bower:css --&gt; &lt;!-- run `gulp inject` to automatically populate bower styles dependencies --&gt; &lt;!-- endbower --&gt; &lt;!-- endbuild --&gt; &lt;!-- build:css({.tmp/serve,src}) styles/app.css --&gt; &lt;!-- inject:css --&gt; &lt;!-- css files will be automatically insert here --&gt; &lt;!-- endinject --&gt; &lt;!-- endbuild --&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;body-bg&quot;&gt;&lt;/div&gt; &lt;main ng-if=&quot;$pageFinishedLoading&quot; ng-class=&quot;{ &apos;menu-collapsed&apos;: $baSidebarService.isMenuCollapsed() }&quot;&gt; &lt;ba-sidebar&gt;&lt;/ba-sidebar&gt; &lt;page-top&gt;&lt;/page-top&gt; &lt;div class=&quot;al-main&quot;&gt; &lt;div class=&quot;al-content&quot;&gt; &lt;content-top&gt;&lt;/content-top&gt; &lt;div ui-view autoscroll=&quot;true&quot; autoscroll-body-top&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;footer class=&quot;al-footer clearfix&quot;&gt; &lt;div class=&quot;al-footer-right&quot;&gt;Created with &lt;i class=&quot;ion-heart&quot;&gt;&lt;/i&gt;&lt;/div&gt; &lt;div class=&quot;al-footer-main clearfix&quot;&gt; &lt;div class=&quot;al-copy&quot;&gt;Blur Admin 2016&lt;/div&gt; &lt;ul class=&quot;al-share clearfix&quot;&gt; &lt;li&gt;&lt;i class=&quot;socicon socicon-facebook&quot;&gt;&lt;/i&gt;&lt;/li&gt; &lt;li&gt;&lt;i class=&quot;socicon socicon-twitter&quot;&gt;&lt;/i&gt;&lt;/li&gt; &lt;li&gt;&lt;i class=&quot;socicon socicon-google&quot;&gt;&lt;/i&gt;&lt;/li&gt; &lt;li&gt;&lt;i class=&quot;socicon socicon-github&quot;&gt;&lt;/i&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/footer&gt; &lt;back-top&gt;&lt;/back-top&gt; &lt;/main&gt; &lt;div id=&quot;preloader&quot; ng-show=&quot;!$pageFinishedLoading&quot;&gt; &lt;div&gt;&lt;/div&gt; &lt;/div&gt; &lt;!-- build:js(src) scripts/vendor.js --&gt; &lt;!-- bower:js --&gt; &lt;!-- run `gulp inject` to automatically populate bower script dependencies --&gt; &lt;!-- endbower --&gt; &lt;!-- endbuild --&gt; &lt;!--去掉引用谷歌maps.js--&gt; &lt;!--&lt;script type=&quot;text/javascript&quot; src=&quot;http://maps.google.com/maps/api/js?sensor=false&quot;&gt;&lt;/script&gt;--&gt; &lt;!-- build:js({.tmp/serve,.tmp/partials,src}) scripts/app.js --&gt; &lt;!-- inject:js --&gt; &lt;!-- js files will be automatically insert here --&gt; &lt;!-- endinject --&gt; &lt;!-- inject:partials --&gt; &lt;!-- angular templates will be automatically converted in js and inserted here --&gt; &lt;!-- endinject --&gt; &lt;!-- endbuild --&gt; &lt;/body&gt; &lt;/html&gt; 源码打包electron-v1.1.0（密码：tmb5） 0x07-参考资料 Electron官网 BlurAdmin官网 Electron开发流程 BlurAdmin模板学习","categories":[],"tags":[{"name":"Electron","slug":"Electron","permalink":"http://yoursite.com/tags/Electron/"}]},{"title":"BlurAdmin模板学习","slug":"BlurAdmin模板学习","date":"2018-08-12T16:00:00.000Z","updated":"2018-10-05T23:09:18.000Z","comments":true,"path":"BlurAdmin模板学习/","link":"","permalink":"http://yoursite.com/BlurAdmin模板学习/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践验证 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章前言文章目的 研究HTML界面开发框架以及相关开发语言 了解BlurAdmin模板的项目结构和简单使用 熟练定制BlurAdmin模板配色、主题、页面、组件等 文章前景 学习BlurAdmin模板可以加深对前端的理解 定制模板、修改组件可以得到合适的模板，缩减项目开发周期 0x01-知识储备BlurAdmin基础BlurAdmin介绍 BlurAdmin是Angular前端Admin Dashboard模板。这意味着您可以在图表，图表表格中看到的所有数据都在Javascript中进行硬编码。您可以无限制地使用任何您想要的后端。 目前很多业务应用程序都有一些管理界面。有时它并不那么明显，但很多Web应用程序都有仪表板，带有面板，图表分析。 BlurAdmin旨在引导您的产品开发，并为构建原型甚至生产就绪应用程序提供生态系统。 尽管像Bootstrap这样的框架提供了许多组件，但通常它们还不足以构建真实世界的应用程序。此模板带有许多流行的UI组件和统一的配色方案。 BlurAdmin文档主要介绍了BlurAdmin模板的特点、安装、定制等一些问题，是BlurAdmin学习必备的文档。 BlurAdmin特点 响应式布局 高分辨率 Bootstrap CSS 框架 Sass Gulp构建 AngularJS jQuery Jquery ui 图表（amChart，Chartist，Chart.js，Morris） 地图（Google，Leaflet，amMap） 总之，其图形界面比较炫酷，图表分析功能强大，各种组件比较齐全。 Node.js基础 Node.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境。 Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型，使其轻量又高效。 Node.js 的包管理器 npm，是全球最大的开源库生态系统。 Node.JS逐渐发展成一个成熟的开发平台，吸引了许多开发者。有许多大型高流量网站都采用Node.JS进行开发，此外，开发人员还可以使用它来开发一些快速移动Web框架。 除了Web应用外，Node.JS也被应用在许多方面，包括应用程序监控、媒体流、远程控制、桌面和移动应用等等 0x02-测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 PostgreSQL WebStorm Node.js Git 0x03-方案设计改变配色方案修改BlurAdmin模板的背景色，文本颜色等 启用模糊主题计算面板的初始背景偏移，改变一些颜色，使主题变得模糊 分析项目结构详细了解该模板目录下每个文件/文件夹的内容、功能等 创建新页面创建一个新的HTML页面，写入内容：Hello BlurAdmin ! 修改侧边栏组件使用多种方式配置侧边栏菜单，使得主页可以打开所创建的页面 0x04-实践验证模板准备下载 GitHub官网下载 git clone https://github.com/akveo/blur-admin.git BlurAdmin官网下载 如果您在安装node.js和/或其他工具以在您的计算机上构建和运行BlurAdmin时遇到问题而您只想下载html / js / css文件，则可以在此页面上找到要下载的链接。 可以在{ARCHIVE_ROOT}/blur-admin-{VERSION}/dev-release目录中找到开发（非压缩）文件。压缩文件在{ARCHIVE_ROOT}/blur-admin-{VERSION}/release目录中。然后您可以打开index.html以查看您的本地版本。 请注意：由于chrome不支持AJAX请求，因此当您通过文件协议打开HTML文件时，可能需要禁用Web安全性才能运行模板。 OS X 上的示例命令： open -a Google\\ Chrome --args --disable-web-security --user-data-dir=~/ChromeDevSession/ Linux上的示例命令 google-chrome --user-data-dir=&quot;~/chrome-dev-session&quot; --disable-web-security Windows上的示例命令 start chrome --user-data-dir=&quot;C:/Chrome dev session&quot; --disable-web-security 下载链接 BlurAdmin 1.3.1BlurAdmin 1.2.0 安装cd blur-admin npm install //安装所需组件 npm install -g yo gulp bower //安装bower npm install -g generator-gulp-angular //安装generator-gulp-angular 注： 安装node如果没有翻墙的话可能会安装失败，使用淘宝镜像代替： npm install -g cnpm --registry=https://registry.npm.taobao.org 然后用 cnpm install 处理 去掉引用谷歌maps.js ### 去掉启动app.js的延迟时间设置和AmCharts预加载 启动 要在开发模式下运行本地副本，请执行： gulp serve 此脚本应在默认浏览器中自动打开模板。 要在生产模式下运行本地副本，请执行： gulp serve:dist 注：release文件即为发布所需文件 模板主页注：默认浅色主题 改变配色方案默认情况下，BlurAdmin有两种颜色配置文件：mint和blur。那么如何创建自己的颜色配置文件呢？假设你想让BlurAdmin变暗。首先，建议将一些colorscheme文件作为基础。对于浅色主题，建议采用src/sass/theme/conf/colorScheme/_mint.scss文件；对于黑暗主题，建议采用src/sass/theme/conf/colorScheme/_blur.scss文件。1）如果想要黑暗主题。复制src/sass/theme/conf/colorScheme/_blur.scss到src/sass/theme/conf/colorScheme/_dark.scss。 2）同时需修改colorscheme文件src/sass/theme/common.scs。请替换 @import &apos;theme/conf/colorScheme/mint&apos;; 至 @import &apos;theme/conf/colorScheme/dark&apos;; 3）现在可以开始改变颜色了。例如，为展示不同颜色的一些内容，可在_dark.scss文件中更改了5个主要变量： $default: rgba(#000000, 0.2); //Panel background color $body-bg: #F0F3F4; // Body background color $default-text: #ffffff; // Default text color $help-text: #eeeeee; // Default subtext color $label-text: #ffffff; // Text for labels in forms (Basically it should be equal to default-text in most cases) 4）完成此操作后，需要在构建图表和其他JavaScript组件时设置javascript以使用相同的颜色。为此，将以下代码添加到某个配置块，例如src/app/theme/theme.config.js： baConfigProvider.changeColors({ default: &apos;rgba(#000000, 0.2)&apos;, defaultText: &apos;#ffffff&apos;, dashboard: { white: &apos;#ffffff&apos;, }, }); 基本上就是这样！现在应用程序如下所示： 如需进一步修改，请参考 Colorscheme scss文件（src/sass/theme/conf/colorScheme/路径下） src/app/theme/theme.configProvider.js 了解哪些javascript颜色可以更改 启用模糊主题如果要将主题切换为模糊，则需要执行以下3个简单步骤： 1）模糊主题需要一些javascript来计算面板的初始背景偏移。这就是为什么你需要做的第一件事是启用该代码。这应该在Angular 配置块中完成。例如，您可以添加以下行src/app/theme/theme.config.js： baConfigProvider.changeTheme({blur: true}); 2）同样你需要改变一些颜色。。对于模糊主题，可以使用以下配置 baConfigProvider.changeColors({ default: &apos;rgba(#000000, 0.2)&apos;, defaultText: &apos;#ffffff&apos;, dashboard: { white: &apos;#ffffff&apos;, }, }); 3）CSS也应该重新编译。在运行构建命令之前，建议切换到模糊颜色配置文件。为此，请替换文件中的主题src/sass/theme/common.scss： @import &apos;theme/conf/colorScheme/mint&apos;; 至 @import &apos;theme/conf/colorScheme/blur&apos;; 或 @import &apos;theme/conf/colorScheme/dark&apos;; 主题效果 注：如果想使用一些不同的背景，请替换以下图像： src/app/assets/img/blur-bg.jpg （主要背景图片） src/app/assets/img/blur-bg-blurred.jpg （面板上使用的模糊背景图像） 分析项目结构该模板的目录结构如下： ├── bower.json &lt;- front-end library dependencies//前端库依赖 ├── gulpfile.js &lt;- main task runner file//主任务运行文件 ├── package.json &lt;- mostly task runner dependencies//许多任务运行依赖 ├── docs/&lt;- wintersmith documentation generator//wintersmith文档生成器 ├── gulp/&lt;- build tasks//项目构建 ├── src/ &lt;- main front-end assets//源代码 │ ├── 404.html │ ├── auth.html │ ├── index.html &lt;- main app dashboard page//主应用程序页面 │ ├── reg.html │ ├── app/&lt;- angular application files//angular应用程序文件 │ │ ├── app.js &lt;- angular application entry point. Used for managing dependencies//angular应用程序入口. 用于管理依赖项 │ │ ├── pages/ &lt;- UI router pages. Pages created for demonstration purposes. Put your application js and html files here//UI路由页面,为演示目的创建的页。将应用程序 js 和 html 文件放在这里 │ │ ├── theme/ &lt;- theme components. Contains various common widgets, panels which used across application//主题组件. 包含各种常用的小部件, 跨应用使用的模板 │ ├── assets/ &lt;- static files (images, fonts etc.)//静态文件 (图像, 字体等) │ ├── sass/ &lt;- sass styles//sass样式文件 │ │ ├── app/ &lt;- application styles. Used mostly for demonstration purposes. Put your app styles here.//应用程序样式。主要用于演示目的。将应用程序样式放在这里 │ │ ├── theme/ &lt;- theme styles. Used to customize bootstrap and other common components used in tempate.//主题样式。用于自定义bootstrap和模板中使用的其他常用组件。 在该模板中，尝试分离主题图层和表示层。大多数其他模板都将它们结合起来。这就是为什么当开始使用它们时，很难删除不需要的东西。 创建新页面BlurAdmin使用Angular UI路由器进行导航。这意味着要创建基本配置ui-router状态所需的新页面。 建议将页面放在单独的模块中。这将允许在将来根据需要轻松关闭某些页面。假设要创建一个标题为“我的新页面”的空白页面 1）创建一个新目录来包含新页面src/app/pages。叫这个目录myNewPage。然后创建空白角度模块以包含页面中名为’myNewPage.module.js’的内容src/app/pages/myNewPage： (function () { &apos;use strict&apos;; angular.module(&apos;BlurAdmin.pages.myNewPage&apos;, []) .config(routeConfig); /** @ngInject */ function routeConfig() { } })(); 2）然后在my-new-page.html里面创建一个空的html文件src/app/pages/myNewPage，写入内容：Hello BlurAdmin !3）最后为这个页面创建ui路由器状态。为此，需要修改第2步创建的module.js文件： (function () { &apos;use strict&apos;; angular.module(&apos;BlurAdmin.pages.myNewPage&apos;, []) .config(routeConfig); /** @ngInject */ function routeConfig($stateProvider) { $stateProvider .state(&apos;myNewPage&apos;, { url: &apos;/myNewPage&apos;, templateUrl: &apos;app/pages/myNewPage/my-new-page.html&apos;, title: &apos;My New Page&apos;, sidebarMeta: { order: 800, }, }); } })(); 修改侧边栏组件边栏用于在应用程序中提供方便的导航方式。应用程序仅支持每个角度应用程序一个侧栏。这意味着侧边栏基本上是一个单一对象。目前侧栏支持1级和2级子菜单。 可以使用baSidebar指令创建补充工具栏： &lt;ba-sidebar&gt;&lt;/ba-sidebar&gt; 目前它仅支持javascript配置。虽然可以手动配置或通过ui-router状态配置。这种方法可以一起使用，也可以一次使用一种。 1）手动配置对于手动配置，需要baSidebarServiceProvider在角度配置块中使用提供程序。提供者有addStaticItem方法，它接收menuItem对象作为参数，它可以具有以下属性： 属性 类型 含义 title String 菜单项的名称 icon String 要在标题附近显示的图标（它是一个类名） stateRef String ui-router 与此菜单项关联的状态 fixedHref String 与此菜单项关联的网址 blank String 指定是否应在新浏览器选项卡中打开以下Url subMenu Array of menu items 要显示为下一级子菜单的菜单项列表 手动配置示例： baSidebarServiceProvider.addStaticItem({ title: &apos;Menu Level 1&apos;, icon: &apos;ion-ios-more&apos; }); 例如启动效果 2）路由配置默认情况下，侧栏会遍历您在应用程序中定义的所有ui-router状态，并sidebarMeta在其中搜索对象。对于具有此属性的每个州，都会创建侧边栏元素。 各州按等级分组。这意味着如果某个状态存在父抽象状态并且它们都具有sidebarMeta属性，则它将显示为该抽象状态菜单项的子项。 该物品的名称取自state的title财产。示例状态配置，它将向侧栏添加项： $stateProvider .state(‘dashboard’, { url: ‘/dashboard’, templateUrl: ‘app/pages/dashboard/dashboard.html’, title: ‘Dashboard’, sidebarMeta: { icon: ‘ion-android-home’, order: 0, }, }); 例如 sidebarMeta 对象可以具有以下属性： 属性 类型 含义 icon String 要在标题附近显示的图标（它是一个类名） order Number 当前层次结构中元素的顺序 路由注册 启动效果 0x05-总结分析 熟悉了BlurAdmin模板，加深了对前端开发的理解 通过对BlurAdmin模板配色、主题、页面、组件等模块的使用，使得定制模板变得简单 其HTML、JavaScript、CSS等语言的操作和一般前端开发一样，当然也可以在后端通过Node.js调用一些模块来扩充操作 0x06-程序源码为避免与原模板命名重复，改名为blur-admin-v1.0.0（密码：l48u） 0x07-参考资料 一款基于angularjs、bootstrap免费的后台模板blur-admin使用 Mint version demo Blur version demo GitHub地址 BlurAdmin文档 BlurAdmin官网","categories":[],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://yoursite.com/tags/PostgreSQL/"}]},{"title":"PostgreSQL操作接口","slug":"PostgreSQL操作接口","date":"2018-08-06T12:54:27.000Z","updated":"2018-08-11T05:46:28.000Z","comments":true,"path":"PostgreSQL操作接口/","link":"","permalink":"http://yoursite.com/PostgreSQL操作接口/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践验证 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章前言文章目的 日志分析中展示要求、界面框架数据库查询接口 PostgreSQL和Node.js、Electron应用之间的连接、通信、封装、优化、打包 文章前景 对于Node.js调用PostgreSQL接口的封装有利于面向对象的开发 通过Electron使用Node.js模块和数据库通信，可以加深对Electron框架的理解 对于Node.js和数据库通信的掌握可以打通前后端的界限，有利于形成全栈思维 0x01-知识储备PostgreSQL基础 自从MySQL被Oracle收购以后，PostgreSQL逐渐成为开源关系型数据库的首选。 PostgreSQL是一个功能强大的开源对象关系数据库系统，它使用并扩展了SQL语言，并结合了许多安全存储和扩展最复杂数据工作负载的功能。 PostgreSQL的起源可以追溯到1986年，作为加州大学伯克利分校POSTGRES项目的一部分，并在核心平台上进行了30多年的积极开发。 PostgreSQL凭借其经过验证的架构，可靠性，数据完整性，强大的功能集，可扩展性以及软件背后的开源社区的奉献精神赢得了良好的声誉，以始终如一地提供高性能和创新的解决方案。 PostgreSQL在所有主要操作系统上运行，自2001年以来一直是符合ACID标准的，并且具有强大的附加功能，例如流行的PostGIS地理空间数据库扩展器。毫无疑问，PostgreSQL已经成为许多人和组织的首选开源关系数据库。 Node.js基础 Node.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境。 Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型，使其轻量又高效。 Node.js 的包管理器 npm，是全球最大的开源库生态系统。 Node.JS逐渐发展成一个成熟的开发平台，吸引了许多开发者。有许多大型高流量网站都采用Node.JS进行开发，此外，开发人员还可以使用它来开发一些快速移动Web框架。 除了Web应用外，Node.JS也被应用在许多方面，包括应用程序监控、媒体流、远程控制、桌面和移动应用等等 0x02-测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 Debian 9系统 PostgreSQL Node.js 注：由于PostgreSQL操作接口使用Node.js实现，而Windows 10系统和Debian 9系统对于Node.js的支持完全一样，故此处只在Windows 10系统上进行测试 0x03-方案设计Electron通过Node.js使用 pg 模块和PostgreSQL连接 客户端方式每一次数据访问请求都必须经历建立数据库连接、打开数据库、存取数据和关闭数据库连接等步骤，而连接并打开数据库是一件既消耗资源又费时的工作，如果频繁发生这种数据库操作，系统的性能必然会急剧下降，甚至会导致系统崩溃。适用：客户端连接次数少、重复访问率低的数据 注：本文数据库操作接口使用客户端方式实现 连接池方式连接池允许应用程序从连接池中获得一个连接并使用这个连接，而不需要为每一个连接请求重新建立一个连接。一旦一个新的连接被创建并且放置在连接池中，应用程序就可以重复使用这个连接而不必实施整个数据库连接创建过程。当应用程序请求一个连接时，连接池为该应用程序分配一个连接而不是重新建立一个连接；当应用程序使用完连接后，该连接被归还给连接池而不是直接释放。适用：大量、重复访问率高的数据 0x04-实践验证创建数据库 插入数据 安装pg模块Node.js中有专门的模块可以用来连接PostgreSql数据库，首先从npm资源库中获取数据库模块，名为”pg”： npm install pg npm ls --depth 0//查看已安装模块 接口测试增删改查接口测试 SELECT接口测试对增删改查接口中查询接口进行了改进 Node.js测试 Electron测试 0x05-总结分析 在函数实现里面，我们采用了回调函数的形式实现，根据输出信息可以很号的看出node.js的主要特性：非阻塞 数据库的查询接口改进后使用指定行列进行操作，查询比较具体，由于Node.js使用非阻塞式 I/O 的模型，故多个查询之间不会冲突 PostgreSQL操作接口是连接了前后端之间的桥梁，使得前端页面和后端数据库之间的通信变得简单直观。 0x06-程序源码创建数据库脚本create table Log_Inf(id character varying(10),type character varying(10),rank character varying(10)); 插入数据脚本insert into Log_Inf values(&apos;1&apos;,&apos;C01&apos;,&apos;G01&apos;); insert into Log_Inf values(&apos;2&apos;,&apos;C02&apos;,&apos;G02&apos;); insert into Log_Inf values(&apos;3&apos;,&apos;C03&apos;,&apos;G03&apos;); insert into Log_Inf values(&apos;4&apos;,&apos;C04&apos;,&apos;G04&apos;); 增删改查操作的封装Client.jsvar f = require(&apos;./PG&apos;); var pg = require(&apos;pg&apos;); //var conString = &quot;tcp://postgres:postgres@localhost/test&quot;; var conString = &quot;tcp://postgres:111111@localhost:5432/test&quot;; var client = new pg.Client(conString); var value = [&apos;9&apos;,&apos;C09&apos;,&apos;G09&apos;]; insertSQLString = &apos;insert into Log_Inf values($1,$2,$3)&apos;; selectSQLString = &apos;select * from Log_Inf&apos;; updateSQLString = &quot;update Log_Inf set TYPE=&apos;C07&apos; where ID=&apos;4&apos;&quot;; deleteSQLString = &quot;delete from Log_Inf where ID=&apos;9&apos;&quot;; client.connect(function(error, results) { if(error){ console.log(&apos;ClientConnectionReady Error: &apos; + error.message); client.end(); return; } console.log(&apos;connection success...\\n&apos;); f._select(client,selectSQLString); f._insert(client,insertSQLString,value); f._update(client,updateSQLString); f._delete(client,deleteSQLString); }); PG.jsfunction _insert(client,insertSQLString,value) { console.log(&quot;insert beginning&quot;); client.query(insertSQLString, value, function(error, results) { if(error) { console.log(&quot;ClientReady Error: &quot; + error.message), client.end(); return; } console.log(&apos;Inserted: &apos; + results.affectedRows + &apos; row.&apos;), console.log(&apos;insert success...\\n&apos;); }); console.log(&quot;insert end\\n&quot;); } function _select(client,selectSQLString) { console.log(&quot;select beginning&quot;); client.query(selectSQLString, function selectCb(error, results, fields) { console.log(&quot;in select callback function&quot;); if (error) { console.log(&apos;GetData Error: &apos; + error.message), client.end(); return; } if(results.rowCount &gt; 0) { var firstResult, resultSet = &apos;&apos;; for(var i = 0, len = results.rowCount; i &lt; len; i++) { firstResult = results.rows[i]; resultSet += &apos;id:&apos; + firstResult[&apos;id&apos;] + &apos; &apos; + &apos;type:&apos; + firstResult[&apos;type&apos;] + &apos; &apos; + &apos;rank:&apos; + firstResult[&apos;rank&apos;] + &apos;\\n&apos;; } } console.log(resultSet); /* 添加功能：使查询结果集返回到客户端并保证此函数的通用性. */ }); console.log(&quot;select end\\n&quot;); } function _update(client,updateSQLString) { console.log(&quot;update beginning&quot;); client.query(updateSQLString,function(error, results) { if(error) { console.log(&quot;ClientReady Error: &quot; + error.message), client.end(); return; } console.log(&apos;update success...\\n&apos;); }); console.log(&quot;update end\\n&quot;); } function _delete(client,deleteSQLString) { console.log(&quot;delete beginning&quot;); client.query(deleteSQLString, function(error, results) { if(error) { console.log(&quot;ClientReady Error: &quot; + error.message), client.end(); return; } console.log(&apos;delete success...\\n&apos;); }); console.log(&quot;delete end\\n&quot;); } exports._insert = _insert; exports._select = _select; exports._update = _update; exports._delete = _delete; SELECT接口的封装Node.js测试Client.jsvar f = require(&apos;./SELECT&apos;); var pg = require(&apos;pg&apos;); var conString = &quot;tcp://postgres:111111@localhost:5432/test&quot;;//1.连接 var client = new pg.Client(conString); Table_Name=&apos;Log_Inf&apos;;//2.表名 Row_Number=0;//2.行数，默认从0开始 Col_Name=&apos;id&apos;;//2.列名 client.connect(function(error, results) { if(error){ console.log(&apos;ClientConnectionReady Error: &apos; + error.message); client.end(); return; } //f._select(client,Table_Name,Row_Number,Col_Name); f._select(client,&apos;Log_Inf&apos;,3,&apos;rank&apos;);//2.all }); SELECT.jsfunction _select(client,Table_Name,Row_Number,Col_Name) { selectSQLString = &apos;select * from &apos;+Table_Name; client.query(selectSQLString, function selectCb(error, results, fields) { if (error) { console.log(&apos;GetData Error: &apos; + error.message), client.end(); return; } if(results.rowCount &gt; 0) { resultSet = results.rows[Row_Number][Col_Name]; } console.log(resultSet); /* 添加功能：使查询结果集返回到客户端并保证此函数的通用性. */ }); } exports._select = _select; 打包后的Node.js测试SELECT接口 密码：mg3w Electron测试测试代码是在我写的Electron开发流程中的electron-v1.0.0（密码：dkes）基础上进行修改 修改方式： electron-v1.0.0文件夹重命名为Electron_PostgreSQL，并将Node.js测试中SELECT.js和Client.js文件放到Electron_PostgreSQL的文件夹下 在index.html的body标签中加入： &lt;div&gt; 数据库数据： &lt;span id=&quot;pg_data&quot;&gt;&lt;/span&gt; &lt;script src=&quot;./Client.js&quot;&gt;&lt;/script&gt; &lt;/div&gt; 在SELECT.js中console.log(&#39;resultSet&#39;);的下一行加入 ： document.getElementById(&apos;pg_data&apos;).innerHTML = resultSet; 打包后的Electron测试:Electron_PostgreSQL(密码：8hcf) 0x07-参考资料 PostgreSQL 官网 Node.js 中文网 Node.js v10.7.0 文档 Node.js 中文网 Electron 官网","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yoursite.com/tags/JavaScript/"},{"name":"实习","slug":"实习","permalink":"http://yoursite.com/tags/实习/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://yoursite.com/tags/PostgreSQL/"},{"name":"Electron","slug":"Electron","permalink":"http://yoursite.com/tags/Electron/"}]},{"title":"日志分析及数据库表的设计","slug":"日志分析及数据库表的设计","date":"2018-07-29T16:00:00.000Z","updated":"2018-09-23T03:30:56.000Z","comments":true,"path":"日志分析及数据库表的设计/","link":"","permalink":"http://yoursite.com/日志分析及数据库表的设计/","excerpt":"","text":"赵岩——2018-08-02——项目周报告——日志分析及数据库表的设计 0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践验证 0x05-总结分析 0x06-程序源码 0x07-参考资料 项目要求日志分析大量日志情况下，写程序（服务形式），定期不断产生日志消息，写入数据库。消息内容至少包括有主机分组、主机id、日志时间、日志类型、日志等级、日志消息。 数据库设计在大量的电脑日志情况下，HTML应用对日志进行条件查询、分析、产生各类型报表。数据库设计要依照数据参考和数据展示来进行设计。 数据操作 在产生大量日志数据的情况下需要项数据库中写入这些数据，而要写入的数据不止日志消息。要知道是哪台计算机产生的日志消息，需要主机的id和主机的分组，而产生的日志包括日志的类型、日志等级、和日志的消息内容，还有日志产生的时间。 在测试阶段，需要把日志的信息写入数据库即有一个数据库表的插入操作，此操作只需要在后台实现，利用postgreSQL数据库桌面工具写入测试数据。还有一个数据查询操作，此操作需要在HTML界面进行展示，将查询的数据通过整合，按照一定的要求进行展示。 知识储备数据库简介数据库可以实现数据共享、减少数据的冗余度、提高数据的独立性、使得数据实现集中控制、增加数据一致性和可维护性、有利于数据的故障恢复。 PostgreSQL基础 PostgreSQL是一个功能强大的开源对象关系数据库系统，它使用并扩展了SQL语言，并结合了许多安全存储和扩展最复杂数据工作负载的功能。 PostgreSQL的起源可以追溯到1986年，作为加州大学伯克利分校POSTGRES项目的一部分，并在核心平台上进行了30多年的积极开发。 PostgreSQL凭借其经过验证的架构，可靠性，数据完整性，强大的功能集，可扩展性以及软件背后的开源社区的奉献精神赢得了良好的声誉，以始终如一地提供高性能和创新的解决方案。 PostgreSQL在所有主要操作系统上运行，自2001年以来一直是符合ACID标准的，并且具有强大的附加功能，例如流行的PostGIS地理空间数据库扩展器。毫无疑问，PostgreSQL已经成为许多人和组织的首选开源关系数据库。 数据库视图视图的概述视图是从一个或者多个表中导出的，它的行为与表非常相似，但视图是一个虚拟表。在视图中，用户可以使用SELECT语句查询语句，以及使用INSERT、UPDATE、和DELETE语句修改记录。在PostgreSQL中，使用视图可以使用户操作方便，而且可以保障数据库系统的安全。我们通过视图看到的数据只是存放在基本表中的数据。当对通过视图看到的数据进行修改时，相应的基本表的数据也要发生变化，同时，若基本表的数据发生变化，则这种变化也可以自动地反映到视图中。 视图的作用与直接从数据库表中读取数据相比，视图具有以下优点： 简单化看到的就是需要的。视图不仅可以简单化用户对数据的理解，也可以简化他们的操作。那些经常使用的查询可以被定义为视图，从而使得用户不必为以后的操作每次指定全部的条件。 安全性通过视图，用户只能查询和修改他们所能见到的数据。数据库中的其他数据则既看不见、也取不到。数据库授权命令可以使每个用户对数据库的检索限制到特定的数据库对象上，但不能授权到数据库特殊的行和特殊的列上。通过视图，用户可以被限制在数据的不同子集上，如下：● 使用权限可被限制在基表的行的子集上。● 使用权限可被限制在基表的列的子集上。● 使用权限可被限制在基表的行和列的子集上。● 使用权限可被限制在多个基表的连接所限定的行上。● 使用权限可被限制在基表中的数据的统计汇总上。● 使用权限可被限制在另一视图的一个子集上，或是一些视图和基表合并后的子集上。 逻辑数据独立性视图可以帮助用户屏蔽真实表结构变化带来的影响。 数据库表设计数据库表的设计根据提供的数据进行分析，由于现阶段只是前期的测试阶段，所采用的数据不是最终的数据，只是项目测试需要的数据，而且日志又分了等级和类型，主机也有自己的分组，我就考虑将主机分组、日志类型和日志等级分别建表，便于以后的修改，于是乎就一共有四张表产生。分别为：日志表、类型表、等级表和主机分组表（红色下划线表示主键，蓝色下划线表示外键） 类型表（日志类型、类型名称） 等级表（日志等级、等级名称） 主机分组表（主机分组、分组名称） 日志表（主机id、日志类型、日志等级、日志时间、日志消息、主机分组） 字段类型设计其中各个表的字段大多对应的是计算机产生的数据，大多数应为字符串，字段的对应的类型再次设置为 character varying ，这个类型为可变长的字符串型，日志时间设置为date类型。 测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 Debian 9系统 PostgreSQL 注：由于PostgreSQL操作使用pgAdmin实现，而Windows 10系统使用pgAdmin 4，Debian 9系统使用pgAdmin3，两者几乎完全一样，故此处只在Windows 10系统上进行测试 创建数据库表类型表的创建语句CREATE TABLE public.&quot;Class&quot; ( &quot;日志类型&quot; character varying COLLATE pg_catalog.&quot;default&quot; NOT NULL, &quot;类型名称&quot; character varying COLLATE pg_catalog.&quot;default&quot; NOT NULL, CONSTRAINT &quot;Class_pkey&quot; PRIMARY KEY (&quot;日志类型&quot;) ) WITH ( OIDS = FALSE ) TABLESPACE pg_default; ALTER TABLE public.&quot;Class&quot; OWNER to postgres; 等级表的创建语句CREATE TABLE public.&quot;Grade&quot; ( &quot;日志等级&quot; character varying COLLATE pg_catalog.&quot;default&quot; NOT NULL, &quot;等级名称&quot; character varying COLLATE pg_catalog.&quot;default&quot; NOT NULL, CONSTRAINT &quot;Grade_pkey&quot; PRIMARY KEY (&quot;日志等级&quot;) ) WITH ( OIDS = FALSE ) TABLESPACE pg_default; ALTER TABLE public.&quot;Grade&quot; OWNER to postgres; 主机分组表的创建语句CREATE TABLE public.&quot;Group&quot; ( &quot;主机分组&quot; character varying COLLATE pg_catalog.&quot;default&quot; NOT NULL, &quot;分组名称&quot; character varying COLLATE pg_catalog.&quot;default&quot; NOT NULL, CONSTRAINT &quot;Group_pkey&quot; PRIMARY KEY (&quot;主机分组&quot;) ) WITH ( OIDS = FALSE ) TABLESPACE pg_default; ALTER TABLE public.&quot;Group&quot; OWNER to postgres; 日志表创建语句CREATE TABLE public.&quot;Mess&quot; ( &quot;主机id&quot; character varying COLLATE pg_catalog.&quot;default&quot; NOT NULL, &quot;日志类型&quot; character varying COLLATE pg_catalog.&quot;default&quot; NOT NULL, &quot;日志等级&quot; character varying COLLATE pg_catalog.&quot;default&quot; NOT NULL, &quot;日志时间&quot; date NOT NULL, &quot;日志消息&quot; character varying COLLATE pg_catalog.&quot;default&quot; NOT NULL, &quot;主机分组&quot; character varying COLLATE pg_catalog.&quot;default&quot; NOT NULL, CONSTRAINT &quot;Mess_pkey&quot; PRIMARY KEY (&quot;主机id&quot;), CONSTRAINT &quot;CFkey&quot; FOREIGN KEY (&quot;日志类型&quot;) REFERENCES public.&quot;Class&quot; (&quot;日志类型&quot;) MATCH FULL ON UPDATE NO ACTION ON DELETE NO ACTION DEFERRABLE INITIALLY DEFERRED NOT VALID, CONSTRAINT &quot;Fkey&quot; FOREIGN KEY (&quot;主机分组&quot;) REFERENCES public.&quot;Group&quot; (&quot;主机分组&quot;) MATCH FULL ON UPDATE NO ACTION ON DELETE NO ACTION DEFERRABLE INITIALLY DEFERRED NOT VALID, CONSTRAINT &quot;GFkey&quot; FOREIGN KEY (&quot;日志等级&quot;) REFERENCES public.&quot;Grade&quot; (&quot;日志等级&quot;) MATCH FULL ON UPDATE NO ACTION ON DELETE NO ACTION DEFERRABLE INITIALLY DEFERRED NOT VALID ) WITH ( OIDS = FALSE ) TABLESPACE pg_default; ALTER TABLE public.&quot;Mess&quot; OWNER to postgres; 写入数据首先先确定日志类型、日志等级和主机分组的信息 类型表INSERT INTO public.&quot;Class&quot;( &quot;日志类型&quot;, &quot;类型名称&quot;) VALUES (&apos;C01&apos;, &apos;A&apos;),(&apos;C02&apos;,&apos;B&apos;),(&apos;C03&apos;,&apos;C&apos;),(&apos;C04&apos;,&apos;D&apos;); 等级表INSERT INTO public.&quot;Grade&quot;( &quot;日志等级&quot;, &quot;等级名称&quot;) VALUES (&apos;G01&apos;, &apos;A级&apos;),(&apos;G02&apos;,&apos;B级&apos;),(&apos;G03&apos;,&apos;C级&apos;),(&apos;G04&apos;,&apos;D级&apos;); 主机分组表INSERT INTO public.&quot;Group&quot;( &quot;主机分组&quot;, &quot;分组名称&quot;) VALUES (&apos;F01&apos;, &apos;A组&apos;),(&apos;F02&apos;,&apos;B组&apos;),(&apos;F03&apos;,&apos;C组&apos;),(&apos;F04&apos;,&apos;D组&apos;); 日志表INSERT INTO public.&quot;Mess&quot;( &quot;主机id&quot;, &quot;日志类型&quot;, &quot;日志等级&quot;, &quot;日志时间&quot;, &quot;日志消息&quot;, &quot;主机分组&quot;) VALUES(&apos;00000001&apos;,&apos;C01&apos;,&apos;G01&apos;,&apos;2018-03-14&apos;,&apos;asjdgahsfhdsvbjhdsvbcxnvvbjdfvbdsfjvbdsfbds&apos;, &apos;F01&apos;), (&apos;00000002&apos;,&apos;C02&apos;,&apos;G03&apos;,&apos;2018-03-14&apos;,&apos;asjdgahsfhdsvbjhdsvbcx215641462273412424&apos;,&apos;F04&apos;), (&apos;00000003&apos;,&apos;C04&apos;,&apos;G02&apos;,&apos;2018-03-21&apos;,&apos;12jdgahsfhdsvbjhdsvbcx215641462273412424&apos;,&apos;F03&apos;), (&apos;00000004&apos;,&apos;C03&apos;,&apos;G02&apos;,&apos;2018-03-26&apos;,&apos;12jdgahsfhd123456dsvbcx215641462273412424&apos;,&apos;F04&apos;), (&apos;00000005&apos;,&apos;C01&apos;,&apos;G04&apos;,&apos;2018-03-26&apos;,&apos;12jdgahsfhd123456dsvbcx215641462273412424&apos;,&apos;F02&apos;); 视图操作创建视图info_log视图的创建语句 CREATE OR REPLACE VIEW public.info_log AS SELECT &quot;Mess&quot;.&quot;主机id&quot;, &quot;Group&quot;.&quot;分组名称&quot;, &quot;Class&quot;.&quot;类型名称&quot;, &quot;Grade&quot;.&quot;等级名称&quot;, &quot;Mess&quot;.&quot;日志时间&quot;, &quot;Mess&quot;.&quot;日志消息&quot; FROM &quot;Mess&quot;, &quot;Group&quot;, &quot;Grade&quot;, &quot;Class&quot; WHERE &quot;Mess&quot;.&quot;主机分组&quot;::text = &quot;Group&quot;.&quot;主机分组&quot;::text AND &quot;Mess&quot;.&quot;日志类型&quot;::text = &quot;Class&quot;.&quot;日志类型&quot;::text AND &quot;Mess&quot;.&quot;日志等级&quot;::text = &quot;Grade&quot;.&quot;日志等级&quot;::text; ALTER TABLE public.info_log OWNER TO postgres; 视图查询通过视图进行所有日志信息的查询 SELECT &quot;主机id&quot;, &quot;分组名称&quot;, &quot;类型名称&quot;, &quot;等级名称&quot;, &quot;日志时间&quot;, &quot;日志消息&quot; FROM public.info_log; 总结分析 通过数据库表的设计和创建，加深了对数据库的理解，掌握了数据库基本操作技能 主键和外键的设置可以帮助我们理清各个表之间的关系，最后通过视图操作将其在一张表上显示，清晰明了 通过对视图的操作即可实现对各个表数据的操作，提升了操作效率 视图操作使得数据库其它表的修改变得方便、安全，通过视图，用户只能查询和修改他们所能见到的数据。 参考资料 PostgreSQL文档 PostgreSQL 9从零开始学","categories":[],"tags":[{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://yoursite.com/tags/PostgreSQL/"}]},{"title":"Electron开发流程","slug":"Electron开发流程","date":"2018-07-23T12:54:27.000Z","updated":"2018-10-06T01:40:42.000Z","comments":true,"path":"Electron开发流程/","link":"","permalink":"http://yoursite.com/Electron开发流程/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践操作 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章前言文章目的 使用Electron开发一个简单桌面应用Demo 了解Electron原理及开发逻辑、流程(编写→运行→打包) 文章前景 将网站构建为桌面应用程序，需求较为广泛 打通了B/S架构与跨平台桌面应用程序之间的界限 为后续开发复杂应用理清业务逻辑，探索开发方式 0x01-知识储备Node.js基础npm包管理安装：npm install moduleName # 安装模块到项目目录下 npm install -g moduleName # -g 的意思是将模块安装到全局，具体安装到磁盘哪个位置，要看 npm config prefix 的位置。 npm install -save moduleName # -save 的意思是将模块安装到项目目录下，并在package文件的dependencies节点写入依赖。 npm install -save-dev moduleName # -save-dev 的意思是将模块安装到项目目录下，并在package文件的devDependencies节点写入依赖 卸载：npm remove moduleName # 卸载项目目录下模块 npm remove -g moduleName # -g 的意思是全局卸载模块 npm remove -save moduleName # -save 的意思是卸载项目目录下模块，并在package文件的dependencies节点删除依赖。 npm remove -save-dev moduleName # -save-dev 的意思是卸载项目目录下模块 ，并在package文件的devDependencies节点删除依赖 注意：devDependencies 节点下的模块是我们在开发时需要用的，比如项目中使用的 gulp ，压缩css、js的模块。这些模块在我们的项目部署后是不需要的，所以我们可以使用 -save-dev 的形式安装。像 express 这些模块是项目运行必备的，应该安装在 dependencies 节点下，所以我们应该使用 -save 的形式安装。 package-lock.json 文件 锁定安装时的包的版本号，并且需要上传到git，以保证其他人在npm install时大家的依赖能保证一致 根据官方文档，这个package-lock.json 是在 npm install时候生成一份文件，用以记录当前状态下实际安装的各个npm package的具体来源和版本号。 npm是一个用于管理package之间依赖关系的管理器，它允许开发者在pacakge.json中间标出自己项目对npm各库包的依赖 Electron基础Electron介绍如果你可以建一个网站，你就可以建一个桌面应用程序。 Electron 是一个使用 JavaScript, HTML 和 CSS 等 Web 技术创建原生程序的框架，它负责比较难搞的部分，你只需把精力放在你的应用的核心上即可。 Electron文档由 指南、API参考、高级 组成，详细介绍了Electron的使用、接口、开发等一些了问题，是Electron学习必备的文档。 Electron特点Web技术Electron 基于 Chromium 和 Node.js, 让你可以使用 HTML, CSS 和 JavaScript 构建应用。这是一个整合了Node，Chromium，V8的一个框架，通过它可以使用JavaScript，HTML, CSS技术来开发桌面应用程序 开源Electron 是一个由 GitHub 及众多贡献者组成的活跃社区共同维护的开源项目。 跨平台Electron 兼容 Mac, Windows 和 Linux， 它构建的应用可在这三个操作系统上面运行。 混合开发随着前端技术的发展，现在越来越多的桌面应用程序会嵌入一些Web技术来进行混合开发，结合了web端和传统桌面软件各自的优点。 0x02-测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 PostgreSQL Node.js 0x03-方案设计electron-packager打包创建一个简单页面，通过Electron打开、打包、更改图标、整合成安装包、更新 electron-builder打包进一步优化，使得可以打包成安装程序，生成文件尽可能小，并且支持自动升级 0x04-实践操作Electron安装由于国外镜像不能访问的原因，所以使用国内淘宝npm镜像进行安装。 npm install -g package --registry=https://registry.npm.taobao.org 也可以使用淘宝NPM开发的cnpm进行package的安装 //首先安装cnpm npm install -g cnpm --registry=https://registry.npm.taobao.org //使用cnpm进行安装，使用方法和npm相同，全局安装 cnpm install -g electron //查看electron版本 electron -v 使用npm通过淘宝镜像安装和cnpm安装，均可成功安装electron（原electron-prebuilt）。 创建应用创建一个electron应用。我们现在仅仅需要3个文件。 index.html main.js package.json index.html使我们想要显示的页面，main.js为此应用的入口，package.json为npm项目的配置文件。 新建一个名为electron的文件夹，进入项目目录进行初始化产生package.json文件 mkdir electron cd electron npm init 使得package.json为中名称为：HelloElectron；描述为：a simple application；scripts中添加”start”: “electron .”；署名为：xiafei_xupt,其余默认即可 新建一个index.html, 使得页面标题为：HelloElectron！；页面内容为：Hello Electron！ 新建一个main.js, 内容如下：（main.js的文件名对应package.json中main的值），同时关闭调试工具。 运行应用在Electron目录下执行npm start 或electron .即可运行 如果你是局部安装，则运行： ./node_modules/.bin/electron . npm start 应用打包electron-packager打包安装electron-packager它也是一个npm模块，是一个用于打包electron应用的工具 npm install -g electron-packager electron-packager --version 开始打包打包格式如下： electron-packager &lt;sourcedir&gt; &lt;appname&gt; --platform=&lt;platform&gt; --arch=&lt;arch&gt; [optional flags...] 但是这样并不够，会提示： Unable to determine Electron version. Please specify an Electron version需要指明Electron version，改进为: electron-packager &lt;sourcedir&gt; &lt;appname&gt; --platform=&lt;platform&gt; --arch=&lt;arch&gt; [optional flags...] --electron-version=&lt;electron version&gt; eg: electron-packager . HelloElectron win32 x64 --electron-version=2.0.6 或 electron-packager . HelloElectron --platform=win32 --arch=x64 --electron-version=2.0.6 打包结束即在当前目录下生成了一个116M的HelloElectron文件夹，该文件夹内有一个65M大小的HelloElectron.exe通过图形界面进入该文件夹，双击即可运行。 通过查看resources\\app目录，可以查看到项目的源代码。 补充 最简单一键打包命令会打包生成所有你需要的各种platform各种arch的包 electron-packager ./ –all 即： electron-packager ./ –all –electron-version=2.0.6 分平台分arch打包 platform 取值有：darwin, linux, mas, win32 。命令： electron-packager ./ --platform=darwin electron-packager ./ --platform=linux electron-packager ./ --platform=mas electron-packager ./ --platform=win32 不写arch的情况下，arch的取值就是打包的电脑的arch值。一般可以取值有： ia32,x64,armv7l,arm64 electron-packager ./ --arch=ia32 electron-packager ./ --arch=x64 electron-packager ./ --arch=armv7l electron-packager ./ --arch=arm64 新生成的包，如果你想继续实验其他选项的话，可能是难以删除的。可以增加个--overwrite参数，会覆盖原有的build。有关其他可选标志的概述，请运行electron-packager --help或查看 usage.txt。有关详细说明，请参阅API文档。 如果我们想要更改窗口左上角的图标和任务栏的图标，只需要在打包的命令上加个icon参数 --icon= &lt;ico_address&gt;eg: --icon=./app/img/icon.ico electron-builder打包安装electron-builder npm install electron-builder -g electron-builder --version 开始打包 实际上打包过程会各种超时,建议挂代理 打包结束打开应用 安装应用 运行应用 补充 一键构建所有安装包electron-builder -mwlelectron-builder –platform=allelectron-builder –win –x64 分平台构建安装包 mac： electron-builder -m electron-builder -o electron-builder --mac electron-builder --macos electron-builder --platform=mac electron-builder --platform=darwin win: electron-builder -w electron-builder --win electron-builder --windows electron-builder --platform=win electron-builder --platform=win32 linux: electron-builder -l electron-builder --linux electron-builder --platform=linux 参数说明 –platform 这个参数是过期废弃的参数，不建议使用。同样，还有 –arch （取值是ia32/x64/all）也是一个过期参数。替代参数是 –x64 或者 –ia32 或者 –armv7l 。 当 –platform 或者 –arch 没有指定的时候，就会build当前系统的platform，当前系统的arch。也就是说，下面的命令在不同的系统下，命令是不一样的。（没有指定platform和arch）。 electron-builder –help 可查看相关用法 latest.yml为与更新相关文件，了打包时生成latest.yml文件，需要在 build 参数中添加 publish 配置，即： “publish”: [ { “provider”: “generic”, “url”: “http://localhost:4000/version&quot;//更新服务器地址 } ]则： 注意 devDependencies与dependencies的区别dependencies 表示我们要在生产环境下使用该依赖，devDependencies 则表示我们仅在开发环境使用该依赖。在打包时，一定要分清哪些包属于生产依赖，哪些属于开发依赖，尤其是在项目较大，依赖包较多的情况下。若在生产环境下错应或者少引依赖包，即便是成功打包，但在使用应用程序期间也会报错，导致打包好的程序无法正常运行。 npm与cnpm的区别说到npm与cnpm的区别，可能大家都知道，但大家容易忽视的一点，是cnpm装的各种node_module，这种方式下所有的包都是扁平化的安装。一下子node_modules展开后有非常多的文件。导致了在打包的过程中非常慢。但是如果改用npm来安装node_modules的话，所有的包都是树状结构的，层级变深。由于这个不同，对一些项目比较大的应用，很容易出现打包过程慢且node内存溢出的问题（这也是在解决electron打包过程中困扰我比较久的问题，最后想到了npm与cnpm的这点不同，解决了node打包内存溢出的问题，从打包一次一小时优化到打包一次一分钟，极大的提高了效率）。所以建议在打包前，将使用cnpm安装的依赖包删除，替换成npm安装的依赖包。 0x05-总结分析文章结论electron-packager打包 支持平台有：Windows (32/64 bit)、OS X (also known as macOS)、Linux (x86/x86_64); 进行应用更新时，使用electron内置的autoUpdate进行更新 支持CLI和JS API两种使用方式； electron-builder打包 electron-builder 可以打包成msi、exe、dmg文件，macOS系统，只能打包dmg文件，window系统才能打包exe，msi文件； 几乎支持了所有平台的所有格式； 支持Auto Update； 支持CLI和JS API两种使用方式； electron应用整合成一个安装包另外可以使用下面两种方法： NSIS打包Electron grunt打包Electron 文章分析本文使用Electron创建一个简单页面，实现了打开、打包、更改图标、整合成安装包等功能，展示了Electron应用开发的简单流程，使得开发逻辑更加清晰，开发过程更加具体，开发目的更加明确。 使用electron-packager打包生成文件较大，且是以文件夹形式生成，较为臃肿；源码暴露，不安全 使用electron-builder打包应用是安装包方式，而不像electron-packager打包之后直接是一个文件夹，里面所有的文件暴露出来。 其中关于应用打包工具，推荐使用electron-builder打包，相比electron-packager有以下优点： 支持更多的平台 支持了自动更新 打出的包更为轻量 打出的包不暴露源码 可以打包出setup安装程序 0x06-程序源码package.json{ &quot;name&quot;: &quot;HelloElectron&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;a simple application&quot;, &quot;main&quot;: &quot;main.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot;, &quot;start&quot;: &quot;electron .&quot; }, &quot;author&quot;: &quot;xiafei_xupt&quot;, &quot;license&quot;: &quot;ISC&quot; } index.html&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;HelloElectron！&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Hello Electron!&lt;/h1&gt; &lt;/body&gt; &lt;/html&gt; main.jsconst {app, BrowserWindow} = require(&apos;electron&apos;); let win; let windowConfig = { width:800, height:600 }; function createWindow(){ win = new BrowserWindow(windowConfig); win.loadURL(`file://${__dirname}/index.html`);//接口 //开启调试工具 //win.webContents.openDevTools(); win.on(&apos;close&apos;,() =&gt; { //回收BrowserWindow对象 win = null; }); win.on(&apos;resize&apos;,() =&gt; { win.reload(); }) } app.on(&apos;ready&apos;,createWindow); app.on(&apos;window-all-closed&apos;,() =&gt; { app.quit(); }); app.on(&apos;activate&apos;,() =&gt; { if(win == null){ createWindow(); } }) Electron Demo打包为避免命名冲突，重命名为electron-v1.0.0（密码：dkes） 0x07-参考资料 electron-packager文档 Electron官网 Electron 文档 打造你第一个 Electron 应用 electron-packager打包工具的最简化使用 electron打包：electron-packager及electron-builder两种方式实现","categories":[],"tags":[{"name":"Electron","slug":"Electron","permalink":"http://yoursite.com/tags/Electron/"}]},{"title":"PostgreSQL语法学习","slug":"PostgreSQL语法学习","date":"2018-07-15T16:00:00.000Z","updated":"2018-08-11T05:43:28.000Z","comments":true,"path":"PostgreSQL语法学习/","link":"","permalink":"http://yoursite.com/PostgreSQL语法学习/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践验证 0x05-总结分析 0x06-参考资料 0x00-文章前言文章目的 熟悉数据库操作基本流程、数据操作命令、编程接口 建立一个简单表格，可以通过SELECT语句查询出来 了解PostgreSQL的相关语法，为后期项目开发做准备 文章前景 有益于对数据库基本操作的掌握 有助于对PostgreSQL语法的学习 有利于对后期相关项目的顺利进展 0x01-知识储备Debian 9上pgadmin3和Windows 10上pgAdmin 4类似，SQL命令完全一样，故此处仅在Windows 10上进行相关学习即可，以下内容为PostgreSQL语法学习所需基础知识。 PostgreSQL命令大全可以使用help语句来获取帮助信息。 按照以下步骤查看PostgreSQL中相关命令的使用。 安装postgreSQL后，打开psql为：程序文件 -&gt; PostgreSQL 10 -&gt; SQL Shell(psql)，输入相关信息即可启动数据库。 获取帮助信息 postgres=＃help 显示发行条款 postgres=＃\\copyright 显示 SQL 命令的说明 postgres=＃\\h 显示 pgsql 命令的说明 postgres=＃\\? …… PostgreSQL语法大全数据库操作 创建数据库: create database database_name; 查看数据库: \\l 删除数据库: drop database database_name; 表格操作 创建表格 CREATE TABLE table_name( column1 datatype, column2 datatype, column3 datatype, ….. columnN datatype, PRIMARY KEY( one or more columns ) ); 删除表格 DROP TABLE table_name; 插入数据 INSERT INTO TABLE_NAME (column1, column2, column3,…columnN) VALUES (value1, value2, value3,…valueN); 查询数据 SELECT “column1”, “column2”..”column” FROM “table_name”; 更新数据 UPDATE table_name SET column1 = value1, column2 = value2…., columnN = valueN WHERE [condition]; 删除数据 DELETE FROM table_name WHERE [condition]; 0x02-测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G 软件 Windows 10系统 Debian 9系统 PostgreSQL 0x03-方案设计UI操作操作起来较为简单，适合于小量数据，用户体验度高 命令操作使用SQL语句操作，由于使用命令，可复用操作大量数据，效率高 0x04-实践验证创建数据库在PostgreSQL中，可以使用CREATE DATABASE命令创建数据库。 语法： CREATE DATABASE database_name; 这里，database_name是指定要创建的数据库的名称。 打开开始菜单，然后单击pgAdmin,第一次打开可能需要你输入密码，结果如下右键单击PostgreSQL 10并将PostgreSQL连接到本地主机服务器。右键单击数据库(Databases)，转到新数据库，将出现一个弹出框，如下图所示 - 然后键入您要的数据库名称，这里创建的数据库名称是：test_db，如下图所示点击保存(Save)就可以了。创建新的数据库(test_db)如下图所示 PostgreSQL使用查询工具创建数据库打开SQL Shell(psql)，执行以下创建语句 create database testdb; 执行结果如下 查看数据库或者在 pgAdmin 的左侧中查看，结果如下 删除数据库使用pgAdmin删除数据库 test_db右键单击数据库：test_db，左键单击delete/drop选项。将收到以下弹出框。点击“是(Yes)”完全删除数据库“test_db” 看到结果： 在PostgreSQL中，可以使用DROP DATABASE命令删除数据库。语法： DROP DATABASE database_name; 这里，database_name是指定要创建的数据库的名称。 PostgreSQL使用查询工具删除数据库打开SQL Shell(psql)，执行以下创建语句 drop database testdb; 查看数据库： 执行语句如下 看到结果： 创建表格在PostgreSQL中，CREATE TABLE语句用于在任何给定的数据库中创建一个新表。 语法： CREATE TABLE table_name( column1 datatype, column2 datatype, column3 datatype, ..... columnN datatype, PRIMARY KEY( one or more columns ) ); UI操作 首先选择要创建表的数据库。 左键单击与所选数据库关联的框类型结构,将看到目录和模式(架构)。 左键单击与模式(架构)关联的框类型结构。现在可以看到public。 左键单击与公共(public)关联的框类型结构，就可以看到有数据表。 选择数据表，右键单击数据表，会得到一个新的弹出表框，创建所需的表。参见示例：创建test_db2数据库，然后创建表:student添加数据 查看SQL脚本 命令操作PostgreSQL使用SQL命令创建表：student2查看所创表格： 删除表格UI操作右键单击所选表，这里选择表为：student2。找到表并选择点击完成。现在应该会看到这样的：点击确定(OK),则该表被删除。现在可以看到没有那个student2的表了。 命令操作 插入数据在PostgreSQL中，INSERT查询用于在表中插入新行。 您可以一次插入单行或多行到表中。 语法： INSERT INTO TABLE_NAME (column1, column2, column3,...columnN) VALUES (value1, value2, value3,...valueN); 注意：column1, column2, column3,…columnN是要插入数据的表中的列的名称。 UI操作 命令操作操作成功 查询数据在PostgreSQL中，SELECT语句用于从数据库表中检索数据。 数据以结果表格的形式返回。 这些结果表称为结果集。 语法： SELECT &quot;column1&quot;, &quot;column2&quot;..&quot;column&quot; FROM &quot;table_name&quot;; 这里，column1，column2，.. columnN指定检索哪些数据的列。 如果要从表中检索所有字段，则必须使用以下语法： SELECT * FROM &quot;table_name&quot;; 使用SQL语句操作：操作成功 更新数据在PostgreSQL中，UPDATE语句用于修改表中现有的记录。 要更新所选行，您必须使用WHERE子句，否则将更新所有行。 语法： 以下是update语句的基本语法： UPDATE table_name SET column1 = value1, column2 = value2...., columnN = valueN WHERE [condition]; 使用SQL语句操作：操作成功 删除数据DELETE语句用于从表中删除现有记录。 “WHERE”子句用于指定删除所选记录的条件，如是不指定条件则将删除所有记录。 语法： 以下是DELETE语句的基本语法： DELETE FROM table_name WHERE [condition]; 使用SQL语句操作：操作成功 0x05-总结分析 PostgreSQL的语法和其它数据库语法基本一样，可以说，几乎所有的数据库语法都是通用的 使用SQL脚本方便了数据表格的创建，可以跨平台使用，从而使得数据库迁移变得较为方便 0x06-参考资料 PostgreSQL文档 PostgreSQL教程","categories":[],"tags":[{"name":"实习","slug":"实习","permalink":"http://yoursite.com/tags/实习/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://yoursite.com/tags/PostgreSQL/"}]},{"title":"PostgreSQL环境搭建","slug":"PostgreSQL环境搭建","date":"2018-07-09T12:54:27.000Z","updated":"2018-08-11T05:11:58.000Z","comments":true,"path":"PostgreSQL环境搭建/","link":"","permalink":"http://yoursite.com/PostgreSQL环境搭建/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践验证 0x05-总结分析 0x06-参考资料 0x00-文章前言文章目的 熟悉数据库设计基本原理，安装数据库开发环境 了解PostgreSQL的特点及工具，为后期项目开发做准备 文章前景 对于规范开发具有参考意义 有利于对PostgreSQL的理解 0x01-知识储备数据库原理是数据的集合，具有统一的结构形式并存放于统一的存储介质内，是多种应用数据的集成，并可被各个应用程序共享。数据库存放数据是按数据所提供的数据模式存放的，具有集成与共享的特点。 PostgreSQL简介PostgreSQL是什么PostgreSQL是一个功能强大的开源对象关系数据库管理系统(ORDBMS)。 用于安全地存储数据; 支持最佳做法，并允许在处理请求时检索它们。 它是开源的，其源代码是免费提供的。PostgreSQL是跨平台的，可以在许多操作系统上运行，如Linux，FreeBSD，OS X，Solaris和Microsoft Windows等。自从MySQL被Oracle收购以后，PostgreSQL逐渐成为开源关系型数据库的首选。 PostgreSQL的历史PostgreSQL由计算机科学教授Michael Stonebraker在UCB创建。 它最初叫做Postgres。 1986年由Michael Stonebraker教授作为后续项目和Ingres项目启动，克服了当代数据库系统的问题。 PostgreSQL现在是任何地方都很先进的开源数据库。 PostgreSQL的特点PostgreSQL可在所有主要操作系统(即Linux，UNIX(AIX，BSD，HP-UX，SGI IRIX，Mac OS X，Solaris，Tru64)和Windows等)上运行。 PostgreSQL支持文本，图像，声音和视频，并包括用于C/C++，Java，Perl，Python，Ruby，Tcl和开放数据库连接(ODBC)的编程接口。 PostgreSQL支持SQL的许多功能，例如复杂SQL查询，SQL子选择，外键，触发器，视图，事务，多进程并发控制(MVCC)，流式复制(9.0)，热备(9.0))。 在PostgreSQL中，表可以设置为从“父”表继承其特征。 可以安装多个扩展以向PostgreSQL添加附加功能。 PostgreSQL的工具有一些开放源码以及付费工具可用作PostgreSQL的前端工具。 这里列出几个被广泛使用的工具： psql：它是一个命令行工具，也是管理PostgreSQL的主要工具。 pgAdmin是PostgreSQL的免费开源图形用户界面管理工具。 phpPgAdmin:它是用PHP编写的PostgreSQL的基于Web的管理工具。 它基于phpMyAdmin工具管理MySQL功能来开发。它可以用作PostgreSQL的前端工具。 pgFouine：它是一个日志分析器，可以从PostgreSQL日志文件创建报告。 0x02-测试环境硬件 处理器：i7 内存：8G 显示器：VGA 或更高 硬盘空间：128G软件 Windows 10系统 Debian 9系统 0x03-方案设计图形安装使用鼠标操作完成安装（适用于Windows 10系统） 命令安装使用shell命令完成安装（适用于Debian 9系统） 0x04-实践验证实践操作Windows 10下图形安装 选择合适的PostgreSQL的版本号以及对应系统，并从这里下载并下载：http://www.enterprisedb.com/products-services-training/pgdownload#windows由于我的系统是 Windows 10 64位，所以选择以下对应的版本 - PostgreSQL 10.4 Windows x86-64 以管理员身份运行下载的postgresql-10.4-1-windows-x64来安装PostgreSQL。 与安装其它软件一样，没有什么特别之处，选择下一步就好。 选择要安装的位置。 默认情况下，它安装在程序文件夹(C:\\Program File)中。 设置将要求您输入密码，因此请您输入密码，这里我输入的密码是：password。 设置PostgreSQL服务器的端口，保持默认，点击下一步。 安装过程就绪。完成安装过程需要一些时间。 完成安装过程后，您将看到以下屏幕取消选中复选框按钮，然后单击完成按钮完成安装。Debian 9下命令安装以root用户进行安装： root@bogon:/home/debian/Downloads# apt-get install postgres root@bogon:/home/debian/Downloads# apt-get install pgadmin3安装pgadmin（以pgAdmin3为例）实践结果Windows 10下图形安装在开始菜单点击SQL Shell (psql)，输入相关信息即可启动数据库。安装成功！Debian 9下命令安装安装成功！0x05-总结分析 PostgreSQL兼容性强，可以跨平台使用 PostgreSQL安装过程较为简单，环境搭建较为方便 0x06-参考资料 PostgreSQL文档 PostgreSQL教程 PostgreSQL在debian下安装、使用","categories":[],"tags":[{"name":"实习","slug":"实习","permalink":"http://yoursite.com/tags/实习/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"http://yoursite.com/tags/PostgreSQL/"}]},{"title":"Linux /proc目录下信息提取","slug":"proc目录下信息提取","date":"2018-06-24T16:00:00.000Z","updated":"2018-08-11T05:50:32.000Z","comments":true,"path":"proc目录下信息提取/","link":"","permalink":"http://yoursite.com/proc目录下信息提取/","excerpt":"","text":"0x00-文章前言 0x01-知识储备 0x02-测试环境 0x03-方案设计 0x04-实践验证 0x05-总结分析 0x06-程序源码 0x07-参考资料 0x00-文章前言文章目的了解proc文件系统即/proc目录，获取该目录下内核运行状态的一系列系统状态信息，并将其以文档形式导出。 文章前景可以更加及时、准确地获得系统状态信息，以便后续对其进行分析、评估、预测、态势感知等。 0x01-知识储备proc文件系统简介proc的全称为process data system ，proc文件系统是一种无存储的文件系统，当读其中的文件时，其内容动态生成，当写文件时，文件所关联的写函数被调用。每个proc文件都关联的字节特定的读写函数，因而它提供了另外的一种和内核通信的机制：内核部件可以通过该文件系统向用户空间提供接口来提供查询信息、修改软件行为，因而它是一种比较重要的特殊文件系统。 Linux系统上的/proc目录是一种文件系统，即proc文件系统。与其它常见的文件系统不同的是，/proc是一种伪文件系统（也即虚拟文件系统），存储的是当前内核运行状态的一系列特殊文件，用户可以通过这些文件查看有关系统硬件及当前正在运行进程的信息，甚至可以通过更改其中某些文件来改变内核的运行状态。proc文件系统属于虚拟文件系统，即该文件系统的数据，由内核动态生成，并不会存放在持久存储数据中。“即时”产生文件信息，换句话说，只有发出读操作请求时，才会产生信息。它以文件系统的方式为访问系统内核数据的操作提供接口。 proc文件系统，使得内核可以生成与系统状态和配置有关的信息。该信息可以由用户和系统程序从普通文件读取，而无需专门的工具与内核通信。从内核开发趋势来看，正在远离用proc文件系统提供的信息，而倾向于采用特定与问题的虚拟文件系统来导出数据。一个很好的例子就是USB文件系统，将与USB子系统有关的许多状态信息导出到用户空间，而没有给proc增加新的负担。但这并不意味这，proc文件系统变的多余，当今，/proc依旧重要，不仅在安装新的发布版时，而且也用于支持（自动化的）系统管理。 procfs 是进程文件系统(file system) 的缩写，包含一个伪文件系统（启动时动态生成的文件系统），用于通过内核访问进程信息。这个文件系统通常被挂载到 /proc 目录。由于 /proc 不是一个真正的文件系统，它也就不占用存储空间，只是占用有限的内存。 proc目录中的常见文件介绍静态生成：静态生成、动态变化动态生成：动态变化 /proc目录中包含许多以数字命名的子目录，这些数字表示系统当前正在运行进程的进程号，里面包含对应进程相关的多个信息文件。/proc/[pid] /proc/[pid]/attr / proc / [pid] / attr / current 该文件的内容代表当前的安全性过程的属性。 / proc / [pid] / attr / exec（自Linux 2.6.0开始该文件表示要分配给进程的属性 / proc / [pid] / attr / fscreate（自Linux 2.6.0开始）该文件表示要分配给创建的文件的属性 / proc / [pid] / attr / keycreate（自Linux 2.6.18开始） 如果一个进程将安全上下文写入这个文件，全部随后创建的键（add_key（2））将被标记这个背景。 /proc/cpu/infocat /proc/cpuinfo / proc / [pid] / stat 有关进程的状态信息。这由ps（1）使用。 它在内核源文件fs / proc / array.c中定义。 这些字段按顺序带有适当的scanf（3）格式speci- 以下列出。是否某些这些 字段显示有效信息由ptrace管理 访问模式PTRACE_MODE_READ_FSCREDS | PTRACE_MODE_NOAUDIT 检查（参考ptrace（2））。如果支票拒绝访问，那么 字段值显示为0.受影响的字段为 用标记[PT]表示。 （1）pid ％d 进程ID。 （2）通讯 ％s 可执行文件的文件名，括号中。 无论可执行文件是否可见，这都是可见的 换出。 （3）状态 ％c 指示过程的以下字符之一 州： R运行 S睡在可中断的等待中 D正在等待不间断磁盘睡眠 Z Zombie T停止（在信号上）或（在Linux 2.6.33之前） 追踪停止 t跟踪停止（Linux 2.6.33以上） W Paging（仅在Linux 2.6.0之前） X Dead（从Linux 2.6.0开始） x Dead（仅Linux 2.6.33至3.13） K Wakekill（仅适用于Linux 2.6.33至3.13） W醒来（仅适用于Linux 2.6.33至3.13） P停放（仅适用于Linux 3.9至3.13） （4）ppid ％d 此进程的父进程的PID。 （5）pgrp ％d 进程的进程组ID。 （6）会话 ％d 进程的会话ID。 （7）tty_nr ％d 过程的控制终端。（未成年人 设备编号包含在组合中 位31至20和7至0; 主要的设备编号是 在位15至8中） （8）tpgid ％d con的前台进程组的ID 流程的终端。 （9）标志 ％u 内核标记进程的单词。对于位平均 - 请参阅Linux内核中的PF_ *定义 源文件include / linux / sched.h。细节取决于 在内核版本上。 此字段的格式为Linux 2.6之前的％lu。 （10）minflt ％lu 过程所做的轻微故障的数量 不需要从中加载内存页面 磁盘。 （11）cminflt ％lu 该进程的小错误数量 等待的孩子们已经做出了决定。 （12）majflt ％lu 过程所造成的重大故障的数量 这需要从磁盘加载一个内存页面。 （13）cmajflt ％lu 该进程的主要故障数量 等待的孩子们已经做出了决定。 （14）utime ％lu 此进程已计划的时间量 在用户模式下，以时钟滴答度量（除以 sysconf（_SC_CLK_TCK））。这包括访客时间， guest_time（运行虚拟CPU所花费的时间，请参阅 下面），以便不知道的应用程序 来宾时间字段不会从那时失去 他们的计算。 （15）stime ％lu 此进程已计划的时间量 在内核模式下，以时钟滴答度量（除以 sysconf（_SC_CLK_TCK））。 （16）cutime ％ld 这个进程等待的时间量， dren已经安排在用户模式下，以英寸计量 时钟滴答（除以sysconf（_SC_CLK_TCK））。（看到 也包括时间（2））。这包括访客时间， cguest_time（运行虚拟CPU所用的时间，请参阅 下面）。 （17）cstime ％ld 这个进程等待的时间量， dren已经在内核模式下进行了安排， 时钟滴答（除以sysconf（_SC_CLK_TCK））。 （18）优先级 ％ld （针对Linux 2.6的解释）对于正在运行的进程 实时调度策略（以下策略 ;请参见 sched_setscheduler（2）），这是否定的schedul- 优先级，减1; 那就是一个数字 范围-2到-100，对应于实时优先级 - 关系1到99.对于在non- 实时调度策略，这是非常好的 值（setpriority（2）），如内核中所示。 内核在数据中存储很好的值 范围0（高）到39（低），对应于 用户可见的-20至19的好范围。 在Linux 2.6之前，这是基于的一个缩放值 调度程序给予这个过程的权重。 （19）nice ％ld 好的值（请参阅setpriority（2）），这是一个值 范围19（低优先级）至-20（高优先级）。 （20）num_threads ％ld 此过程中的线程数（自Linux 2.6开始）。 在内核2.6之前，这个字段被硬编码为0 先前移除的字段的占位符。 （21）itrealvalue ％ld 在下一个SIGALRM之前jiffies的时间发送 归因于间隔计时器的过程。由于ker- nel 2.6.17，这个字段不再维护，并且 被硬编码为0。 （22）starttime ％llu 系统启动后进程启动的时间。在 Linux 2.6之前的内核，表达了这个值 在jiffies。从Linux 2.6开始，数值被表达出来 在时钟周期中（除以sysconf（_SC_CLK_TCK））。 此字段的格式为Linux 2.6之前的％lu。 （23）vs ％lu 虚拟内存大小（字节）。 （24）rss ％ld 驻留集大小：进程拥有的页数 在真实的记忆中。这只是计数的页面 朝向文本，数据或堆栈空间。这不是 包括未被请求加载的页面， 或哪些被换出。 （25）rsslim ％lu 当前在软件rss上的软限制 处理; 看到的描述RLIMIT_RSS在 getrlimit（2） 。 （26）startcode ％lu [PT] 程序文本可以运行的地址。 （27）endcode ％lu [PT] 程序文本可以运行的地址。 （28）startstack ％lu [PT] 开始的地址（即底部） 叠加。 （29）kstkesp ％lu [PT] 发现ESP（堆栈指针）的当前值 在进程的内核堆栈页面中。 （30）kstkeip ％lu [PT] 当前的EIP（指令指针）。 （31）信号 ％lu 未决信号的位图显示为deci- mal号码。已过时，因为它不提供 有关实时信号的信息; 使用 / proc / [pid] / status。 （32）阻止 ％lu 被阻塞信号的位图显示为一个deci- mal号码。已过时，因为它不提供 有关实时信号的信息; 使用 / proc / [pid] / status。 （33）sigignore ％lu 忽略信号的位图，显示为一个deci- mal号码。已过时，因为它不提供 有关实时信号的信息; 使用 / proc / [pid] / status。 （34）sigcatch ％lu 捕获信号的位图，以小数形式显示 数。已过时，因为它不提供 有关实时信号的信息; 使用 / proc / [pid] / status。 （35）wchan ％lu [PT] 这是进程等待的“通道” ING。它是内核中某个位置的地址 进程在睡觉的地方。相应的 符号名称可以在/ proc / [pid] / wchan中找到。 （36）nswap ％lu 交换页数（不保留）。 （37）cnswap ％lu子进程的 累积nswap（不是main- tained）。 （38）exit_signal ％d（自Linux 2.1.22开始） 当我们死亡时，信号被发送给父母。 （39）处理器 ％d（自Linux 2.2.8开始） 上次执行的CPU号码。 （40）rt_priority ％U（因为Linux 2.5.19） 实时调度优先级，范围内的一个数字 1到99用于实时调度的进程 策略或0，用于非实时进程（请参阅 sched_setscheduler（2））。 （41）策略 ％u（自Linux 2.5.19开始） 调度策略（请参阅sched_setscheduler（2））。 使用linux / sched.h中的SCHED_ *常量进行解码。 这个字段的格式是Linux之前的％lu 2.6.22。 （42）delayacct_blkio_ticks ％llu（自Linux 2.6.18开始） 累计块I / O延迟，以时钟滴答度量 （厘秒）。 （43）guest_time ％lu（自Linux 2.6.24起） 过程的访客时间（运行vir- 用于客户操作系统的双CPU），以英寸计算 时钟滴答（除以sysconf（_SC_CLK_TCK））。 （44）cguest_time ％ld（自Linux 2.6.24起） 该过程的孩子的访客时间，以英寸计 时钟滴答（除以sysconf（_SC_CLK_TCK））。 （45）start_data ％lu（自Linux 3.3起）[PT] 程序初始化和unini- tialized（BSS）数据被放置。 （46）end_data ％lu（自Linux 3.3起）[PT] 地址在哪个程序初始化和unini- tialized（BSS）数据被放置。 （47）start_brk ％lu（自Linux 3.3起）[PT] 程序堆的地址可以扩展 与brk（2）。 （48）arg_start ％lu（自Linux 3.5起）[PT] 程序命令行参数上面的地址 （argv）被放置。 （49）arg_end ％lu（自Linux 3.5起）[PT] 程序命令行参数（argv）下的地址 摆放在。 （50）env_start ％lu（自Linux 3.5起）[PT] 在上面放置程序环境的地址。 （51）env_end ％lu（自Linux 3.5起）[PT] 地址在哪个程序环境下放置。 （52）exit_code ％d（自Linux 3.5起）[PT] 线程的退出状态以表格形式报告 waitpid（2）。 / proc / [pid] / status 提供/ proc / [pid] / stat和 / proc / [pid] / statm中的大部分信息， 解析。这是一个例子： $ cat / proc / $$ / status Name: bash Umask: 0022 State: S (sleeping Tgid：17248 Ngid：0 Pid：17248 PPid：17200 TracerPid：0 Uid：1000 1000 1000 1000 Gid：100 100 100 100 FDSize：256 Groups：16 33 100 NStgid：17248 NSpid：17248 NSpgid：17248 NSsid：17200 VmPeak：131168 kB VmSize：131168 kB VmLck：0 kB VmPin：0 kB VmHWM：13484 kB VmRSS：13484 kB RssAnon：10264 kB RssFile：3220 kB RssShmem：0 kB VmData：10332 kB VmStk：136 kB VmExe：992 kB VmLib：2104 kB VmPTE：76 kB VmPMD：12 kB VmSwap：0 kB HugetlbPages：0 kB＃4.4 Threads：1 SigQ: 0/3067 SigPnd: 0000000000000000 ShdPnd: 0000000000000000 SigBlk: 0000000000010000 SigIgn: 0000000000384004 SigCgt: 000000004b813efb CapInh: 0000000000000000 CapPrm: 0000000000000000 CapEff: 0000000000000000 CapBnd: ffffffffffffffff CapAmb: 0000000000000000 NoNewPrivs：0 Seccomp：0 Cpus_allowed：00000001 Cpus_allowed_list：0 Mems_allowed：1 Mems_allowed_list：0 volunte_ctxt_switches：150 nonvoluntary_ctxt_switches：545 这些字段如下所示： * 名称：由此进程运行的命令。 * Umask：处理umask，用八进制表示一个领先的 零; 见umask（2）。（从Linux 4.7开始）。 * 状态：进程的当前状态。其中一个“R（跑步）”， “S（睡眠）”，“D（磁盘睡眠）”，“T（停止）”，“T（追踪 停止）“，”Z（僵尸）“或”X（死亡）“。 * Tgid：线程组ID（即进程ID）。 * Ngid：NUMA组ID（如果没有，则为0;自Linux 3.13以来）。 * Pid：线程ID（请参阅gettid（2））。 * PPid：父进程的PID。 * TracerPid：进程跟踪此进程的PID（如果不是，则为0） 被追踪）。 * Uid，Gid：真实，有效，保存的设置和文件系统UID （GID的）。 * FDSize：当前分配的文件描述符插槽的数量。 * 团体：补充小组名单。 * NStgid：每个PID中的线程组ID（即PID） 其中[pid]是其成员的名称空间。最左边的条目 显示相对于PID命名空间的值 读取过程，接着是值 嵌套的内部命名空间。（从Linux 4.1开始） * NSpid：每个PID名称空间中的线程ID，其中 [pid]是其成员。这些字段按照NStgid排序。 （从Linux 4.1开始） * NSpgid：在每个PID名称空间中处理组ID 哪个[pid]是成员。这些字段按照Nst- gid排序。（从Linux 4.1开始） * NSsid：后代命名空间会话ID层次结构会话ID 在其中[pid]是其成员的每个PID名称空间中。 这些字段按照NStgid排序。（从Linux 4.1开始） * VmPeak：峰值虚拟内存大小。 * VmSize：虚拟内存大小。 * VmLck：锁定内存大小（请参阅mlock（3））。 * VmPin：固定的内存大小（自Linux 3.2以来）。这些是 因某些需要而无法移动的页面 直接访问物理内存。 * VmHWM：高峰居民组大小（“高水位”）。 * VmRSS：居民组大小。请注意，这里的值是 总和RssAnon，RssFile和RssShmem。 * RssAnon：驻留匿名内存的大小。（自Linux以来 4.5）。 * RssFile：常驻文件映射的大小。（自Linux 4.5以来）。 * RssShmem：驻留共享内存的大小（包括System V 共享内存，来自tmpfs（5）的映射和共享匿名 映射）。（自Linux 4.5以来）。 * VmData，VmStk，VmExe：数据，堆栈和文本的大小seg- 发言：。 * VmLib：共享库代码大小。 * VmPTE：页表条目大小（自Linux 2.6.10起）。 * VmPMD：第二级页面表的大小（自Linux 4.0开始）。 * VmSwap：由匿名私人交换虚拟内存大小 页; 不包括shmem交换使用（因为Linux 2.6.34）。 * HugetlbPages：hugetlb内存部分的大小。（自Linux以来 4.4）。 * 线程数：包含这个的进程中的线程数 线。 * SigQ：该字段包含两个以斜线分隔的数字 与排队信号有关的真实用户ID 处理。其中第一个是当前的数量 排队的信号为这个真实的用户ID，第二个是 对此的排队信号数量的资源限制 处理（参照的描述RLIMIT_SIGPENDING在 getrlimit（2） ）。 * SigPnd，ShdPnd：线程和for的待处理信号的数量 作为一个整体（见pthreads（7）和signal（7））。 * SigBlk，SigIgn，SigCgt：指示信号的掩码 被阻止，被忽略并被捕获（见信号（7））。 * CapInh，CapPrm，CapEff：启用的功能掩码 可继承的，允许的和有效的集合（参见 能力（7））。 * CapBnd：Capability Bounding集合（自Linux 2.6.26起，参见 能力（7））。 * CapAmb：环境能力集（自Linux 4.3起，参见 能力（7））。 * NoNewPrivs：no_new_privs位的值（自Linux 4.10开始， 参见prctl（2））。 * Seccomp：进程的Seccomp模式（自Linux 3.8起，请参阅 seccomp（2））。0表示SECCOMP_MODE_DISABLED ; 1表示SEC- COMP_MODE_STRICT ; 2表示SECCOMP_MODE_FILTER。这个领域 仅当内核是在启用CON- FIG_SECCOMP内核配置选项的情况下生成的。 * Cpus_allowed：可以运行此进程的CPU的掩码 （从Linux 2.6.24开始，请参阅cpuset（7））。 * Cpus_allowed_list：与之前相同，但是以“列表格式” （从Linux 2.6.26开始，请参阅cpuset（7））。 * Mems_allowed：此进程允许的内存节点掩码 （从Linux 2.6.24开始，请参阅cpuset（7））。 * Mems_allowed_list：与之前相同，但是以“列表格式” （从Linux 2.6.26开始，请参阅cpuset（7））。 * voluntary_ctxt_switches，nonvoluntary_ctxt_switches：号码 自愿和非自愿的上下文切换（自Linux以来 2.6.23）。 11010091031041061071081111111311341212913131513231328133313541359136413661371393141401140314071414143614511455145914631476148514891494149915152115611572158415881590161602160316051611162216231626163516501664171725181851861922079208209021218222234232367237242526272829833535387338844041410424426427433447550050150250450550995100510251585160548550855095510551255625645705570857145905601860416050611617628635693695772373173574757689915936968980997 /proc/acpi； /proc/asound /proc/buddyinfo用于诊断内存碎片问题的相关信息文件； /proc/bus /cgroups /proc/cmdline在启动时传递至内核的相关参数信息，这些信息通常由lilo或grub等启动管理工具进行传递；/proc/consoles /proc/cpuinfo处理器的相关信息的文件； /proc/crypto /proc/devices /proc/diskstats /proc/dma /proc/driverdriverexecdomainsfbfilesystemsfsinterruptsiomemioportsirqkallsymskcorekeyskey-userskmsgkpagecgroupkpagecountkpageflagsloadavglocksmeminfomiscmodulesmountsmptmtrrnetpagetypeinfopartitionssched_debugschedstatselfslabinfosoftirqsstatswapssyssysrq-triggersysvipcthread-selftimer_listttyuptimeversionvmallocinfovmstatzoneinfo… proc的数据结构与Ext2一样，proc大量使用了VFS数据结构，因为作为一种文件系统，它必须集成到内核的VFS抽象层中。但，毕竟proc只是用于获取内核的数据为主要目的，所以在其设计的过程中，遵循简单实用的特性，较Ext2简单。 proc文件系统API内核为创建proc文件提供了一套API，相关API如下： struct proc_dir_entry proc_mkdir(const char name, struct proc_dir_entry *parent); 该函数用于在proc文件系统中创建一个目录项，大多数时候，当我们期望实现自己的proc文件时，都要先创建一个自己的目录，然后在该目录里创建自己的文件，当然我们也可以直接在已经存在的proc文件系统目录里创建自己的文件。该函数的各个参数含义如下：name：该目录的名字parent：该目录的父目录的名字void proc_remove(struct proc_dir_entry de);该函数用于删除一个目录。struct proc_dir_entry proc_create(const char name, umode_t mode, struct proc_dir_entry parent, const struct file_operations proc_fops);该函数用于在proc文件系统中创建一个proc文件，其参数含义如下：name：proc文件的名字，表现在proc文件系统中，就是文件的名字mode：proc文件的访问模式，表现在proc文件系统中，就是文件的访问模式parent：该proc文件所在的目录proc_fops：指向用于操作该文件的文件操作的指针这些参数提供了一个文件所需要的关键信息，包括文件名，访问模式，目录项（用于指定文件在文件系统中的位置），以及文件操作指针。当要删除一个文件时，需要使用API：void remove_proc_entry(const char name, struct proc_dir_entry *parent)；参数的含义是显然的，该函数用于从proc文件系统的指定目录删除指定的proc文件。还有一些其它的API，都定义在include/linux/prof_fs.h中。在proc文件系统中创建文件或者目录时，最终都会调到proc_register，该函数会为新创建的文件或目录指定正确的file_operations和inode_operations，它们将在访问文件时被使用。 深入理解计算机系统操作系统原理0x02-测试环境硬件环境软件环境0x03-方案设计方案A/proc目录下所有文件按目录形式复制出来，再进行选择性地提取有效信息。 方案B手动导出 方案C使用shell脚本直接提取目的信息，按合适格式导出到文档中。 方案D通过内核模块获取目的信息，按合适格式导出到文档中。 方案E代码直接调用mysql API, 方案FNode.js 直接调用系统API接口 0x04-实践验证实践操作实践结果方案Adf -a 显示为0ls -lh /proc/kcoredu -hs /proc/kcorels /proc/kcore -lhhexdump（或od）-r——– 1 root root 128T Jun 30 12:50 /proc/kcore /proc是伪文件系统，内核想报告多大就多大。又不用分配出来不可行。 方案B暂时先提取十条进程的信息/proc/17256/stat 1725 (gvfsd-metadata) S 693 1725 1725 0 -1 4194304 746 0 174 0 10 20 0 0 20 0 3 0 8235 198119424 479 18446744073709551615 94113580531712 94113580601292 140721845185440 0 0 0 0 4096 0 0 0 0 17 0 0 0 238 0 0 94113582698760 94113582702612 94113598459904 140721845193626 140721845193655 140721845193655 140721845194715 0即： 安装linux-header apt-get install -y linux-headers-$(uname -r) dmesg -C 0x05-总结分析文章结论文章分析0x06-程序源码代码A代码B0x07-参考资料 Linux Programmer’s Manual PROC(5) 百度一下 Markdown用法 除了您现在看到的这个 Cmd Markdown 在线版本，您还可以前往以下网址下载： Windows/Mac/Linux 全平台客户端 请保留此份 Cmd Markdown 的欢迎稿兼使用说明，如需撰写新稿件，点击顶部工具栏右侧的 新文稿 或者使用快捷键 Ctrl+Alt+N。 什么是 MarkdownMarkdown 是一种方便记忆、书写的纯文本标记语言，用户可以使用这些标记符号以最小的输入代价生成极富表现力的文档：譬如您正在阅读的这份文档。它使用简单的符号标记不同的标题，分割不同的段落，粗体 或者 斜体 某些文字，更棒的是，它还可以 1. 制作一份待办事宜 Todo 列表 支持以 PDF 格式导出文稿 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 新增 Todo 列表功能 修复 LaTex 公式渲染问题 新增 LaTex 公式编号功能 2. 书写一个质能守恒公式[^LaTeX]$$E=mc^2$$ 3. 高亮一段代码[^code]1234567@requires_authorizationclass SomeClass: passif __name__ == '__main__': # A comment print 'hello world' 4. 高效绘制 流程图12345678st=&gt;start: Startop=&gt;operation: Your Operationcond=&gt;condition: Yes or No?e=&gt;endst-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 5. 高效绘制 序列图123Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks! 6. 高效绘制 甘特图12345678910111213title 项目开发流程section 项目确定 需求分析 :a1, 2016-06-22, 3d 可行性报告 :after a1, 5d 概念验证 : 5dsection 项目实施 概要设计 :2016-07-05 , 5d 详细设计 :2016-07-08, 10d 编码 :2016-07-15, 10d 测试 :2016-07-22, 5dsection 发布验收 发布: 2d 验收: 3d 7. 绘制表格 项目 价格 数量 计算机 \\$1600 5 手机 \\$12 12 管线 \\$1 234 8. 更详细语法说明想要查看更详细的语法说明，可以参考我们准备的 Cmd Markdown 简明语法手册，进阶用户可以参考 Cmd Markdown 高阶语法手册 了解更多高级功能。 总而言之，不同于其它 所见即所得 的编辑器：你只需使用键盘专注于书写文本内容，就可以生成印刷级的排版格式，省却在键盘和工具栏之间来回切换，调整内容和格式的麻烦。Markdown 在流畅的书写和印刷级的阅读体验之间找到了平衡。 目前它已经成为世界上最大的技术分享网站 GitHub 和 技术问答网站 StackOverFlow 的御用书写格式。 什么是 Cmd Markdown您可以使用很多工具书写 Markdown，但是 Cmd Markdown 是这个星球上我们已知的、最好的 Markdown 工具——没有之一 ：）因为深信文字的力量，所以我们和你一样，对流畅书写，分享思想和知识，以及阅读体验有极致的追求，我们把对于这些诉求的回应整合在 Cmd Markdown，并且一次，两次，三次，乃至无数次地提升这个工具的体验，最终将它演化成一个 编辑/发布/阅读 Markdown 的在线平台——您可以在任何地方，任何系统/设备上管理这里的文字。 1. 实时同步预览我们将 Cmd Markdown 的主界面一分为二，左边为编辑区，右边为预览区，在编辑区的操作会实时地渲染到预览区方便查看最终的版面效果，并且如果你在其中一个区拖动滚动条，我们有一个巧妙的算法把另一个区的滚动条同步到等价的位置，超酷！ 2. 编辑工具栏也许您还是一个 Markdown 语法的新手，在您完全熟悉它之前，我们在 编辑区 的顶部放置了一个如下图所示的工具栏，您可以使用鼠标在工具栏上调整格式，不过我们仍旧鼓励你使用键盘标记格式，提高书写的流畅度。 3. 编辑模式完全心无旁骛的方式编辑文字：点击 编辑工具栏 最右侧的拉伸按钮或者按下 Ctrl + M，将 Cmd Markdown 切换到独立的编辑模式，这是一个极度简洁的写作环境，所有可能会引起分心的元素都已经被挪除，超清爽！ 4. 实时的云端文稿为了保障数据安全，Cmd Markdown 会将您每一次击键的内容保存至云端，同时在 编辑工具栏 的最右侧提示 已保存 的字样。无需担心浏览器崩溃，机器掉电或者地震，海啸——在编辑的过程中随时关闭浏览器或者机器，下一次回到 Cmd Markdown 的时候继续写作。 5. 离线模式在网络环境不稳定的情况下记录文字一样很安全！在您写作的时候，如果电脑突然失去网络连接，Cmd Markdown 会智能切换至离线模式，将您后续键入的文字保存在本地，直到网络恢复再将他们传送至云端，即使在网络恢复前关闭浏览器或者电脑，一样没有问题，等到下次开启 Cmd Markdown 的时候，她会提醒您将离线保存的文字传送至云端。简而言之，我们尽最大的努力保障您文字的安全。 6. 管理工具栏为了便于管理您的文稿，在 预览区 的顶部放置了如下所示的 管理工具栏： 通过管理工具栏可以： 发布：将当前的文稿生成固定链接，在网络上发布，分享 新建：开始撰写一篇新的文稿 删除：删除当前的文稿 导出：将当前的文稿转化为 Markdown 文本或者 Html 格式，并导出到本地 列表：所有新增和过往的文稿都可以在这里查看、操作 模式：切换 普通/Vim/Emacs 编辑模式 7. 阅读工具栏 通过 预览区 右上角的 阅读工具栏，可以查看当前文稿的目录并增强阅读体验。 工具栏上的五个图标依次为： 目录：快速导航当前文稿的目录结构以跳转到感兴趣的段落 视图：互换左边编辑区和右边预览区的位置 主题：内置了黑白两种模式的主题，试试 黑色主题，超炫！ 阅读：心无旁骛的阅读模式提供超一流的阅读体验 全屏：简洁，简洁，再简洁，一个完全沉浸式的写作和阅读环境 8. 阅读模式在 阅读工具栏 点击 或者按下 Ctrl+Alt+M 随即进入独立的阅读模式界面，我们在版面渲染上的每一个细节：字体，字号，行间距，前背景色都倾注了大量的时间，努力提升阅读的体验和品质。 9. 标签、分类和搜索在编辑区任意行首位置输入以下格式的文字可以标签当前文档： 标签： 未分类 标签以后的文稿在【文件列表】（Ctrl+Alt+F）里会按照标签分类，用户可以同时使用键盘或者鼠标浏览查看，或者在【文件列表】的搜索文本框内搜索标题关键字过滤文稿，如下图所示： 10. 文稿发布和分享在您使用 Cmd Markdown 记录，创作，整理，阅读文稿的同时，我们不仅希望它是一个有力的工具，更希望您的思想和知识通过这个平台，连同优质的阅读体验，将他们分享给有相同志趣的人，进而鼓励更多的人来到这里记录分享他们的思想和知识，尝试点击 (Ctrl+Alt+P) 发布这份文档给好友吧！ 再一次感谢您花费时间阅读这份欢迎稿，点击 (Ctrl+Alt+N) 开始撰写新的文稿吧！祝您在这里记录、阅读、分享愉快！ 作者 @ghosert2016 年 07月 07日 [^LaTeX]: 支持 LaTeX 编辑显示支持，例如：$\\sum_{i=1}^n a_i=0$， 访问 MathJax 参考更多使用方法。 [^code]: 代码高亮功能支持包括 Java, Python, JavaScript 在内的，四十一种主流编程语言。 0x05-参考资料Linux下Proc文件系统的编程剖析_郭松http://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFQ&amp;dbname=CJFD2010&amp;filename=HQDB201005010&amp;uid=WEEvREcwSlJHSldRa1FhcTdWajFtZk1DY3hvZmUvYk10TGtFRmcwaDkyTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4ggI8Fm4gTkoUKaID8j8gFw!!&amp;v=MjA1NzN5RGxVN3pJTFR6UGJMRzRIOUhNcW85RVpJUjhlWDFMdXhZUzdEaDFUM3FUcldNMUZyQ1VSTEtmWWVSb0Y=","categories":[],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"http://yoursite.com/tags/Kernel/"},{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"如何规范自己的技术博客？","slug":"如何规范自己的技术博客？","date":"2018-06-19T06:48:21.000Z","updated":"2019-02-22T09:08:03.970Z","comments":true,"path":"如何规范自己的技术博客？/","link":"","permalink":"http://yoursite.com/如何规范自己的技术博客？/","excerpt":"","text":"转自：http://blog.sina.cn/dpool/blog/s/blog_a1616bfb0102xebc.html 前言：一篇好的技术博客是表述自己的思想，传递自己总结的知识，与同行业分享成果，进行技术交流最佳的方式。不仅可以把以前使用过的内容从记忆的海洋中找寻出来，提高工作学习效率；而且是对零碎知识点的积累和深究，可以发现潜在的、遗留的或技术瓶颈的历史问题；再者IT技术日新月异，虚拟化、云计算、大数据时代已强势登陆，通过技术博客可以了解行业动态，提升技术方面眼界。 规范点：一、技术博客有自己的特色网上转载的技术博客对自已未必是最好的，并且转载后时间一长该话题就不再问津了。形成自己的风格是提高个人兴趣的手段，可以快速的从自己的思路中恢复过来。它也是自我学习和体会的最佳方式，一个技术问题转载只需手指一弹，写技术博客需数小时之久，其过程的细节、关键点只有亲手实践才更清晰明白。并且同样的知识点、同样的问题每个人见解、想法、思路都是各见千秋的。 二、技术博客图文并茂一幅图能很好的表达自己的思想，有时好图胜过偌大篇幅的晦涩代码。整体的架构图、部署图、继承关系图、流程图都是很好的方法，不仅让结构过程清晰而且更吸引读者。代码毕竟是实现过程，而不是原理。 三、有目标性和系统性要明确每篇博客的目标，不是简单的罗列大堆的文字代码，要明确目的，明确解决了哪些技术难题。要判断自己所写的东西是否有价值。对每个知识点尽量做到系统性和深入性，博客是花时间求知识，若只追求数量没有质量是得不偿失的，要做就做最好的。如果时间和兴趣都有的话，可以一个专题整体发布博客，当然是有些挑战和难度的。一篇博客讲述一个问题，要多联系实际，以主题为中心，构建清晰的脉络结构。 四、分享源码分享是一种美德，分享自己的成果是一种成就感，分享自己的过程是一种超越感。你分享的内容越多，自我所需要掌握提升的也会更多，自我提升的压力动力也就越多。源码是理解思想最佳的方式，是很重要的资源积累。 五、专业化博客是技术的总结和提高，不是解决问题的过程，不必要列出所有的测试、解决、实践方法，只需列出关键的节点。要想掌握一项技术、知识，需要一个过程：实践遇到问题—理论学习问题—实践解决问题—理论总结问题—问题提升，循环往复，不断上升。总结前人写博客步骤：（1）碰到有价值的问题（工作、书本、网上课题），记录作为博客的开篇。（2）分析解决问题，记录好问题解决的方案和可能的思路。（3）画出部分的流程图、结构图，其他的可以在完成代码后在设计。（4）落实到代码的实现，测试并发布完整的程序。（5）总结，写技术博客。找资料最好用google，百度只是大众化的不适合技术研究，下载源码、找问题根源最好从官方网站查询，别人的博客虽只是别人主观遇到的问题，有时会浪费大量的成品和时间。英文文章的水平整体高于中文文章水平，应该尽量强迫自己看英文文章。写一篇好的技术文档是一个专业软件工程师的必要素养，我们不仅要写出漂亮的代码而且要使写的技术文档越来越专业。 六、不断打补丁技术博客中肯定会遗留问题或与网友沟通后出现新的bug，也或技术的更新带来的不兼容，那我们要时时更新。最好不要修改原来写的技术博客，要以补丁patch的形式汇总，这样可以很清晰的查阅更新的内容、明白技术的变更。 总结：以上规范约束自己的博客质量，以求做的比较完善，以提升技术为主要出发点。","categories":[],"tags":[{"name":"教程","slug":"教程","permalink":"http://yoursite.com/tags/教程/"}]},{"title":"简单的linux设备驱动程序","slug":"简单的linux设备驱动程序","date":"2018-06-17T16:00:00.000Z","updated":"2018-08-11T05:52:40.000Z","comments":true,"path":"简单的linux设备驱动程序/","link":"","permalink":"http://yoursite.com/简单的linux设备驱动程序/","excerpt":"","text":"简单的linux设备驱动程序","categories":[],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"http://yoursite.com/tags/Kernel/"}]},{"title":"内存管理之伙伴算法","slug":"伙伴算法","date":"2018-05-29T11:48:21.000Z","updated":"2018-06-04T22:22:42.000Z","comments":true,"path":"伙伴算法/","link":"","permalink":"http://yoursite.com/伙伴算法/","excerpt":"","text":"Buddy算法的优缺点：1）尽管伙伴内存算法在内存碎片问题上已经做的相当出色，但是该算法中，一个很小的块往往会阻碍一个大块的合并，一个系统中，对内存块的分配，大小是随机的，一片内存中仅一个小的内存块没有释放，旁边两个大的就不能合并。 2）算法中有一定的浪费现象，伙伴算法是按2的幂次方大小进行分配内存块，当然这样做是有原因的，即为了避免把大的内存块拆的太碎，更重要的是使分配和释放过程迅速。但是他也带来了不利的一面，如果所需内存大小不是2的幂次方，就会有部分页面浪费。有时还很严重。比如原来是1024个块，申请了16个块，再申请600个块就申请不到了，因为已经被分割了。 3）另外拆分和合并涉及到 较多的链表和位图操作，开销还是比较大的。 Buddy（伙伴的定义）：这里给出伙伴的概念，满足以下三个条件的称为伙伴：1）两个块大小相同；2）两个块地址连续；3）两个块必须是同一个大块中分离出来的； Buddy算法的分配原理：假如系统需要4(22)个页面大小的内存块，该算法就到free_area[2]中查找，如果链表中有空闲块，就直接从中摘下并分配出去。如果没有，算法将顺着数组向上查找free_area[3],如果free_area[3]中有空闲块，则将其从链表中摘下，分成等大小的两部分，前四个页面作为一个块插入free_area[2]，后4个页面分配出去，free_area[3]中也没有，就再向上查找，如果free_area[4]中有，就将这16(2222)个页面等分成两份，前一半挂如free_area[3]的链表头部，后一半的8个页等分成两等分，前一半挂free_area[2]的链表中，后一半分配出去。假如free_area[4]也没有，则重复上面的过程，知道到达free_area数组的最后，如果还没有则放弃分配。 Buddy算法的释放原理：内存的释放是分配的逆过程，也可以看作是伙伴的合并过程。当释放一个块时，先在其对应的链表中考查是否有伙伴存在，如果没有伙伴块，就直接把要释放的块挂入链表头；如果有，则从链表中摘下伙伴，合并成一个大块，然后继续考察合并后的块在更大一级链表中是否有伙伴存在，直到不能合并或者已经合并到了最大的块(222222222个页面)。 整个过程中，位图扮演了重要的角色，如图2所示，位图的某一位对应两个互为伙伴的块，为1表示其中一块已经分配出去了，为0表示两块都空闲。伙伴中无论是分配还是释放都只是相对的位图进行异或操作。分配内存时对位图的是为释放过程服务，释放过程根据位图判断伙伴是否存在，如果对相应位的异或操作得1，则没有伙伴可以合并，如果异或操作得0，就进行合并，并且继续按这种方式合并伙伴，直到不能合并为止。 代码实现：心得体会 #：参考资料：Github：https://github.com/hurley25/hurlex-II/blob/master/mm/buddy_mm.c","categories":[],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"http://yoursite.com/tags/Kernel/"}]},{"title":"实验-内存管理(FF、BF、WF)","slug":"实验-内存管理","date":"2018-05-28T01:48:11.000Z","updated":"2018-06-04T22:11:46.000Z","comments":true,"path":"实验-内存管理/","link":"","permalink":"http://yoursite.com/实验-内存管理/","excerpt":"","text":"一. 实验目的及实验环境(一)、实验环境硬件处理器：i7；内存：8G；显示器：VGA 或更高；硬盘空间：128G。 软件Centos 7下gcc编译器、gdb调试工具。 (二)、实验目的 掌握内存分配FF，BF，WF策略及实现的思路； 掌握内存回收过程及实现思路； 参考本程序思路，实现内存的申请、释放的管理程序，调试运行，总结程序设计中出现的问题并找出原因。二、实验内容 补充完整FF，BF，WF等算法的代码； 掌握内存回收过程及实现思路； 实现内存的申请和释放。三．方案设计(一)、实现功能 Set memory size (default=1024) Select memory allocation algorithm New process Terminate a process Display memory usage Exit(二)、关键算法思想设计与分析首次适应算法（First Fit）从空闲分区表的第一个表目起查找该表，把最先能够满足要求的空闲区分配给作业，这种方法目的在于减少查找时间。为适应这种算法，空闲分区表（空闲区链）中的空闲分区要按地址由低到高进行排序。该算法优先使用低址部分空闲区，在低址空间造成许多小的空闲区，在高地址空间保留大的空闲区。 最佳适应算法（Best Fit）它从全部空闲区中找出能满足作业要求的、 且大小最小的空闲分区，这种方法能使碎片尽量小。为适应此算法，空闲分 区表（空闲区链）中的空闲分区要按从小到大进行排序，自表头开始查找到 第一个满足要求的自由分区分配。该算法保留大的空闲区，但造成许多小的 空闲区。 最差适应算法（Worst Fit）它从全部空闲区中找出能满足作业要求的、 且大小最大的空闲分区，从而使链表中的结点大小趋于均匀，适用于请求分 配的内存大小范围较窄的系统。为适应此算法，空闲分区表（空闲区链）中 的空闲分区要按大小从大到小进行排序，自表头开始查找到第一个满足要求的自由分区分配。该算法保留小的空闲区，尽量减少小的碎片产生。 四．测试数据及运行结果 设置内存大小 选择算法 创建进程 选择杀死进程 查看内存以及进程退出程序并释放内存空间五．总结这次实验刚开始的时候不知道整个实验的思路，还好老师在课堂上大概讲解了一下，并且给出了大部分代码，剩下的工作就是填写部分代码，这样实验就简单多了。通过本次的内存实验我了解到了内存的管理模型的知识，在内存紧缩合并回收部分还遇到了一些问题，最终通过查资料解决了问题，虽然对内存的管理掌握得不是很熟练，但这激励了我下来后看书，努力学习不懂的知识，通过让我对其有了更加深入的了解，让我认识到了，操作系统是一项真正实用，而且很有意义的学科，增加了我对操作系统的兴趣，也为以后的学习打下理论基础。 六. 源代码#include&lt;stdio.h&gt; #include&lt;malloc.h&gt; #include&lt;unistd.h&gt; #include&lt;stdlib.h&gt; #define PROCESS_NAME_LEN 32 //进程名长度 #define MIN_SLICE10 //最小碎片的大小 #define DEFAULT_MEM_SIZE 1024//内存大小 #define DEFAULT_MEM_START 0 //起始位置 /*内存分配算法*/ #define MA_FF 1 #define MA_BF 2 #define MA_WF 3 /*描述每一个空闲块的数据结构*/ struct free_block_type { int size;//空闲块大小 int start_addr;//空闲块起始地址 struct free_block_type *next;//指向下一个空闲块 }; /*指向内存中空闲块链表的首指针*/ struct free_block_type *free_block = NULL; /*每个进程分配到的内存块的描述*/ struct allocated_block { int pid;//进程标识符 int size;//进程大小 int start_addr;//进程分配到的内存块的起始地址 char process_name[PROCESS_NAME_LEN];//进程名 struct allocated_block *next;//指向下一个进程控制块 }; /*进程分配内存块链表的首指针*/ struct allocated_block *allocated_block_head = NULL; int free_block_count = 0;//空闲块个数 int mem_size = DEFAULT_MEM_SIZE; //内存大小 int current_free_mem_size = 0;//当前空闲内存大小 int ma_algorithm = MA_FF; //当前分配算法 static int pid = 0; //初始PID int flag = 0;//设置内存大小标志,表示内存大小是否设置 /*函数声明*/ struct free_block_type* init_free_block(int mem_size); void display_menu(); int set_mem_size(); void set_algorithm(); void rearrange(int algorithm); int rearrange_WF(); int rearrange_BF(); int rearrange_FF(); int new_process(); int allocate_mem(struct allocated_block *ab); void kill_process(); int free_mem(struct allocated_block *ab); int dispose(struct allocated_block *free_ab); int display_mem_usage(); struct allocated_block *find_process(int pid); int do_exit(); int allocate_FF(struct allocated_block *ab); int allocate_BF(struct allocated_block *ab); int allocate_WF(struct allocated_block *ab); int allocate(struct free_block_type *pre, struct free_block_type *allocate_free_nlock, struct allocated_block *ab); int mem_retrench(struct allocated_block *ab); // 通过内存紧缩技术给新进程分配内存空间 int mem_retrench(struct allocated_block *ab) { struct allocated_block *allocated_work, *allocated_pre = allocated_block_head; struct free_block_type *free_work, *free_pre = free_block-&gt;next; if(allocated_pre == NULL) return -1; allocated_pre-&gt;start_addr = 0; allocated_work = allocated_pre-&gt;next; while(allocated_work != NULL) { allocated_work-&gt;start_addr = allocated_pre-&gt;start_addr + allocated_pre-&gt;size; allocated_pre = allocated_work; allocated_work = allocated_work-&gt;next; } free_block-&gt;start_addr = allocated_pre-&gt;start_addr + allocated_pre-&gt;size; free_block-&gt;size = current_free_mem_size; free_block-&gt;next = NULL; free_work = free_pre; while(free_pre != NULL) { free(free_pre); free_pre = free_work; if(free_pre != NULL) free_work = free_work-&gt;next; } allocate(NULL, free_block, ab); return 1; } // 给新进程分配内存空间 int allocate(struct free_block_type *pre, struct free_block_type *allocate_free_block, struct allocated_block *ab) { struct allocated_block *p = allocated_block_head; ab-&gt;start_addr = allocate_free_block-&gt;start_addr; if(allocate_free_block-&gt;size - ab-&gt;size &lt; MIN_SLICE) { ab-&gt;size = allocate_free_block-&gt;size; if(pre != NULL) { pre-&gt;next = allocate_free_block; } else { free_block = allocate_free_block-&gt;next; } free(allocate_free_block); } else { allocate_free_block-&gt;start_addr += ab-&gt;size; allocate_free_block-&gt;size -= ab-&gt;size; } if(p == NULL) { allocated_block_head = ab; } else { while(p-&gt;next != NULL) p = p-&gt;next; p-&gt;next = ab; } current_free_mem_size -= ab-&gt;size; if(current_free_mem_size == 0) free_block = NULL; return 0; } //按照最坏适应算法给新进程分配内存空间 int allocate_WF(struct allocated_block *ab) { int ret; struct free_block_type *wf = free_block; if(wf == NULL) return -1; if(wf-&gt;size &gt;= ab-&gt;size) allocate(NULL, wf, ab); else if(current_free_mem_size &gt;= ab-&gt;size) ret = mem_retrench(ab); else ret = -2; rearrange_WF(); return ret; } // 按照最佳适应算法给新进程分配内存空间 int allocate_BF(struct allocated_block *ab) { int ret; struct free_block_type *pre = NULL, *bf = free_block; if(bf == NULL) return -1; while(bf != NULL) { if(bf-&gt;size &gt;= ab-&gt;size) { ret = allocate(pre, bf,ab); break; } pre = bf; pre = pre-&gt;next; } if(bf == NULL &amp;&amp; current_free_mem_size &gt; ab-&gt;size) ret = mem_retrench(ab); else ret = -2; rearrange_BF(); return ret; } // 按照首次适应算法给新进程分配内存空间 int allocate_FF(struct allocated_block *ab) { int ret; struct free_block_type *pre = NULL, *ff = free_block; if(ff == NULL) return -1; while(ff != NULL) { if(ff-&gt;size &gt;= ab-&gt;size) { ret = allocate(pre, ff,ab); break; } pre = ff; pre = pre-&gt;next; } if(ff == NULL &amp;&amp; current_free_mem_size &gt; ab-&gt;size) ret = mem_retrench(ab); else ret = -2; rearrange_FF(); return ret; } //分配内存模块 int allocate_mem(struct allocated_block *ab) { int ret ; struct free_block_type *fbt, *pre; int request_size = ab-&gt;size; fbt = pre = free_block; switch(ma_algorithm) { case MA_FF : ret = allocate_FF(ab); break; case MA_BF : ret = allocate_BF(ab); break; case MA_WF : ret = allocate_WF(ab); break; default : break; } return ret; } // 创建一个新的进程。 int new_process() { struct allocated_block *ab; int size; int ret; ab = (struct allocated_block *)malloc(sizeof(struct allocated_block)); if(!ab) exit(-5); ab-&gt;next = NULL; pid++; sprintf(ab-&gt;process_name, &quot;PROCESS-%02d&quot;, pid);//sprintf()函数将格式化的数据写入某字符串中 ab-&gt;pid = pid; printf(&quot;Memory for %s:&quot;, ab-&gt;process_name); for(; ; ) { scanf(&quot;%d&quot;, &amp;size); getchar(); if(size &gt; 0) { ab-&gt;size = size; break; } else printf(&quot;The size have to greater than zero! Please input again!&quot;); } ret = allocate_mem(ab); //从空闲区分配内存，ret==1表示分配ok if((ret == 1) &amp;&amp; (allocated_block_head == NULL))//如果此时allocated_block_head尚未赋值，则赋值 { //进程分配链表为空 allocated_block_head = ab; return 1; } else if(ret == 1) //分配成功，将该已分配块的描述插入已分配链表 { ab-&gt;next = allocated_block_head;//头插法 allocated_block_head = ab; return 2; } else if(ret == -1) //分配不成功 { printf(&quot;Allocation fail\\n&quot;); free(ab); return -1; } return 3; } //退出程序并释放内存空间。 int do_exit() { struct allocated_block *allocated_ab, *allocated_pre; struct free_block_type *free_ab, *free_pre; free_pre = free_block; allocated_pre = allocated_block_head; if(free_pre != NULL) { free_ab = free_pre-&gt;next; while(free_ab != NULL) { free(free_pre); free_pre = free_ab; free_ab = free_ab-&gt;next; } } if(allocated_pre != NULL) { allocated_ab = allocated_pre-&gt;next; while(allocated_ab != NULL) { free(allocated_pre); allocated_pre = allocated_ab; allocated_ab = allocated_ab-&gt;next; } } allocated_ab = allocated_ab-&gt;next; return 0; } //在进程分配链表中寻找指定进程。 struct allocated_block *find_process(int pid) { struct allocated_block *ab = allocated_block_head; if(ab == NULL) { printf(&quot;Here??????111111111\\n&quot;); return NULL; } while(ab-&gt;pid != pid &amp;&amp; ab-&gt;next != NULL) ab = ab-&gt;next; if(ab-&gt;next == NULL &amp;&amp; ab-&gt;pid != pid) { printf(&quot;Here??????2222222\\n&quot;); return NULL; } return ab; } //显示当前内存的使用情况，包括空闲区的情况和已经分配的情况。 int display_mem_usage() { struct free_block_type *fbt = free_block; struct allocated_block *ab = allocated_block_head; printf(&quot;----------------------------------------------------------\\n&quot;); //显示空闲区 printf(&quot;Free Memory:\\n&quot;); printf(&quot;%20s %20s\\n&quot;, &quot; start_addr&quot;, &quot; size&quot;); while(fbt != NULL) { printf(&quot;%20d %20d\\n&quot;, fbt-&gt;start_addr, fbt-&gt;size); fbt = fbt-&gt;next; } //显示已分配区 printf(&quot;\\nUsed Memory:\\n&quot;); printf(&quot;%10s %20s %10s %10s\\n&quot;, &quot;PID&quot;, &quot;ProcessName&quot;, &quot;start_addr&quot;, &quot; size&quot;); while(ab != NULL) { printf(&quot;%10d %20s %10d %10d\\n&quot;, ab-&gt;pid, ab-&gt;process_name, ab-&gt;start_addr, ab-&gt;size); ab = ab-&gt;next; } printf(&quot;----------------------------------------------------------\\n&quot;); return 1; } // 释放ab数据结构节点。 int dispose(struct allocated_block *free_ab) { struct allocated_block *pre, *ab; if(free_block == NULL) return -1; if(free_ab == allocated_block_head)//如果要释放第一个节点 { allocated_block_head = allocated_block_head-&gt;next; free(free_ab); } else { pre = allocated_block_head; ab = allocated_block_head-&gt;next; //找到free_ab while(ab != free_ab) { pre = ab; ab = ab-&gt;next; } pre-&gt;next = ab-&gt;next; free(ab); } return 1; } /*将ab所表示的已分配区归还，并进行可能的合并*/ int free_mem(struct allocated_block *ab) { int algorithm = ma_algorithm; struct free_block_type *fbt, *pre, *work; fbt = (struct free_block_type*)malloc(sizeof(struct free_block_type)); if(!fbt) return -1; pre = free_block; fbt-&gt;start_addr = ab-&gt;start_addr; fbt-&gt;size = ab-&gt;size; fbt-&gt;next = NULL; if(pre != NULL) { while(pre-&gt;next != NULL) pre = pre-&gt;next; pre-&gt;next = fbt; } else { free_block = fbt; } rearrange_FF(); pre = free_block; work = pre-&gt;next; while(work != NULL) { if(pre-&gt;start_addr + pre-&gt;size == work-&gt;start_addr) { pre-&gt;size += work-&gt;size; free(work); work = pre-&gt;next; } else { pre = work; work = work-&gt;next; } } current_free_mem_size += ab-&gt;size; return 1; } // 删除进程，归还分配的存储空间，并删除描述该进程内存分配的节点。 void kill_process() { struct allocated_block *ab; int pid; printf(&quot;Kill Process, pid=&quot;); scanf(&quot;%d&quot;, &amp;pid); getchar(); ab = find_process(pid); if(ab != NULL) { free_mem(ab); /*释放ab所表示的分配区*/ dispose(ab); /*释放ab数据结构节点*/ } } //按FF算法重新整理内存空闲块链表,按空闲块首地址排序。 int rearrange_FF() { struct free_block_type *head = free_block; struct free_block_type *forehand, *pre, *rear; int i; if(head == NULL) return -1; //冒泡排序 for(i = 0; i &lt; free_block_count-1; i++) { forehand = head; pre = forehand-&gt;next; rear = pre-&gt;next; while(pre-&gt;next != NULL) { if(forehand == head &amp;&amp; forehand-&gt;start_addr &gt;= pre-&gt;start_addr)//比较空闲链表中第一个空闲块与第二个空闲块的开始地址的大小 { head-&gt;next = pre-&gt;next; pre-&gt;next = head; head = pre; forehand = head-&gt;next; pre = forehand-&gt;next; rear = pre-&gt;next; } else if(pre-&gt;start_addr &gt;= rear-&gt;start_addr)//比较链表中其他相邻两节点的开始地址的大小 { pre-&gt;next = rear-&gt;next; forehand-&gt;next = rear; rear-&gt;next = pre; forehand = rear; rear = pre-&gt;next; } else { forehand = pre; pre = rear; rear = rear-&gt;next; } } } return 0; } // 按BF算法重新整理内存空闲块链表,按空闲块大小从小到大排序。 int rearrange_BF() { struct free_block_type *head = free_block; struct free_block_type *forehand, *pre, *rear; int i; if(head == NULL) return -1; //冒泡排序 for(i = 0; i &lt; free_block_count-1; i++) { forehand = head; pre = forehand-&gt;next; rear = pre-&gt;next; while(pre-&gt;next != NULL) { if(forehand == head &amp;&amp; forehand-&gt;size &lt;= pre-&gt;size)//比较空闲链表中第一个空闲块与第二个空闲块的空间的大小 { head-&gt;next = pre-&gt;next; pre-&gt;next = head; head = pre; forehand = head-&gt;next; pre = forehand-&gt;next; rear = pre-&gt;next; } else if(pre-&gt;size &lt;= rear-&gt;size)//比较链表中其他相邻两节点的空间的大小 { pre-&gt;next = rear-&gt;next; forehand-&gt;next = rear; rear-&gt;next = pre; forehand = rear; rear = pre-&gt;next; } else { forehand = pre; pre = rear; rear = rear-&gt;next; } } } return 0; } //按WF算法重新整理内存空闲块链表,按空闲块大小从大到小排序。 int rearrange_WF() { struct free_block_type *head = free_block; struct free_block_type *forehand, *pre, *rear; int i; if(head == NULL) return -1; //冒泡排序 for(i = 0; i &lt; free_block_count-1; i++) { forehand = head; pre = forehand-&gt;next; rear = pre-&gt;next; while(pre-&gt;next != NULL) { if(forehand == head &amp;&amp; forehand-&gt;size &gt;= pre-&gt;size)//比较空闲链表中第一个空闲块与第二个空闲块空间的大小 { head-&gt;next = pre-&gt;next; pre-&gt;next = head; head = pre; forehand = head-&gt;next; pre = forehand-&gt;next; rear = pre-&gt;next; } else if(pre-&gt;size &gt;= rear-&gt;size)//比较链表中其他相邻两节点的空间的大小 { pre-&gt;next = rear-&gt;next; forehand-&gt;next = rear; rear-&gt;next = pre; forehand = rear; rear = pre-&gt;next; } else { forehand = pre; pre = rear; rear = rear-&gt;next; } } } return 0; } //按指定的算法整理内存空闲块链表。 void rearrange(int algorithm) { switch(algorithm) { case MA_FF: rearrange_FF(); break; case MA_BF: rearrange_BF(); break; case MA_WF: rearrange_WF(); break; } } //设置当前的分配算法 void set_algorithm() { int algorithm; //system(&quot;clear&quot;); printf(&quot;\\t1 - First Fit\\n&quot;);//首次适应算法 printf(&quot;\\t2 - Best Fit \\n&quot;);//最佳适应算法 printf(&quot;\\t3 - Worst Fit \\n&quot;);//最坏适应算法 printf(&quot;\\nPlease choose(1~3):&quot;); for(; ; ) { scanf(&quot;%d&quot;, &amp;algorithm); getchar(); if(algorithm &gt;= 1 &amp;&amp; algorithm &lt;= 3) { ma_algorithm = algorithm; break; } else { printf(&quot;\\nCannot input %d, Please input 1~3 : &quot;, algorithm); } } //按指定算法重新排列空闲区链表 rearrange(ma_algorithm); } //设置内存的大小 int set_mem_size() { int size; if(flag != 0)//防止重复设置 { printf(&quot;Cannot set memory size again\\n&quot;); return 0; } printf(&quot;Total memory size = &quot;); for(; ; ) { scanf(&quot;%d&quot;, &amp;size); getchar(); if(size &gt; 0) { current_free_mem_size = size; mem_size = size;//设置内存大小为size free_block-&gt;size = mem_size;//设置空闲块大小为size break; } else { printf(&quot;The size must greater than zero! Please input again:&quot;); } } flag = 1;//内存大小已经设置 return 1; } //显示主菜单 void display_menu() { printf(&quot;\\n&quot;); //system(&quot;clear&quot;); printf(&quot;1 - Set memory size (default=%d)\\n&quot;, DEFAULT_MEM_SIZE); printf(&quot;2 - Select memory allocation algorithm\\n&quot;); printf(&quot;3 - New process \\n&quot;); printf(&quot;4 - Terminate a process \\n&quot;); printf(&quot;5 - Display memory usage \\n&quot;); printf(&quot;0 - Exit\\n&quot;); } // 初始化空闲块，默认为一块，可以指定大小及起始地址 struct free_block_type* init_free_block(int mem_size) { struct free_block_type *fb; fb = (struct free_block_type *)malloc(sizeof(struct free_block_type)); if(fb == NULL)//初始化失败 { printf(&quot;No mem\\n&quot;); return NULL; } current_free_mem_size = mem_size; fb-&gt;size = mem_size;//设置空闲块大小 fb-&gt;start_addr = DEFAULT_MEM_START;//空闲块起始地址 fb-&gt;next = NULL;//首地址指向NULL return fb; } /*主函数*/ int main(void) { char choice; pid = 0; free_block = init_free_block(mem_size); //初始化空闲区 while(1) { display_menu();//显示菜单 fflush(stdin); choice = getchar();//获取用户输入 getchar(); switch(choice) { case &apos;1&apos;: //设置内存大小 set_mem_size(); break; case &apos;2&apos;: //设置算法 set_algorithm(); flag = 1; break; case &apos;3&apos;: //创建新进程 new_process(); flag = 1; break; case &apos;4&apos;://删除进程 kill_process(); flag = 1; break; case &apos;5&apos;://显示内存使用 display_mem_usage(); flag = 1; break; case &apos;0&apos;: //释放链表并退出 do_exit(); exit(0); default: break; } } } 七、改进 内存整理： 删除空闲内存，重新过一遍算法","categories":[],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/tags/操作系统/"}]},{"title":"面试-操作系统","slug":"面试-操作系统","date":"2018-05-23T07:38:44.000Z","updated":"2018-06-04T22:18:16.000Z","comments":true,"path":"面试-操作系统/","link":"","permalink":"http://yoursite.com/面试-操作系统/","excerpt":"","text":"1.请问下面的程序一共输出多少个“-”？#include&lt;stdio.h&gt; #include&lt;sys/types.h&gt; #include&lt;unistd.h&gt; int main() { int i; for(i=0;i&lt;2;i++){ fork(); printf(&quot;-&quot;); } wait(NULL); wait(NULL); return 0; } 输出：8个“-” 若：\\n#include&lt;stdio.h&gt; #include&lt;sys/types.h&gt; #include&lt;unistd.h&gt; int main() { int i; for(i=0;i&lt;2;i++){ fork(); printf(&quot;-\\n&quot;); } wait(NULL); wait(NULL); return 0; } 输出：6个“-” 若：fflush(stdout);#include&lt;stdio.h&gt; #include&lt;sys/types.h&gt; #include&lt;unistd.h&gt; int main() { int i; for(i=0;i&lt;2;i++){ fork(); printf(&quot;-&quot;); fflush(stdout); } wait(NULL); wait(NULL); return 0; } 输出：6个“-” 若：EOF#include&lt;stdio.h&gt; #include&lt;sys/types.h&gt; #include&lt;unistd.h&gt; int main() { int i; int c; for(i=0;i&lt;2;i++){ fork(); printf(&quot;-&quot;); c=getchar(); } wait(NULL); wait(NULL); return 0; } 输出：6个“-” 为什么？- //产生两个进程 i=0 - - //2个 i=1 - - - - //4个 总结 因为printf（“-”）语句有buffer，把“-”放在了缓存中，并没有真正的输出，在fork的时候，缓存被复制了子进程空间，就成了8个。 Unix下的设备有“块设备”，就是以一块一块的数据存取的设备，如磁盘和内存；“字符设备”是一个存取一个字符设备，如键盘和串口。块设备一般都有缓存，而字符设备一般没有缓存。 遇到“\\n”、主动flush、EOF、缓存区满、文件描述符关闭、程序退出，等就会把数据刷出缓存区 2.在物理内存为1G的计算机中能否malloc(1.2G)？问题：不同平台上去测试malloc()最多能分配多大内存空间时，为什么结果有时不同？ 测试：Linux环境下：Windows环境：结论代码：#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; unsigned maximum=1024*1024*1024; int main(int argc, char *argv[]) { unsigned blocksize[]={1024*1024,1024,1}; int i,count; void *block; for(i=0;i&lt;sizeof(blocksize)/sizeof(unsigned);i++) { for(count=1; ;count++) { block=malloc(maximum+blocksize[i]*count); if(block!=NULL) { maximum=maximum+blocksize[i]*count; free(block); } else { break; } } } /*printf(&quot;maximummalloc size=%u bytes\\n&quot;,maximum);*/ printf(&quot;2&quot;); return 0; }","categories":[],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/tags/操作系统/"}]},{"title":"Git相关问题","slug":"Git相关问题","date":"2018-05-22T07:40:25.000Z","updated":"2019-02-22T07:53:02.803Z","comments":true,"path":"Git相关问题/","link":"","permalink":"http://yoursite.com/Git相关问题/","excerpt":"","text":"如何在同一电脑上进行多个Github帐号配置 配置~/.ssh/config文件 修改~/.ssh/config文件，如果.ssh下没有这个文件可以自己创建，修改后的config文件内容如下： Host github.com HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa Host cocoding.github.com HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_newkey NPM问题安装完node.js并配置环境变量。在cmd窗口检查npm安装是否成功。 安装淘宝npm： 临时使用 npm --registry https://registry.npm.taobao.org install express 持久使用 npm config set registry https://registry.npm.taobao.org 配置后可通过下面方式来验证是否成功 npm config get registry 或 npm info express 通过cnpm使用 npm install -g cnpm –registry=https://registry.npm.taobao.org 使用 cnpm install express","categories":[],"tags":[{"name":"教程","slug":"教程","permalink":"http://yoursite.com/tags/教程/"}]},{"title":"FAQ","slug":"FAQ","date":"2018-05-02T16:00:00.000Z","updated":"2018-08-11T05:11:00.000Z","comments":true,"path":"FAQ/","link":"","permalink":"http://yoursite.com/FAQ/","excerpt":"","text":"Q1:浏览器报Uncaught ReferenceError: require is not definedA1:这个时候你需要看下你是不是在浏览器中运行node.js的模块了.不要把node.js和js搞混了,两个的运行环境是不相同.所以,你再浏览器环境下使用node.js的方法显示的not defined.Q2:Ajax A2:服务端渲染随着单页面应用以及Restful接口的兴起，Ajax逐渐成为目前前后端交流最为频繁的方式。 Ajax的核心是XmlHttpRequest。我们通过对该对象的操作来进行异步的数据请求。 实际上我们接触到最多jQuey就有很好的封装，比如$.ajax，$.post等，如果用Angular的话我们可以用$http服务， 除了这些之外，我们可以使用第三方的Ajax库qwest等。","categories":[],"tags":[{"name":"FAQ","slug":"FAQ","permalink":"http://yoursite.com/tags/FAQ/"}]},{"title":"实验-进程管理(线程、进程、互斥与死锁)","slug":"实验-进程管理","date":"2018-04-28T01:48:11.000Z","updated":"2018-06-04T22:10:42.000Z","comments":true,"path":"实验-进程管理/","link":"","permalink":"http://yoursite.com/实验-进程管理/","excerpt":"","text":"一. 实验目的及实验环境实验环境硬件处理器：i7；内存：8G；显示器：VGA 或更高；硬盘空间：128G。 软件Centos 7下gcc编译器、gdb调试工具。 实验目的进程通过观察、分析实验现象，深入理解多进程并发执行的过程、fork函数在创建子进程时对内存的操作；加深对进程概念的理解，明确进程和程序的区别；进一步认识并发执行的实质；分析进程争用资源的现象，学习解决进程互斥的方；了解Linux系统中进程通信的基本原理。 线程理解多线程的概念，学会Linux编程中的线程的创建与终止。理解多线程并发工作时对资源的抢占，通过本实验掌握在Linux操作系统中遵循Posix线程标准接口进行多线程程序编程，熟练掌握线程的创建pthread_create()。 互斥与死锁理解死锁的产生原因与Linux编程中对临界资源进行加锁使得多进程或多线程对临界资源进行互斥访问。 利用信号量或者互斥锁实现线程间的同步。 二、实验内容进程1、你最初认为运行结果会怎么样？ 答：会持续输出0-9号进程，直到输入数字键+回车，则会杀死该进程，接下来的输出将不会有该进程号，当输入q+回车，则退出程序。 2、实际的结果什么样？有什么特点？试对产生该现象的原因进行分析。 答：实际的结果与预期差不多。因输入进程总数3小于设定的最大进程数，因此按进程数3来处理。随机输出0-2号进程，sleep(SLEEP_INTERVAL)，循环输出，输入数字键，则会杀死该数字对应的进程，直到输入q退出循环，然后kill杀死本组所有进程。分析：每创建一个子进程时，将其pid存储在pid[i]中，i存储在proc_number，然后调用死循环函数do_something()，输出该进程的代号proc_number；当输入数字键时，主进程会执行kill(pid[ch-‘0’],SIGTERM)，从而杀死（ch-‘0’）号进程。当输入q时循环退出，kill(0,SIGTERM)，杀死本组所有进程，程序退出。 3、proc_number 这个全局变量在各个子进程里的值相同吗？为什么？ 答：相同，因为子进程相互独立，资源互不影响。 4、kill 命令在程序中使用了几次？每次的作用是什么？执行后的现象是什么？ 答：kill命令在程序中使用了2次：kill(pid[ch-‘0’],SIGTERM)和kill(0,SIGTERM);第一次是杀死该进程号pid[ch-‘0’]，执行后接下来的结果中不会有该进程号，就会使该子进程真正结束。第二次是杀死本组所有进程。即主进程以及它创建的所有子进程。执行后程序退出，进程结束。 5、使用kill 命令可以在进程的外部杀死进程。进程怎样能主动退出？这两种退出方式哪种更好一些？ 答：进程在main函数中return，或调用exit()函数都可以正常退出。 而使用kill命令则是异常退出。 当然是正常退出比较好，若在子进程退出前使用kill命令杀死其父进程，则系统会让init进程接管子进程。当用kill命令使得子进程先于父进程退出时，而父进程又没有调用wait函数等待子进程结束，子进程处于僵死状态，并且会一直保持下去，直到系统重启。子进程处于僵死状态时，内核只保存该进程的必要信息以被父进程所需，此时子进程始终占着资源，同时减少了系统可以创建的最大进程数。 6、在do_something()输出pro_number的地址，把do_something里的死循环改成10次，问实际创建的子进程个数有什么变化？ 答：pro_number的地址不变，当把死循环改成10次后，子进程个数只有10个，并且杀死后的进程还是会重新输出。 线程1、你最初认为前三列数会相等吗？最后一列斜杠两边的数字是相等，还是大于或者小于关系？ 答：我认为前三列数不会相等，因为线程之间在抢占cpu资源，三个线程运行次数是随机的，最后一列的数字左边等于右边。 2、最后的结果如你所料吗？有什么特点？试对原因进行分析。 答：最后的结果不是我所预料的，最后斜杠两边的数字时一样的，原因在与我在程序中添加了信号量。 3、thread 的CPU 占用率是多少？为什么会这样？答：在我的电脑上cpu占用率147%,一个方面是线程执行的都是无限循环的代码，另一方面是线程之间抢占资源很激烈。 4、thread_worker()内是死循环，它是怎么退出的？你认为这样退出好吗？ 答：thread_worker()函数内是死循环，退出时因为主函数中设置的输入q时循环退出。整个进程的终止导致了所有线程的结束，这样结束线程不好，因为如果线程使用临界资源的时候没有释放就结束了，那么这个临界资源就会被认为是被已经退出的线程占用着，从而得不到释放。 互斥与死锁1、你预想deadlock.c 的运行结果会如何？ 答：运行结果可能会发生中止现象，我认为thread1和thread2会相互争抢资源，有一定的概率发生死锁，因为他们的运行顺序是抢占式的。 2、deadlock.c 的实际运行结果如何？多次运行每次的现象都一样吗？为什么会这样？ 答：实际的运行结果是：开始几次运行正常，但是经过多次的运行之后，其中一次会让程序卡死，无法再执行。这是因为thread1锁定了资源1，thread2锁定了资源2，两个线程又同时需要对方的资源，这样导致了死锁。 三．方案设计进程利用fork( )函数创建进程，并将每个进程的进程号保存在主进程中保存进程号的数组。每个进程输出自己是第几个进程与自己的进程号。当用户输入’q’时，主进程向每个进程发送终止信号，杀死所有进程；学习fork与kill的用法，补全程序代码，调试运行，观察并 分析实验结果。 线程主进程创建三个线程并发工作。这三个线程都对main_counter进程修改(没执行一次循环将main_counter加1)，也将属于自己线程的变量counter[i]加1，最后比较三个线程counter值之和与main_counter的大小。补全程序代码，调试运行，观察并 分析实验结果。 互斥与死锁准备好上节实验3完成的程序。阅读参考资料，了解互斥锁的加锁机制 及相关的系统调用。找到实验3程序的代码临界区，用临界区解决 main_counter 与sum 不同步的问题。对main_counter与sum加锁实现三个线程的互斥访问。 四．测试数据及运行结果进程：线程：互斥与死锁：五．总结在本次实验中，我学会了创建进程和杀死进程，创建线程和杀死线程，线程的种类，和线程创建及管理机制并且了解了线程互斥锁的类型。重新理解了互斥与同步的概念以及死锁及其相关内容。更进一步认识死锁的发生条件和预防死锁发生的方法。死锁发生的条件有互斥条件，占有且等待条件，不可抢占条件等。我们只要破坏死锁发生条件之一我们就可以预防死锁的发生！本实验采用破坏占有且等待条件预防死锁发生！处理及调度的算法有一定的难度，因为其理论上的难度，但是通过学习让我对其有了更加深入的了解，让我认识到了，操作系统是一项真正实用，而且很有意义的学科，增加了我对操作系统的兴趣，也为以后的学习打下理论基础。 六、源代码进程#include&lt;stdio.h&gt; #include&lt;sys/types.h&gt; #include&lt;unistd.h&gt; #include&lt;signal.h&gt; #include&lt;ctype.h&gt; #define MAX_CHILD_NUMBER 10 #define SLEEP_INTERVAL 2 int proc_number=0; void do_something(); main(int argc,char* argv[]) { int child_proc_number=MAX_CHILD_NUMBER; int i; char ch; pid_t child_pid; pid_t pid[10]={0};/*存放每个子进程的id*/ if(argc&gt;1) { child_proc_number=atoi(argv[1]); child_proc_number=(child_proc_number&gt;10)?10:child_proc_number; } for(i=0;i&lt;child_proc_number;i++) { child_pid=fork(); if(child_pid==-1) { perror(&quot;fork&quot;); } else if(child_pid==0) { proc_number=i; do_something(); } else pid[i]=child_pid; } /*用户选择杀死进程，数字表示杀死该进程,q表示退出*/ printf(&quot;请输入要杀死进程的编号(q退出):\\n&quot;); while((ch=getchar())!=&apos;q&apos;) { if(isdigit(ch)) { kill(pid[ch-&apos;0&apos;],SIGTERM); } } /*杀死本组的所有进程*/ for(i=0;i&lt;=proc_number;i++) { kill(pid[i],SIGTERM); } kill(0,SIGTERM); return; } void do_something() { for(;;) { printf(&quot;This is process No.%d and its pid is %d\\n&quot;,proc_number,getpid()); sleep(SLEEP_INTERVAL); } } 线程#include &lt;stdio.h&gt; #include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; #include &lt;ctype.h&gt; #include &lt;pthread.h&gt; #include&lt;semaphore.h&gt; #define MAX_THREAD 3 /* 线程的个数 */ unsigned long long main_counter, counter[MAX_THREAD]; /* unsigned long long是比long还长的整数 */ sem_t S1,S2; void* thread_worker(void*); void *thread_worker(void *p){ int thread_num; thread_num=(int)p; for(;;){ sem_wait(&amp;S1); sem_wait(&amp;S2); counter[thread_num]++;/* 本线程的counter加一 */ main_counter++;/* 主counter 加一 */ sem_post(&amp;S2); sem_post(&amp;S1); } } int main(int argc,char *argv[]) { int i,rtn,ch; pthread_t pthread_id[MAX_THREAD]={0}; sem_init(&amp;S1,0,1); sem_init(&amp;S2,0,1); for(i=0;i&lt;MAX_THREAD;i++) { rtn=pthread_create(&amp;pthread_id[i],NULL,thread_worker,(void*)i); } do { unsigned long long sum=0; sem_wait(&amp;S1); sem_wait(&amp;S2); for(i=0;i&lt;MAX_THREAD;i++){/* 求所有counter的和 */ sum+=counter[i]; printf(&quot;第%d个counter的值是%llu\\n&quot;,i+1,counter[i]); } printf(&quot;main_counter的值:%llu sum的值%llu\\n&quot;,main_counter,sum); sem_post(&amp;S2); sem_post(&amp;S1); }while((ch=getchar())!=&apos;q&apos;); return 0; } 互斥锁#include &lt;stdio.h&gt; #include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; # include &lt;ctype.h&gt; #include &lt;pthread.h&gt; #define LOOP_TIMES 10000 pthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER; pthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER; void* thread_worker(void*); void critical_section(int thread_num, int i); void *thread_worker(void *p) { int i; for(i=0;i&lt;LOOP_TIMES;i++) { //对互斥锁上锁 pthread_mutex_lock(&amp;mutex1); pthread_mutex_lock(&amp;mutex2); critical_section(2,i); //对互斥锁解锁 pthread_mutex_unlock(&amp;mutex2); pthread_mutex_unlock(&amp;mutex1); } } void critical_section(int thread_num,int i) { printf(&quot;Thread%d:%d\\n&quot;,thread_num,i); } int main() { int rtn,i; pthread_t pthread_id=0; rtn=pthread_create(&amp;pthread_id,NULL,thread_worker,NULL); if(rtn!=0) { printf(&quot;pthread_create ERROR!\\n&quot;); return -1; } for(i=0;i&lt;LOOP_TIMES;i++) { pthread_mutex_lock(&amp;mutex1); pthread_mutex_lock(&amp;mutex2); critical_section(1,i); pthread_mutex_unlock(&amp;mutex2); pthread_mutex_unlock(&amp;mutex1); } //互斥锁销毁 pthread_mutex_destroy(&amp;mutex1); pthread_mutex_destroy(&amp;mutex2); return 0; } 信号量#include&lt;stdio.h&gt; #include&lt;sys/types.h&gt; #include&lt;ctype.h&gt; #include&lt;unistd.h&gt; #include&lt;pthread.h&gt; #include&lt;semaphore.h&gt; #define LOOP_TIMES 10000 sem_t S1,S2; void *thread_worker(void *); void critical_section(int thread_num,int i); void *thread_worker(void *p) { int i; for(i=0;i&lt;LOOP_TIMES;i++) { //信号量减一 sem_wait(&amp;S2); sem_wait(&amp;S1); critical_section(2,i); //信号量加一 sem_post(&amp;S1); sem_post(&amp;S2); } } void critical_section(int thread_num,int i) { printf(&quot;Thread%d:%d\\n&quot;,thread_num,i); } int main() { int rtn,i; sem_init(&amp;S1,0,1); sem_init(&amp;S2,0,1); pthread_t pthread_id=0; rtn=pthread_create(&amp;pthread_id,NULL,thread_worker,NULL); if(rtn!=0) { printf(&quot;pthread_create ERROR!\\n&quot;); return -1; } for(i=0;i&lt;LOOP_TIMES;i++) { sem_wait(&amp;S1); sem_wait(&amp;S2); critical_section(1,i); sem_post(&amp;S1); sem_post(&amp;S2); } //销毁信号量 sem_destroy(&amp;S1); sem_destroy(&amp;S2); return 0; } 七、改进","categories":[],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/tags/操作系统/"}]},{"title":"JavaScript教程","slug":"JavaScript 教程","date":"2018-04-22T06:06:29.000Z","updated":"2019-02-22T09:30:45.596Z","comments":true,"path":"JavaScript 教程/","link":"","permalink":"http://yoursite.com/JavaScript 教程/","excerpt":"","text":"JavaScript 简介JavaScript 是世界上最流行的编程语言。这门语言可用于 HTML 和 web，更可广泛用于服务器、PC、笔记本电脑、平板电脑和智能手机等设备。 JavaScript 是脚本语言JavaScript 是一种轻量级的编程语言。 JavaScript 是可插入 HTML 页面的编程代码。 JavaScript 插入 HTML 页面后，可由所有的现代浏览器执行。 JavaScript 很容易学习。 JavaScript：写入 HTML 输出实例document.write(&quot;&lt;h1&gt;This is a heading&lt;/h1&gt;&quot;); document.write(&quot;&lt;p&gt;This is a paragraph&lt;/p&gt;&quot;); 提示您只能在 HTML 输出中使用 document.write。如果您在文档加载后使用该方法，会覆盖整个文档。 JavaScript：对事件作出反应实例&lt;button type=&quot;button&quot; onclick=&quot;alert(&apos;Welcome!&apos;)&quot;&gt;点击这里&lt;/button&gt; 亲自试一试alert() 函数在 JavaScript 中并不常用，但它对于代码测试非常方便。 onclick 事件只是您即将在本教程中学到的众多事件之一。 JavaScript：改变 HTML 内容使用 JavaScript 来处理 HTML 内容是非常强大的功能。 实例x=document.getElementById(&quot;demo&quot;) //查找元素 x.innerHTML=&quot;Hello JavaScript&quot;;//改变内容 亲自试一试您会经常看到 document.getElementByID(“some id”)。这个方法是 HTML DOM 中定义的。 DOM（文档对象模型）是用以访问 HTML 元素的正式 W3C 标准。 您将在本教程的多个章节中学到有关 HTML DOM 的知识。","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yoursite.com/tags/JavaScript/"}]},{"title":"Windows 基本操作","slug":"Windows 基本操作","date":"2018-04-17T08:15:33.000Z","updated":"2019-02-22T08:40:23.376Z","comments":true,"path":"Windows 基本操作/","link":"","permalink":"http://yoursite.com/Windows 基本操作/","excerpt":"","text":"如何把Win10用户头像恢复成默认用户头像（黑白头像）https://www.windows10.pro/restore-the-default-avatar/ Windows10 1709 专业版 内置账户Administrator无法使用指纹登录Windows怎样实现自动登录而无需输入密码https://jingyan.baidu.com/article/851fbc370272633e1f15abca.html control userpasswords2 查看系统激活状态slmgr.vbs -xpr 如何重置outlook到初始状态 Windows下阅读linux源码的强大软件Source Insighthttps://blog.csdn.net/star714/article/details/71107666","categories":[],"tags":[{"name":"教程","slug":"教程","permalink":"http://yoursite.com/tags/教程/"}]},{"title":"Linux基本操作","slug":"Linux基本操作","date":"2018-04-11T09:15:33.000Z","updated":"2019-02-22T09:40:02.629Z","comments":true,"path":"Linux基本操作/","link":"","permalink":"http://yoursite.com/Linux基本操作/","excerpt":"","text":"安装linux-header1apt-get install -y linux-headers-$(uname -r) debian安装mysql：https://www.jianshu.com/p/40b770d86a7b apt-get的update指令更新源 apt-get的update指令更新源 1234sudo apt-get updateapt-get install mysql-server debian8.8安装谷歌浏览器第一步：下载： wget https://dl.google.com/linux/direct/google-chrome-stable_current_i386.deb //32位 wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb //64位 第二步：安装 dpkg -i google-chrome*.deb 如果提示出错：用命令修复：apt-get -f install（所有命令在root下执行） 当发现可能是安装的其他软件包不兼容导致了安装包出错时，可以根据提示需要执行sudo apt-get -f install来卸载之前的冲突包。如果安装过aptitude包，还可以使用命令 aptitude -f install ，实现相同的效果。 说明： sudo apt-get -f install 是修复损坏的软件包，尝试卸载出错的包，重新安装正确版本的。 -f 是 参数 放在 install 前面跟后面是一样的效果 即： &quot; sudo apt-get -f install &quot; equals to &quot; sudo apt-get install -f&quot; Debian从命令行模式启动自用gnome桌面美化插件tweak-toolhttps://blog.csdn.net/weixin_38600067/article/details/78730017https://extensions.gnome.org/ ubuntu12.04添加快速启动项到左侧的启动栏上打开**/usr/share/applications**在该处找到你安装的软件的图标，然后点击打开改软件，软件打开后，其图标就会出现在启动栏上，然后***右击*该图标，然后选择“锁定到启动器”即可。** kali linux添加用户https://jingyan.baidu.com/article/380abd0a10b3791d90192cef.html Kali-Linux安装驱动并使用Blueman连接蓝牙耳机https://www.cnblogs.com/bobdylan/p/6933784.html Linux安装gurb到指定分区ubuntu开机进入initramfs的解决办法https://blog.csdn.net/yaoqsm/article/details/78780371 Grub引导项修复详解https://blog.csdn.net/gatieme/article/details/59127020 解决kali-linux更新源无法使用的问题（签名失效）http://www.chenglong.ren/2018/06/04/%E8%A7%A3%E5%86%B3kali-linux%E6%9B%B4%E6%96%B0%E6%BA%90%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E7%AD%BE%E5%90%8D%E5%A4%B1%E6%95%88%EF%BC%89/ kali linux 安装搜狗输入法https://blog.csdn.net/anjingshen/article/details/75909366 Linux 操作系统挂起、休眠、关机相关命令https://blog.csdn.net/uncleunclelee/article/details/52993629 linux 清理cache/buff（缓存）https://blog.csdn.net/chenlei_525/article/details/78137727echo 3 &gt; /proc/sys/vm/drop_caches 在Linux中利用Service命令添加系统服务及开机自启动https://blog.csdn.net/u013554213/article/details/78792686https://blog.csdn.net/aa2650/article/details/6304049http://www.hack1412.com/diandijilu/2018/0323/122.html kali Rolling安装之后的一些常用配置总结https://www.cnblogs.com/ssooking/p/5899499.html VMware Linux下如何卸载VMware Tools?https://jingyan.baidu.com/article/fc07f9895aa92212ffe51986.html Kali Linux 2018 更新源配置https://blog.csdn.net/xfyangle/article/details/81055093 修改启动顺序https://m.aliyun.com/jiaocheng/129513.html 无法获得锁 /var/lib/dpkg/lock - open (11: 资源暂时不可用)https://www.cnblogs.com/fsong/p/5823826.html 设置在开机时自动链接蓝牙https://blog.csdn.net/huuinn/article/details/81064790https://ubuntuforums.org/showthread.php?t=2390542https://blog.csdn.net/huuinn/article/details/81064790https://blog.csdn.net/myfox0630/article/details/51958505 Linux core 文件介绍https://www.cnblogs.com/dongzhiquan/archive/2012/01/20/2328355.html 更改kali默认的grub背景图和登录图片还有桌面背景图片http://tieba.baidu.com/p/3776145153https://www.blackmoreops.com/2015/11/27/change-grub-background-in-kali-linux/ gnome-tweak-tool 安装https://download.gnome.org/sources/gnome-tweak-tool/ 开机进入initramfs?https://jingyan.baidu.com/article/495ba841d5330738b20ede44.html VMware Workstation Pro 15.0.0 官方版+激活密钥https://www.nocmd.com/740.html wechathttps://www.jianshu.com/p/b2896516a049 https://github.com/geeeeeeeeek/electronic-wechat/releases Linux环境崩溃生成core文件以及调试https://www.cnblogs.com/secondtonone1/p/5732938.html /etc/profile中加入以下一行 : ulimit-c 0 Could not get lock /var/lib/dpkg/lock-frontend - open (11: Resource temporarily unavailable) E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is another process using it?https://blog.csdn.net/github_35160620/article/details/51933605 Kali Linux 2018 更新 https://blog.csdn.net/xfyangle/article/details/81055093 更新apt-get clean &amp;&amp; apt-get update &amp;&amp; apt-get upgrade -y &amp;&amp; apt-get dist-upgrade -y 命令讲解：apt-get clean //清除缓存索引apt-get update //更新索引文件apt-get upgrade //更新实际的软件包文件apt-get dist-upgrade //根据依赖关系更新 VMware Workstation 15 Pro 永久激活密钥2018年09月29日 17:12:17 清晨的光明 阅读数：9186 标签： VMware WorkstationVMware Workstation15版权声明：转载请标明出处，谢谢！ https://blog.csdn.net/kdongyi/article/details/82900243 永久激活密钥UG5J2-0ME12-M89WY-NPWXX-WQH88 GA590-86Y05-4806Y-X4PEE-ZV8E0YA18K-0WY8P-H85DY-L4NZG-X7RADUA5DR-2ZD4H-089FY-6YQ5T-YPRX6B806Y-86Y05-GA590-X4PEE-ZV8E0ZF582-0NW5N-H8D2P-0XZEE-Z22VA VMware Tool install way:https://kb.vmware.com/support/kb/enduser/std_adp.php?p_faqid=340&amp;build=10134415 kali linux 开启SSH服务 容许root登陆https://blog.csdn.net/u010953692/article/details/80312751 vscode安装https://code.visualstudio.com/ kali 中文乱码https://www.cnblogs.com/wszme/p/9065268.html chrome浏览器安装flash插件（pepperflashplugin-nonfree）https://www.cnblogs.com/tianhei/p/8075730.html Ctrl+Alt+T自定义快捷键窗口里修改 1）名称：可以随意填写 2）命令：填写/usr/bin/gnome-terminal（因为这个是终端程序的路径嘛） 安装Chrome浏览器 ？ 添加chrome源 su root cd /etc/yum.repos.d/ 下载google-chrome.repo并保存 wget http://repo.fdzh.org/chrome/google-chrome-mirrors.repo 安装Chrome dnf install -y google-chrome-stable 使sudo命令，用户不在sudoers文件中解决之法大约等待十几分钟安装完毕后，就可以在所有应用中找到Chrome了。解决方法很简单，就是在/etc/sudoers文件中把自己的用户名加进去。我们通过gedit编辑器打开该文件：sudo gedit /etc/sudoers找到：Allow root to run any commands anywhere这一行，在其下方加入：此处为你的用户名 ALL=(ALL) ALL保存即可。 安装WeChatcentos升级内核后如何取消旧内核开机启动选项rpm -qa kernel 会提示有哪些kernel并列出来。 rpm -e kernel*** 删除不想要的kernel，然后查看grub文件，会发现系统已经将启动grub里的旧的启动项删除，不需要再手动删除。 linux下如何实现空密码登陆在linux下如何手动修改passwd配置文件实现 在linux中口令管理这项，用户在没有设置密码的情况下是没有办法登陆糸统的方法如下： 首先你把一个用户的密码清空，passwd -d users ;查看一下，passwd -S users ;会发现显示 passwd:locked ；就是说密码已锁定，可以直接登陆了。打“passwd -uf users ”可以密码解锁成功，恢复密码。或者在GDM（GNOME环境）里面设置自动登录，每次开机可无需输入密码 CentOS, RHEL &amp; Fedora上安装TeamViewer 10# cd /tmp # wget http://download.teamviewer.com/download/version_10x/teamviewer_linux.rpm # yum localinstall teamviewer_linux.rpm 启动TeamViewer 使用下面的命令就可以启动了 # teamviewer Centos7.4/RHEL7.4系统下安装VMware workstation14http://baijiahao.baidu.com/s?id=1589366067425485735&amp;wfr=spider&amp;for=pc 初始化root密码使用:sudo passwd root设置root的密码 修改主机名hostnamectl set-hostname &lt;newhostname&gt; 这条命令会删除/etc/hostname文件中的主机名，然后替换为新的主机名。和第一种方法一样，我们也需要更新/etc/hosts文件。这两种方法的本质都是一样的。","categories":[],"tags":[{"name":"教程","slug":"教程","permalink":"http://yoursite.com/tags/教程/"}]},{"title":"Kernel前辈教C小子探案  3.18-3.20","slug":"Kernel前辈教C小子探案","date":"2018-03-20T05:05:00.000Z","updated":"2018-04-15T01:20:34.000Z","comments":true,"path":"Kernel前辈教C小子探案/","link":"","permalink":"http://yoursite.com/Kernel前辈教C小子探案/","excerpt":"","text":"111与221C小子：int main(){int n=1;printf(&quot;%d %d %d\\n&quot;,n,++n,n--);}Kernel前辈，请问它怎么在不同的编译器下答案不一样Kernel前辈:C小子，你自己的答案是什么？C小子：官方答案1 1 1Kernel前辈:为什么会不一样，这很有意思。回答一下这个问题C小子：好Kernel前辈:学习Linux内核，需要具备的知识基础，非常熟练的C，数据结构，编译原理，操作系统，软件工程，计算机原理，如果要了解网络，还需要网络知识。如果没有这些基础，真的学的很痛苦，就像空中楼阁，还有汇编语言。考试与实际代码还有相当的距离的，你看过Linux的一点代码，应该有感觉的。还有shell脚本语言C小子：是的，坚持了理论有时就要放弃实践，坚持了实践就有时就要放弃理论。shell之前也写过Kernel前辈:学内核这块，必须在理论和实践之间来回转换，因为，必须拿出东西才能给自己信心C小子：是的。技术是基本功!C小子：#include &lt;stdio.h&gt;int main(){ int n=1; printf(&quot;%d %d %d\\n&quot;,n,++n,n--);} vc++ ：2 2 1Turbo C: 1 1 1 VC++环境下连续自增(自减)运算规则在一般表达式中和在函数参数中计算的结果相同;规则：1.先参考运算优先级;（++n的优先级高）2.然后再从右至左依次对每个表达式求解;（n–=1，n=1;++n=2，n=2;n=2）3.然后再从左到右输出每个表达式的值;（2 2 1 ）4.最后变量n的值再自减1次。 Turbo C环境中当自增、自减运算出现在函数参数中时，计算方法采用扫描格式决定;规则：1.Turbo C编译环境中在从右至左依次对每个表达式求解时，先得到n–的值，然后n的值减1;（n–=1，n=0）2.然后n加上1，得到++n的值;（n=0+1=1,++n=1）3.最后n为1。（n=1）C小子：Kernel前辈:（1）把这些汇编指令解释一下 （2）从编译角度说明二者这样做的理以及带来的问题 （3）在实际项目中遇到这样的问题如何解决 （4）在Linux 下运行看看结果 （5）谁遵循了标准 CC小子：好的C小子：（1）把这些汇编指令解释一下汇编代码： int n=1;00401028 mov dword ptr [ebp-4],1//将1存放到ebp-4中，ebp-4此时为1 printf(&quot;%d %d %d\\n&quot;,n,++n,n--);// 2 2 10040102F mov eax,dword ptr [ebp-4]//把ebp-4的值存放到寄存器eax中，eax此时为100401032 mov dword ptr [ebp-8],eax//将寄存器的值存放到地址为ebp-8的临时量中，此临时量ebp-8保存的值是100401035 mov ecx,dword ptr [ebp-8]//将ebp-8的值存放到寄存器ecx中，ecx此时是100401038 push ecx//将ecx的值压入栈中，100401039 mov edx,dword ptr [ebp-4]//将ebp-4的值放到edx中，edx此时为10040103C add edx,1//对寄存器edx的值进行+1操作，edx为20040103F mov dword ptr [ebp-4],edx//将寄存器edx的值重新写到ebp-4中，ebp-4此时为200401042 mov eax,dword ptr [ebp-4]//将ebp-4的值取出来放到寄存器eax中，eax为200401045 push eax//将eax的值压入栈中,1 200401046 mov ecx,dword ptr [ebp-4]//将ebp-4的值放到ecx中，ecx为200401049 push ecx////将ecx的值压入栈中， 1 2 20040104A push offset string &quot;%d&quot; (0042201c)//压入字符串参数0040104F mov edx,dword ptr [ebp-4]//将ebp-4的值放到edx中，edx 为200401052 sub edx,1//对edx寄存器进行-1操作，edx 为100401055 mov dword ptr [ebp-4],edx//将eax放到ebp-4中00401058 call printf (00401090)//开始执行printf函数 2 2 10040105D add esp,10h//释放局部变量空间 （2）从编译角度说明二者这样做的理由以及带来的问题理由：编译时不同编译器处理方法不同，在vc++中编译时，需要考虑优先级，（add edx,1）。编译角度很底层，规则不同，或许是因为更底层的一些东西限制，我再查查 问题：会出现歧义， 使得一些程序不能很好的移植，不能跨平台使用 （3）在实际项目中遇到这样的问题如何解决应避免歧义，以稳定兼容为原则，将自增自减运算用变量代替，根据要求改写,可写成：#include &lt;stdio.h&gt;int main(){ int i,j,k; int n=1; i=n; j=++n; k=n--; printf(&quot;%d %d %d\\n&quot;,n,++n,n--);} （4）在Linux 下运行看看结果1 1 1（5）谁遵循了标准 Clinux 下的编译器gcc遵循了标准 cKernel前辈:回答的不错，还有一个问题，为什么要压栈？C小子：压栈可能是为何后面便于一条输出语句可以输出多个结果吧Kernel前辈:不对C小子：那是为什么呀，从右向左的压栈，从左向右的输出，多个结果保证顺序。编译系统我不是非常了解Kernel前辈:手上要有一本深入理解计算机系统的书，查看函数的执行过程就明白了C小子：嗯嗯，我了解的深度不够Kernel前辈:不是不够，皮毛尚未触及Kernel前辈:刚才你回答问题的思路和方法是正确的C小子：Kernel前辈，虽然我用户态的程序不太了解，但不是完全不可用学内核，只要方法正确，对比着学，内核态用户态相互验证，这样更好。那到底为什么要压栈呀？Kernel前辈:这个需要你系统的去了解，不能等答案。会涉及到编译程序如何对函数进程编译处理。执行程序如何执行函数C小子：是一种约定的规则Kernel前辈:对，计算机中有很多的标准和接口C小子：会不会编译程序对函数处理 在不同的条件下也不同，就像不同的编译器那个程序结果也不同。就是说有不同的规则Kernel前辈:编译器不一样，处理规则上有差异C小子：好有意思呀，一切可定义Kernel前辈:但业界也有统一标准，这些标准相当于基类，是最低原则，各家还会定自己的规则C小子：各家自己定义是为了便于自己的一些应用，统一标准是为了传播交流。多谢Kernel前辈指点。 20001与19496Kernel前辈:一个加1操作就可以把计算机方方面面的知识都带出来。加1操作系统会引发很多有趣的话题，在并发环境下又发生什么不可思议的事？写一个简单的程序，两个线程共享变量n, 初值为1，分别对N加1000次后，结果是什么，为什么C小子：#include &lt;stdio.h&gt;#include &quot;windows.h&quot;int n = 1;bool p1 = false;bool p2 = false;DWORD WINAPI proc1(LPVOID lparentet){for(int i = 0;i&lt;1000;i++){n++;}p1= true;return 0;}DWORD WINAPI proc2(LPVOID lparentet){for(int i = 0;i&lt;1000;i++){n++;}p2 = true;return 0;}int main(){CreateThread(NULL,0,proc1,NULL,0,NULL);CreateThread(NULL,0,proc2,NULL,0,NULL);while(1){if(p1 &amp;&amp; p2){printf(&quot;%d\\n&quot;,n);break;}}return 0;}1000次，运行结果一直都是2001，没有发现异常，但是1W次有时会有异常，按理说是20001，但有时就是其它数，10W次的话经常异常。好奇怪，次数越多，异常现象越明显1000次很难发现异常。这和处理器性能有没有关系？Kernel前辈:这个问题，自己探索，如果方向对了，再给你说C小子：好，会不会是一个线程访问这个全局变量时而另一个线程将其修改，从而产生异常。而异常结果小于正常结果是因为是n++这个运算。如果是n–则会大于正常结果。异常结果与正常结果之差不一定是发生异常的次数，一个线程访问这个全局变量时而另一个线程或许会将其修改再修改。次数越多，异常现象越明显，这和处理器性能应该没有关系，因为执行的次数一定。全局变量为1，n– 1000次后应是-1999，异常结果大于正常结果Kernel前辈:从线程的并发执行考虑C小子：一个线程访问这个全局变量时而另一个线程将其修改，从而产生异常Kernel前辈:同步机制C小子：多谢Kernel前辈指点Kernel前辈:为什么异常还没说到根本上C小子：没有上锁，经常无序执行，虽然效率高，但是容易出错。再次感谢Kernel前辈的指点。","categories":[],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"http://yoursite.com/tags/Kernel/"}]},{"title":"Hello Docker World","slug":"Hello Docker World","date":"2018-01-11T06:06:29.000Z","updated":"2019-02-22T09:43:38.167Z","comments":true,"path":"Hello Docker World/","link":"","permalink":"http://yoursite.com/Hello Docker World/","excerpt":"","text":"安装Docker命令： #wget -qO- https://get.docker.com | sh 允许非root用户： #usermod -aG docker xxx //把xxx用户添加到docker用户组中 拉docker镜像： #docker pull nginx 查看已安装docker镜像： #docker images 启动nginx服务 #docker run -p 8080:80 -d nginx 列出运行中的容器 #docker ps 编辑html文件，添加Hello Docker World #vim index.html 拷贝文件： #docker cp index.html 容器id://usr/share/nginx/html 查看主页： localhost:8080","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"安全 中华人民共和国网络安全法 5.28-6.1","slug":"diary-2017-0528-0601","date":"2017-06-01T02:36:00.000Z","updated":"2017-06-01T06:34:00.000Z","comments":true,"path":"diary-2017-0528-0601/","link":"","permalink":"http://yoursite.com/diary-2017-0528-0601/","excerpt":"中华人民共和国网络安全法(2016年11月7日第十二届全国人民代表大会常务委员会第二十四次会议通过,2017年6月1日正式实施） 目 录 第一章 总 则 第二章 网络安全支持与促进 第三章 网络运行安全 第一节 一般规定 第二节 关键信息基础设施的运行安全 第四章 网络信息安全 第五章 监测预警与应急处置 第六章 法律责任 第七章 附 则","text":"中华人民共和国网络安全法(2016年11月7日第十二届全国人民代表大会常务委员会第二十四次会议通过,2017年6月1日正式实施） 目 录 第一章 总 则 第二章 网络安全支持与促进 第三章 网络运行安全 第一节 一般规定 第二节 关键信息基础设施的运行安全 第四章 网络信息安全 第五章 监测预警与应急处置 第六章 法律责任 第七章 附 则 第一章 总 则第一条 为了保障网络安全，维护网络空间主权和国家安全、社会公共利益，保护公民、法人和其他组织的合法权益，促进经济社会信息化健康发展，制定本法。第二条 在中华人民共和国境内建设、运营、维护和使用网络，以及网络安全的监督管理，适用本法。第三条 国家坚持网络安全与信息化发展并重，遵循积极利用、科学发展、依法管理、确保安全的方针，推进网络基础设施建设和互联互通，鼓励网络技术创新和应用，支持培养网络安全人才，建立健全网络安全保障体系，提高网络安全保护能力。第四条 国家制定并不断完善网络安全战略，明确保障网络安全的基本要求和主要目标，提出重点领域的网络安全政策、工作任务和措施。第五条 国家采取措施，监测、防御、处置来源于中华人民共和国境内外的网络安全风险和威胁，保护关键信息基础设施免受攻击、侵入、干扰和破坏，依法惩治网络违法犯罪活动，维护网络空间安全和秩序。第六条 国家倡导诚实守信、健康文明的网络行为，推动传播社会主义核心价值观，采取措施提高全社会的网络安全意识和水平，形成全社会共同参与促进网络安全的良好环境。第七条 国家积极开展网络空间治理、网络技术研发和标准制定、打击网络违法犯罪等方面的国际交流与合作，推动构建和平、安全、开放、合作的网络空间，建立多边、民主、透明的网络治理体系。第八条 国家网信部门负责统筹协调网络安全工作和相关监督管理工作。国务院电信主管部门、公安部门和其他有关机关依照本法和有关法律、行政法规的规定，在各自职责范围内负责网络安全保护和监督管理工作。县级以上地方人民政府有关部门的网络安全保护和监督管理职责，按照国家有关规定确定。第九条 网络运营者开展经营和服务活动，必须遵守法律、行政法规，尊重社会公德，遵守商业道德，诚实信用，履行网络安全保护义务，接受政府和社会的监督，承担社会责任。第十条 建设、运营网络或者通过网络提供服务，应当依照法律、行政法规的规定和国家标准的强制性要求，采取技术措施和其他必要措施，保障网络安全、稳定运行，有效应对网络安全事件，防范网络违法犯罪活动，维护网络数据的完整性、保密性和可用性。第十一条 网络相关行业组织按照章程，加强行业自律，制定网络安全行为规范，指导会员加强网络安全保护，提高网络安全保护水平，促进行业健康发展。第十二条 国家保护公民、法人和其他组织依法使用网络的权利，促进网络接入普及，提升网络服务水平，为社会提供安全、便利的网络服务，保障网络信息依法有序自由流动。任何个人和组织使用网络应当遵守宪法法律，遵守公共秩序，尊重社会公德，不得危害网络安全，不得利用网络从事危害国家安全、荣誉和利益，煽动颠覆国家政权、推翻社会主义制度，煽动分裂国家、破坏国家统一，宣扬恐怖主义、极端主义，宣扬民族仇恨、民族歧视，传播暴力、淫秽色情信息，编造、传播虚假信息扰乱经济秩序和社会秩序，以及侵害他人名誉、隐私、知识产权和其他合法权益等活动。第十三条 国家支持研究开发有利于未成年人健康成长的网络产品和服务，依法惩治利用网络从事危害未成年人身心健康的活动，为未成年人提供安全、健康的网络环境。第十四条 任何个人和组织有权对危害网络安全的行为向网信、电信、公安等部门举报。收到举报的部门应当及时依法作出处理；不属于本部门职责的，应当及时移送有权处理的部门。有关部门应当对举报人的相关信息予以保密，保护举报人的合法权益。第二章 网络安全支持与促进第十五条 国家建立和完善网络安全标准体系。国务院标准化行政主管部门和国务院其他有关部门根据各自的职责，组织制定并适时修订有关网络安全管理以及网络产品、服务和运行安全的国家标准、行业标准。国家支持企业、研究机构、高等学校、网络相关行业组织参与网络安全国家标准、行业标准的制定。第十六条 国务院和省、自治区、直辖市人民政府应当统筹规划，加大投入，扶持重点网络安全技术产业和项目，支持网络安全技术的研究开发和应用，推广安全可信的网络产品和服务，保护网络技术知识产权，支持企业、研究机构和高等学校等参与国家网络安全技术创新项目。第十七条 国家推进网络安全社会化服务体系建设，鼓励有关企业、机构开展网络安全认证、检测和风险评估等安全服务。第十八条 国家鼓励开发网络数据安全保护和利用技术，促进公共数据资源开放，推动技术创新和经济社会发展。国家支持创新网络安全管理方式，运用网络新技术，提升网络安全保护水平。第十九条 各级人民政府及其有关部门应当组织开展经常性的网络安全宣传教育，并指导、督促有关单位做好网络安全宣传教育工作。大众传播媒介应当有针对性地面向社会进行网络安全宣传教育。第二十条 国家支持企业和高等学校、职业学校等教育培训机构开展网络安全相关教育与培训，采取多种方式培养网络安全人才，促进网络安全人才交流。第三章 网络运行安全第一节 一般规定第二十一条 国家实行网络安全等级保护制度。网络运营者应当按照网络安全等级保护制度的要求，履行下列安全保护义务，保障网络免受干扰、破坏或者未经授权的访问，防止网络数据泄露或者被窃取、篡改：（一）制定内部安全管理制度和操作规程，确定网络安全负责人，落实网络安全保护责任；（二）采取防范计算机病毒和网络攻击、网络侵入等危害网络安全行为的技术措施；（三）采取监测、记录网络运行状态、网络安全事件的技术措施，并按照规定留存相关的网络日志不少于六个月；（四）采取数据分类、重要数据备份和加密等措施；（五）法律、行政法规规定的其他义务。第二十二条 网络产品、服务应当符合相关国家标准的强制性要求。网络产品、服务的提供者不得设置恶意程序；发现其网络产品、服务存在安全缺陷、漏洞等风险时，应当立即采取补救措施，按照规定及时告知用户并向有关主管部门报告。网络产品、服务的提供者应当为其产品、服务持续提供安全维护；在规定或者当事人约定的期限内，不得终止提供安全维护。网络产品、服务具有收集用户信息功能的，其提供者应当向用户明示并取得同意；涉及用户个人信息的，还应当遵守本法和有关法律、行政法规关于个人信息保护的规定。第二十三条 网络关键设备和网络安全专用产品应当按照相关国家标准的强制性要求，由具备资格的机构安全认证合格或者安全检测符合要求后，方可销售或者提供。国家网信部门会同国务院有关部门制定、公布网络关键设备和网络安全专用产品目录，并推动安全认证和安全检测结果互认，避免重复认证、检测。第二十四条 网络运营者为用户办理网络接入、域名注册服务，办理固定电话、移动电话等入网手续，或者为用户提供信息发布、即时通讯等服务，在与用户签订协议或者确认提供服务时，应当要求用户提供真实身份信息。用户不提供真实身份信息的，网络运营者不得为其提供相关服务。国家实施网络可信身份战略，支持研究开发安全、方便的电子身份认证技术，推动不同电子身份认证之间的互认。第二十五条 网络运营者应当制定网络安全事件应急预案，及时处置系统漏洞、计算机病毒、网络攻击、网络侵入等安全风险；在发生危害网络安全的事件时，立即启动应急预案，采取相应的补救措施，并按照规定向有关主管部门报告。第二十六条 开展网络安全认证、检测、风险评估等活动，向社会发布系统漏洞、计算机病毒、网络攻击、网络侵入等网络安全信息，应当遵守国家有关规定。第二十七条 任何个人和组织不得从事非法侵入他人网络、干扰他人网络正常功能、窃取网络数据等危害网络安全的活动；不得提供专门用于从事侵入网络、干扰网络正常功能及防护措施、窃取网络数据等危害网络安全活动的程序、工具；明知他人从事危害网络安全的活动的，不得为其提供技术支持、广告推广、支付结算等帮助。第二十八条 网络运营者应当为公安机关、国家安全机关依法维护国家安全和侦查犯罪的活动提供技术支持和协助。第二十九条 国家支持网络运营者之间在网络安全信息收集、分析、通报和应急处置等方面进行合作，提高网络运营者的安全保障能力。有关行业组织建立健全本行业的网络安全保护规范和协作机制，加强对网络安全风险的分析评估，定期向会员进行风险警示，支持、协助会员应对网络安全风险。第三十条 网信部门和有关部门在履行网络安全保护职责中获取的信息，只能用于维护网络安全的需要，不得用于其他用途。第二节 关键信息基础设施的运行安全第三十一条 国家对公共通信和信息服务、能源、交通、水利、金融、公共服务、电子政务等重要行业和领域，以及其他一旦遭到破坏、丧失功能或者数据泄露，可能严重危害国家安全、国计民生、公共利益的关键信息基础设施，在网络安全等级保护制度的基础上，实行重点保护。关键信息基础设施的具体范围和安全保护办法由国务院制定。国家鼓励关键信息基础设施以外的网络运营者自愿参与关键信息基础设施保护体系。第三十二条 按照国务院规定的职责分工，负责关键信息基础设施安全保护工作的部门分别编制并组织实施本行业、本领域的关键信息基础设施安全规划，指导和监督关键信息基础设施运行安全保护工作。第三十三条 建设关键信息基础设施应当确保其具有支持业务稳定、持续运行的性能，并保证安全技术措施同步规划、同步建设、同步使用。第三十四条 除本法第二十一条的规定外，关键信息基础设施的运营者还应当履行下列安全保护义务：（一）设置专门安全管理机构和安全管理负责人，并对该负责人和关键岗位的人员进行安全背景审查；（二）定期对从业人员进行网络安全教育、技术培训和技能考核；（三）对重要系统和数据库进行容灾备份；（四）制定网络安全事件应急预案，并定期进行演练；（五）法律、行政法规规定的其他义务。第三十五条 关键信息基础设施的运营者采购网络产品和服务，可能影响国家安全的，应当通过国家网信部门会同国务院有关部门组织的国家安全审查。第三十六条 关键信息基础设施的运营者采购网络产品和服务，应当按照规定与提供者签订安全保密协议，明确安全和保密义务与责任。第三十七条 关键信息基础设施的运营者在中华人民共和国境内运营中收集和产生的个人信息和重要数据应当在境内存储。因业务需要，确需向境外提供的，应当按照国家网信部门会同国务院有关部门制定的办法进行安全评估；法律、行政法规另有规定的，依照其规定。第三十八条 关键信息基础设施的运营者应当自行或者委托网络安全服务机构对其网络的安全性和可能存在的风险每年至少进行一次检测评估，并将检测评估情况和改进措施报送相关负责关键信息基础设施安全保护工作的部门。第三十九条 国家网信部门应当统筹协调有关部门对关键信息基础设施的安全保护采取下列措施：（一）对关键信息基础设施的安全风险进行抽查检测，提出改进措施，必要时可以委托网络安全服务机构对网络存在的安全风险进行检测评估；（二）定期组织关键信息基础设施的运营者进行网络安全应急演练，提高应对网络安全事件的水平和协同配合能力；（三）促进有关部门、关键信息基础设施的运营者以及有关研究机构、网络安全服务机构等之间的网络安全信息共享；（四）对网络安全事件的应急处置与网络功能的恢复等，提供技术支持和协助。第四章 网络信息安全第四十条 网络运营者应当对其收集的用户信息严格保密，并建立健全用户信息保护制度。第四十一条 网络运营者收集、使用个人信息，应当遵循合法、正当、必要的原则，公开收集、使用规则，明示收集、使用信息的目的、方式和范围，并经被收集者同意。网络运营者不得收集与其提供的服务无关的个人信息，不得违反法律、行政法规的规定和双方的约定收集、使用个人信息，并应当依照法律、行政法规的规定和与用户的约定，处理其保存的个人信息。第四十二条 网络运营者不得泄露、篡改、毁损其收集的个人信息；未经被收集者同意，不得向他人提供个人信息。但是，经过处理无法识别特定个人且不能复原的除外。网络运营者应当采取技术措施和其他必要措施，确保其收集的个人信息安全，防止信息泄露、毁损、丢失。在发生或者可能发生个人信息泄露、毁损、丢失的情况时，应当立即采取补救措施，按照规定及时告知用户并向有关主管部门报告。第四十三条 个人发现网络运营者违反法律、行政法规的规定或者双方的约定收集、使用其个人信息的，有权要求网络运营者删除其个人信息；发现网络运营者收集、存储的其个人信息有错误的，有权要求网络运营者予以更正。网络运营者应当采取措施予以删除或者更正。第四十四条 任何个人和组织不得窃取或者以其他非法方式获取个人信息，不得非法出售或者非法向他人提供个人信息。第四十五条 依法负有网络安全监督管理职责的部门及其工作人员，必须对在履行职责中知悉的个人信息、隐私和商业秘密严格保密，不得泄露、出售或者非法向他人提供。第四十六条 任何个人和组织应当对其使用网络的行为负责，不得设立用于实施诈骗，传授犯罪方法，制作或者销售违禁物品、管制物品等违法犯罪活动的网站、通讯群组，不得利用网络发布涉及实施诈骗，制作或者销售违禁物品、管制物品以及其他违法犯罪活动的信息。第四十七条 网络运营者应当加强对其用户发布的信息的管理，发现法律、行政法规禁止发布或者传输的信息的，应当立即停止传输该信息，采取消除等处置措施，防止信息扩散，保存有关记录，并向有关主管部门报告。第四十八条 任何个人和组织发送的电子信息、提供的应用软件，不得设置恶意程序，不得含有法律、行政法规禁止发布或者传输的信息。电子信息发送服务提供者和应用软件下载服务提供者，应当履行安全管理义务，知道其用户有前款规定行为的，应当停止提供服务，采取消除等处置措施，保存有关记录，并向有关主管部门报告。第四十九条 网络运营者应当建立网络信息安全投诉、举报制度，公布投诉、举报方式等信息，及时受理并处理有关网络信息安全的投诉和举报。网络运营者对网信部门和有关部门依法实施的监督检查，应当予以配合。第五十条 国家网信部门和有关部门依法履行网络信息安全监督管理职责，发现法律、行政法规禁止发布或者传输的信息的，应当要求网络运营者停止传输，采取消除等处置措施，保存有关记录；对来源于中华人民共和国境外的上述信息，应当通知有关机构采取技术措施和其他必要措施阻断传播。第五章 监测预警与应急处置第五十一条 国家建立网络安全监测预警和信息通报制度。国家网信部门应当统筹协调有关部门加强网络安全信息收集、分析和通报工作，按照规定统一发布网络安全监测预警信息。第五十二条 负责关键信息基础设施安全保护工作的部门，应当建立健全本行业、本领域的网络安全监测预警和信息通报制度，并按照规定报送网络安全监测预警信息。第五十三条 国家网信部门协调有关部门建立健全网络安全风险评估和应急工作机制，制定网络安全事件应急预案，并定期组织演练。负责关键信息基础设施安全保护工作的部门应当制定本行业、本领域的网络安全事件应急预案，并定期组织演练。网络安全事件应急预案应当按照事件发生后的危害程度、影响范围等因素对网络安全事件进行分级，并规定相应的应急处置措施。第五十四条 网络安全事件发生的风险增大时，省级以上人民政府有关部门应当按照规定的权限和程序，并根据网络安全风险的特点和可能造成的危害，采取下列措施：（一）要求有关部门、机构和人员及时收集、报告有关信息，加强对网络安全风险的监测；（二）组织有关部门、机构和专业人员，对网络安全风险信息进行分析评估，预测事件发生的可能性、影响范围和危害程度；（三）向社会发布网络安全风险预警，发布避免、减轻危害的措施。第五十五条 发生网络安全事件，应当立即启动网络安全事件应急预案，对网络安全事件进行调查和评估，要求网络运营者采取技术措施和其他必要措施，消除安全隐患，防止危害扩大，并及时向社会发布与公众有关的警示信息。第五十六条 省级以上人民政府有关部门在履行网络安全监督管理职责中，发现网络存在较大安全风险或者发生安全事件的，可以按照规定的权限和程序对该网络的运营者的法定代表人或者主要负责人进行约谈。网络运营者应当按照要求采取措施，进行整改，消除隐患。第五十七条 因网络安全事件，发生突发事件或者生产安全事故的，应当依照《中华人民共和国突发事件应对法》、《中华人民共和国安全生产法》等有关法律、行政法规的规定处置。第五十八条 因维护国家安全和社会公共秩序，处置重大突发社会安全事件的需要，经国务院决定或者批准，可以在特定区域对网络通信采取限制等临时措施。第六章 法律责任第五十九条 网络运营者不履行本法第二十一条、第二十五条规定的网络安全保护义务的，由有关主管部门责令改正，给予警告；拒不改正或者导致危害网络安全等后果的，处一万元以上十万元以下罚款，对直接负责的主管人员处五千元以上五万元以下罚款。关键信息基础设施的运营者不履行本法第三十三条、第三十四条、第三十六条、第三十八条规定的网络安全保护义务的，由有关主管部门责令改正，给予警告；拒不改正或者导致危害网络安全等后果的，处十万元以上一百万元以下罚款，对直接负责的主管人员处一万元以上十万元以下罚款。第六十条 违反本法第二十二条第一款、第二款和第四十八条第一款规定，有下列行为之一的，由有关主管部门责令改正，给予警告；拒不改正或者导致危害网络安全等后果的，处五万元以上五十万元以下罚款，对直接负责的主管人员处一万元以上十万元以下罚款：（一）设置恶意程序的；（二）对其产品、服务存在的安全缺陷、漏洞等风险未立即采取补救措施，或者未按照规定及时告知用户并向有关主管部门报告的；（三）擅自终止为其产品、服务提供安全维护的。第六十一条 网络运营者违反本法第二十四条第一款规定，未要求用户提供真实身份信息，或者对不提供真实身份信息的用户提供相关服务的，由有关主管部门责令改正；拒不改正或者情节严重的，处五万元以上五十万元以下罚款，并可以由有关主管部门责令暂停相关业务、停业整顿、关闭网站、吊销相关业务许可证或者吊销营业执照，对直接负责的主管人员和其他直接责任人员处一万元以上十万元以下罚款。第六十二条 违反本法第二十六条规定，开展网络安全认证、检测、风险评估等活动，或者向社会发布系统漏洞、计算机病毒、网络攻击、网络侵入等网络安全信息的，由有关主管部门责令改正，给予警告；拒不改正或者情节严重的，处一万元以上十万元以下罚款，并可以由有关主管部门责令暂停相关业务、停业整顿、关闭网站、吊销相关业务许可证或者吊销营业执照，对直接负责的主管人员和其他直接责任人员处五千元以上五万元以下罚款。第六十三条 违反本法第二十七条规定，从事危害网络安全的活动，或者提供专门用于从事危害网络安全活动的程序、工具，或者为他人从事危害网络安全的活动提供技术支持、广告推广、支付结算等帮助，尚不构成犯罪的，由公安机关没收违法所得，处五日以下拘留，可以并处五万元以上五十万元以下罚款；情节较重的，处五日以上十五日以下拘留，可以并处十万元以上一百万元以下罚款。单位有前款行为的，由公安机关没收违法所得，处十万元以上一百万元以下罚款，并对直接负责的主管人员和其他直接责任人员依照前款规定处罚。违反本法第二十七条规定，受到治安管理处罚的人员，五年内不得从事网络安全管理和网络运营关键岗位的工作；受到刑事处罚的人员，终身不得从事网络安全管理和网络运营关键岗位的工作。第六十四条 网络运营者、网络产品或者服务的提供者违反本法第二十二条第三款、第四十一条至第四十三条规定，侵害个人信息依法得到保护的权利的，由有关主管部门责令改正，可以根据情节单处或者并处警告、没收违法所得、处违法所得一倍以上十倍以下罚款，没有违法所得的，处一百万元以下罚款，对直接负责的主管人员和其他直接责任人员处一万元以上十万元以下罚款；情节严重的，并可以责令暂停相关业务、停业整顿、关闭网站、吊销相关业务许可证或者吊销营业执照。违反本法第四十四条规定，窃取或者以其他非法方式获取、非法出售或者非法向他人提供个人信息，尚不构成犯罪的，由公安机关没收违法所得，并处违法所得一倍以上十倍以下罚款，没有违法所得的，处一百万元以下罚款。第六十五条 关键信息基础设施的运营者违反本法第三十五条规定，使用未经安全审查或者安全审查未通过的网络产品或者服务的，由有关主管部门责令停止使用，处采购金额一倍以上十倍以下罚款；对直接负责的主管人员和其他直接责任人员处一万元以上十万元以下罚款。第六十六条 关键信息基础设施的运营者违反本法第三十七条规定，在境外存储网络数据，或者向境外提供网络数据的，由有关主管部门责令改正，给予警告，没收违法所得，处五万元以上五十万元以下罚款，并可以责令暂停相关业务、停业整顿、关闭网站、吊销相关业务许可证或者吊销营业执照；对直接负责的主管人员和其他直接责任人员处一万元以上十万元以下罚款。第六十七条 违反本法第四十六条规定，设立用于实施违法犯罪活动的网站、通讯群组，或者利用网络发布涉及实施违法犯罪活动的信息，尚不构成犯罪的，由公安机关处五日以下拘留，可以并处一万元以上十万元以下罚款；情节较重的，处五日以上十五日以下拘留，可以并处五万元以上五十万元以下罚款。关闭用于实施违法犯罪活动的网站、通讯群组。单位有前款行为的，由公安机关处十万元以上五十万元以下罚款，并对直接负责的主管人员和其他直接责任人员依照前款规定处罚。第六十八条 网络运营者违反本法第四十七条规定，对法律、行政法规禁止发布或者传输的信息未停止传输、采取消除等处置措施、保存有关记录的，由有关主管部门责令改正，给予警告，没收违法所得；拒不改正或者情节严重的，处十万元以上五十万元以下罚款，并可以责令暂停相关业务、停业整顿、关闭网站、吊销相关业务许可证或者吊销营业执照，对直接负责的主管人员和其他直接责任人员处一万元以上十万元以下罚款。电子信息发送服务提供者、应用软件下载服务提供者，不履行本法第四十八条第二款规定的安全管理义务的，依照前款规定处罚。第六十九条 网络运营者违反本法规定，有下列行为之一的，由有关主管部门责令改正；拒不改正或者情节严重的，处五万元以上五十万元以下罚款，对直接负责的主管人员和其他直接责任人员，处一万元以上十万元以下罚款：（一）不按照有关部门的要求对法律、行政法规禁止发布或者传输的信息，采取停止传输、消除等处置措施的；（二）拒绝、阻碍有关部门依法实施的监督检查的；（三）拒不向公安机关、国家安全机关提供技术支持和协助的。第七十条 发布或者传输本法第十二条第二款和其他法律、行政法规禁止发布或者传输的信息的，依照有关法律、行政法规的规定处罚。第七十一条 有本法规定的违法行为的，依照有关法律、行政法规的规定记入信用档案，并予以公示。第七十二条 国家机关政务网络的运营者不履行本法规定的网络安全保护义务的，由其上级机关或者有关机关责令改正；对直接负责的主管人员和其他直接责任人员依法给予处分。第七十三条 网信部门和有关部门违反本法第三十条规定，将在履行网络安全保护职责中获取的信息用于其他用途的，对直接负责的主管人员和其他直接责任人员依法给予处分。网信部门和有关部门的工作人员玩忽职守、滥用职权、徇私舞弊，尚不构成犯罪的，依法给予处分。第七十四条 违反本法规定，给他人造成损害的，依法承担民事责任。违反本法规定，构成违反治安管理行为的，依法给予治安管理处罚；构成犯罪的，依法追究刑事责任。第七十五条 境外的机构、组织、个人从事攻击、侵入、干扰、破坏等危害中华人民共和国的关键信息基础设施的活动，造成严重后果的，依法追究法律责任；国务院公安部门和有关部门并可以决定对该机构、组织、个人采取冻结财产或者其他必要的制裁措施。第七章 附 则第七十六条 本法下列用语的含义：（一）网络，是指由计算机或者其他信息终端及相关设备组成的按照一定的规则和程序对信息进行收集、存储、传输、交换、处理的系统。（二）网络安全，是指通过采取必要措施，防范对网络的攻击、侵入、干扰、破坏和非法使用以及意外事故，使网络处于稳定可靠运行的状态，以及保障网络数据的完整性、保密性、可用性的能力。（三）网络运营者，是指网络的所有者、管理者和网络服务提供者。（四）网络数据，是指通过网络收集、存储、传输、处理和产生的各种电子数据。（五）个人信息，是指以电子或者其他方式记录的能够单独或者与其他信息结合识别自然人个人身份的各种信息，包括但不限于自然人的姓名、出生日期、身份证件号码、个人生物识别信息、住址、电话号码等。第七十七条 存储、处理涉及国家秘密信息的网络的运行安全保护，除应当遵守本法外，还应当遵守保密法律、行政法规的规定。第七十八条 军事网络的安全保护，由中央军事委员会另行规定。第七十九条 本法自2017年6月1日起施行。","categories":[],"tags":[{"name":"安全","slug":"安全","permalink":"http://yoursite.com/tags/安全/"},{"name":"红线","slug":"红线","permalink":"http://yoursite.com/tags/红线/"}]},{"title":"安全 全国高校电脑遭病毒绑架 5.10-5.13","slug":"diary-2017-0510-0513","date":"2017-05-13T02:36:00.000Z","updated":"2017-05-13T07:35:18.000Z","comments":true,"path":"diary-2017-0510-0513/","link":"","permalink":"http://yoursite.com/diary-2017-0510-0513/","excerpt":"​​​本周五，一次迄今为止最大规模的勒索病毒网络攻击席卷全球。据卡巴斯基统计，在过去的十几个小时里，全球共有74个国家的至少4.5万电脑中招。而杀毒软件Avast统计的数据更为惊人：病毒已感染全球至少5.7万台电脑，并仍在迅速蔓延中。截至13日凌晨，全球被该病毒感染的国家与地区。","text":"​​​本周五，一次迄今为止最大规模的勒索病毒网络攻击席卷全球。据卡巴斯基统计，在过去的十几个小时里，全球共有74个国家的至少4.5万电脑中招。而杀毒软件Avast统计的数据更为惊人：病毒已感染全球至少5.7万台电脑，并仍在迅速蔓延中。截至13日凌晨，全球被该病毒感染的国家与地区。 在此提醒广大校园网用户： 为计算机安装最新的安全补丁，微软已发布补丁MS17-010修复了“永恒之蓝”攻击的系统漏洞，请尽快安装此安全补丁，网址为https://technet.microsoft.com/zh-cn/library/security/MS17-010。 关闭445、135、137、138、139端口，关闭网络共享。 强化网络安全意识：不明链接不要点击，不明文件不要下载，不明邮件不要打开。 尽快（今后定期）备份自己电脑中的重要文件资料到移动硬盘、U盘，备份完后脱机保存该磁盘。 建议仍在使用windows xp， windows 2003操作系统的用户尽快升级到window 7/windows 10，或windows 2008/2012/2016操作系统。 安装正版操作系统、Office软件等。","categories":[],"tags":[{"name":"安全","slug":"安全","permalink":"http://yoursite.com/tags/安全/"}]},{"title":"安全 计算机的各种端口关闭方法 2.10-3.09","slug":"diary-2016-0210-0309","date":"2016-03-09T02:36:00.000Z","updated":"2017-05-13T07:30:54.000Z","comments":true,"path":"diary-2016-0210-0309/","link":"","permalink":"http://yoursite.com/diary-2016-0210-0309/","excerpt":"有人曾经把服务器比作房子，而把端口比作通向不同房间（服务）的门，如果不考虑细节的话，这是一个不错的比喻。入侵者要占领这间房子，势必要破门而入（物理入侵另说），那么对于入侵者来说，了解房子开了几扇门，都是什么样的门，门后面有什么东西就显得至关重要。入侵者通常会用扫描器对目标主机的端口进行扫描，以确定哪些端口是开放的，从开放的端口，入侵者可以知道目标主机大致提供了哪些服务，进而猜测可能存在 的漏洞，因此对端口的扫描可以帮助我们更好的了解目标主机，而对于管理员，扫描本机的开放端口也是做好安全防范的第一步。​​​","text":"有人曾经把服务器比作房子，而把端口比作通向不同房间（服务）的门，如果不考虑细节的话，这是一个不错的比喻。入侵者要占领这间房子，势必要破门而入（物理入侵另说），那么对于入侵者来说，了解房子开了几扇门，都是什么样的门，门后面有什么东西就显得至关重要。入侵者通常会用扫描器对目标主机的端口进行扫描，以确定哪些端口是开放的，从开放的端口，入侵者可以知道目标主机大致提供了哪些服务，进而猜测可能存在 的漏洞，因此对端口的扫描可以帮助我们更好的了解目标主机，而对于管理员，扫描本机的开放端口也是做好安全防范的第一步。​​​ 常见各端口： 关闭139端口的方法是在“网络和拨号连接”中“本地连接”中选取“Internet协议(TCP/IP)”属性，进入“高级TCP/IP设置”“WinS设置”里面有一项“禁用TCP/IP的NETBIOS”，打勾就关闭了139端口。 445端口的关闭:修改注册表，添加一个键值HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Services\\NetBT\\Parameters在右面的窗口建立一个SMBDeviceEnabled 为REG_DWORD类型键值为 0这样就ok了 135端口关闭方法 Windows XP系统运行dcomcnfg，展开“组件服务”→“计算机”，在“我的电脑”上点右键选“属性”，切换到“默认属性”，取消“启用分布式COM”；然后切换到“默认协议”，删除“面向连接的TCP/IP”。以上选项有对应的注册表键值，因此也可通过注册表来修改： HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Ole\\EnableDCOM的值改为“N” HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Rpc\\DCOM Protocols 中删除“ncacn_ip_tcp”此外，还需要停用“Distributed Transaction Coordinator”服务，重启之后， 135端口就没有了。Windows 2000系统前面的步骤和在XP下相同，只是需要多停用一个服务，“Task Scheduler”注意dcomcnfg的界面稍有不同，不过内容是一样的。Windows 2003以上方法在2003下无效，目前我只找到一个折中的方法。默认情况下，135端口是在所有地址上监听的，如果只在本机回环地址上监听，也不失为一种解决办法。要想改变135监听的地址，需要Windows Server 2003 Resource Kit tools中的rpccfg.exe。首先看一下网卡上都有哪些网段：rpccfg -l，一般情况下输出如下： 1 127.0.0.0 1 MS TCP Loopback interface 2 192.168.0.0 1 Realtek RTL8139/810x Family Fast Ethernet NIC然后输入；rpccfg -a 1。这样只有本机回环地址才开放135端口。 关闭23端口23端口主要用于Telnet（远程登录）服务，是Internet上普遍采用的登录和仿真程序。端口说明：23端口主要用于Telnet（远程登录）服务，是Internet上普遍采用的登录和仿真程序。同样需要设置客户端和服务器端，开启Telnet服务的客户端就可以登录远程Telnet服务器，采用授权用户名和密码登录。登录之后，允许用户使用命令提示符窗口进行相应的操作。在Windows中可以在命令提示符窗口中，键入“Telnet”命令来使用Telnet远程登录。操作建议：利用Telnet服务，黑客可以搜索远程登录Unix的服务，扫描操作系统的类型。而且在Windows 2000中Telnet服务存在多个严重的漏洞，比如提升权限、拒绝服务等，可以让远程服务器崩溃。Telnet服务的23端口也是TTS（Tiny Telnet Server）木马的缺省端口。所以，建议关闭23端口。","categories":[],"tags":[{"name":"安全","slug":"安全","permalink":"http://yoursite.com/tags/安全/"}]},{"title":"博客网站搭建","slug":"博客网站搭建","date":"2014-05-29T11:48:21.000Z","updated":"2019-02-22T08:50:33.523Z","comments":true,"path":"博客网站搭建/","link":"","permalink":"http://yoursite.com/博客网站搭建/","excerpt":"","text":"hexo博客的背景设置 https://blog.csdn.net/com_ma/article/details/76039859 hexo github搭建个人博客 https://blog.csdn.net/ainuser/article/details/77609180 相关命令： npm install -g hexo npm i hexo init hexo g hexo s hexo d npm install hexo-deployer-git ssh-keygen -t rsa -C &quot;email&quot; git config --global user.name hexo修改默认端口 https://hexo.io/zh-cn/docs/server.html https://blog.csdn.net/gl486546/article/details/71189933","categories":[],"tags":[{"name":"教程","slug":"教程","permalink":"http://yoursite.com/tags/教程/"}]},{"title":"安全 360云盘免费扩容100T空间 4.10-4.14","slug":"diary-2014-0410-0414","date":"2014-04-14T07:54:00.000Z","updated":"2017-05-13T07:56:10.000Z","comments":true,"path":"diary-2014-0410-0414/","link":"","permalink":"http://yoursite.com/diary-2014-0410-0414/","excerpt":"​​​云盘是一种专业的网络存储工具，随时随地的安全存放数据和重要资料。云盘相对于传统的实体磁盘来说，更方便，用户不需要把储存重要资料的实体磁盘带在身上。却一样可以通过互联网，轻松从云端读取自己所存储的信息。最近身边有好几个朋友让帮忙升级，终于闲了下来，下面教大家免费获得360云盘领100T免费空间。","text":"​​​云盘是一种专业的网络存储工具，随时随地的安全存放数据和重要资料。云盘相对于传统的实体磁盘来说，更方便，用户不需要把储存重要资料的实体磁盘带在身上。却一样可以通过互联网，轻松从云端读取自己所存储的信息。最近身边有好几个朋友让帮忙升级，终于闲了下来，下面教大家免费获得360云盘领100T免费空间。 简易教程： 打开浏览器，输入网址 http://sehd.360.cn/turntable/base/draw/?active=0434a1&amp;qid=XXXX 后面的XXXX表示的是32个十六进制数，要求大写并只要0-9 A-F 中随机32位值即可，比如我随意输的C5CA1ACBBBEFCAB299CD9B73E87C7B4A 修改好后直接回车，打开的网站中，找到卡号即可，一串大写的字母 如果出现下面情况，那就是XXX的与别人的重复，在修改下即可 找到卡号后，去360的“空间升级卡”，复制刚刚的卡号，升级即可","categories":[],"tags":[{"name":"安全","slug":"安全","permalink":"http://yoursite.com/tags/安全/"}]},{"title":"Hello World","slug":"hello-world","date":"2014-03-01T02:36:00.000Z","updated":"2018-06-04T21:42:54.000Z","comments":true,"path":"hello-world/","link":"","permalink":"http://yoursite.com/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[{"name":"博客","slug":"博客","permalink":"http://yoursite.com/tags/博客/"}]}]}